{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d05e3b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import afqinsight.nn.tf_models as nn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from afqinsight.datasets import AFQDataset\n",
    "from afqinsight.nn.tf_models import cnn_lenet, mlp4, cnn_vgg, lstm1v0, lstm1, lstm2, blstm1, blstm2, lstm_fcn, cnn_resnet\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os.path\n",
    "# Harmonization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from neurocombat_sklearn import CombatModel\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle, resample\n",
    "from afqinsight.augmentation import jitter, time_warp, scaling\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed8f6798",
   "metadata": {},
   "outputs": [],
   "source": [
    "afq_dataset = AFQDataset.from_files(\n",
    "    fn_nodes=\"../data/raw/combined_tract_profiles.csv\",\n",
    "    fn_subjects=\"../data/raw/participants_updated_id.csv\",\n",
    "    dwi_metrics=[\"dki_fa\", \"dki_md\", \"dki_mk\"],\n",
    "    index_col=\"subject_id\",\n",
    "    target_cols=[\"age\", \"dl_qc_score\", \"scan_site_id\"],\n",
    "    label_encode_cols=[\"scan_site_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a625e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "afq_dataset.drop_target_na()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03cafa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1865\n",
      "(1865, 7200)\n",
      "(1865, 3)\n"
     ]
    }
   ],
   "source": [
    "print(len(afq_dataset.subjects))\n",
    "print(afq_dataset.X.shape)\n",
    "print(afq_dataset.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "337e9c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-17 22:34:23.755187: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "full_dataset = list(afq_dataset.as_tensorflow_dataset().as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcc7387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([xx[0][None] for xx in full_dataset], 0)\n",
    "y = np.array([yy[1][0] for yy in full_dataset])\n",
    "qc = np.array([yy[1][1] for yy in full_dataset])\n",
    "site = np.array([yy[1][2] for yy in full_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15ba2569",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[qc>0]\n",
    "y = y[qc>0]\n",
    "site = site[qc>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d163e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "# EarlyStopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.001,\n",
    "    mode=\"min\",\n",
    "    patience=100\n",
    ")\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9a93d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_this(X, y, rounds=2): \n",
    "    new_X = X[:]\n",
    "    new_y = y[:]\n",
    "    for f in range(rounds): \n",
    "        aug_X = np.zeros_like(X)\n",
    "        # Do each channel separately:\n",
    "        for channel in range(aug_X.shape[-1]):\n",
    "            this_X = X[..., channel][..., np.newaxis]\n",
    "            this_X = jitter(this_X, sigma=np.mean(this_X)/25)\n",
    "            this_X = scaling(this_X, sigma=np.mean(this_X)/25)\n",
    "            this_X = time_warp(this_X, sigma=np.mean(this_X)/25)\n",
    "            aug_X[..., channel] = this_X[...,0]\n",
    "        new_X = np.concatenate([new_X, aug_X])\n",
    "        new_y = np.concatenate([new_y, y])\n",
    "    return new_X, new_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "550e06c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "def impute(X_data):\n",
    "    X_data = np.concatenate([imputer.fit_transform(X_data[..., ii])[:, :, None] for ii in range(X_data.shape[-1])], -1)\n",
    "    return X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a4d4695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-in-one test\n",
    "def cross_site(model_name, name_str, lr, site_1, site_2, site_3, X, y):\n",
    "    # Split the data by sites\n",
    "    X_1 = X[site==site_1]\n",
    "    y_1 = y[site==site_1]\n",
    "    X_2 = X[site==site_2]\n",
    "    y_2 = y[site==site_2]\n",
    "    X_3 = X[site==site_3]\n",
    "    y_3 = y[site==site_3]\n",
    "    # Split the data into train and test sets:\n",
    "    X_train1, X_test, y_train1, y_test = train_test_split(X_1, y_1, test_size=0.2)\n",
    "    X_train2, _, y_train2, _ = train_test_split(X_2, y_2, test_size=0.2)\n",
    "    X_train3, _, y_train3, _ = train_test_split(X_3, y_3, test_size=0.2)\n",
    "    # Imputation\n",
    "    X_train1 = impute(X_train1)\n",
    "    X_train2 = impute(X_train2)\n",
    "    X_train3 = impute(X_train3)\n",
    "    X_test = impute(X_test)\n",
    "    \n",
    "    # Single_site\n",
    "    # Training on site 1\n",
    "    model1 = model_name(input_shape=(100, 72), n_classes=1, output_activation=None, verbose=True)\n",
    "    model1.compile(loss='mean_squared_error',\n",
    "                   optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                   metrics=['mean_squared_error', \n",
    "                            tf.keras.metrics.RootMeanSquaredError(name='rmse'), \n",
    "                            'mean_absolute_error'])\n",
    "               \n",
    "    ckpt_filepath1 = tempfile.NamedTemporaryFile().name + '.h5'\n",
    "    ckpt1 = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = ckpt_filepath1,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"auto\",\n",
    "    )\n",
    "\n",
    "    log1 = tf.keras.callbacks.CSVLogger(filename=(name_str + '1.csv'), append=True)\n",
    "    callbacks1 = [early_stopping, ckpt1, reduce_lr, log1]\n",
    "    model1.fit(X_train1, y_train1, epochs=n_epochs, batch_size=128,\n",
    "               validation_split=0.2, callbacks=callbacks1)\n",
    "    model1.load_weights(ckpt_filepath1)\n",
    "    \n",
    "    # Training on site 2\n",
    "    model2 = model_name(input_shape=(100, 72), n_classes=1, output_activation=None, verbose=True)\n",
    "    model2.compile(loss='mean_squared_error',\n",
    "                   optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                   metrics=['mean_squared_error', \n",
    "                            tf.keras.metrics.RootMeanSquaredError(name='rmse'), \n",
    "                            'mean_absolute_error'])\n",
    "               \n",
    "    ckpt_filepath2 = tempfile.NamedTemporaryFile().name + '.h5'\n",
    "    ckpt2 = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = ckpt_filepath2,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"auto\",\n",
    "    )\n",
    "\n",
    "    log2 = tf.keras.callbacks.CSVLogger(filename=(name_str + '2.csv'), append=True)\n",
    "    callbacks2 = [early_stopping, ckpt2, reduce_lr, log2]\n",
    "    model2.fit(X_train2, y_train2, epochs=n_epochs, batch_size=128,\n",
    "               validation_split=0.2, callbacks=callbacks2)\n",
    "    model2.load_weights(ckpt_filepath2)\n",
    "               \n",
    "    # Training on site 3\n",
    "    model3 = model_name(input_shape=(100, 72), n_classes=1, output_activation=None, verbose=True)\n",
    "    model3.compile(loss='mean_squared_error',\n",
    "                   optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                   metrics=['mean_squared_error', \n",
    "                            tf.keras.metrics.RootMeanSquaredError(name='rmse'), \n",
    "                            'mean_absolute_error'])\n",
    "\n",
    "    ckpt_filepath3 = tempfile.NamedTemporaryFile().name + '.h5'\n",
    "    ckpt3 = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = ckpt_filepath3,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"auto\",\n",
    "    )\n",
    "    \n",
    "    log3 = tf.keras.callbacks.CSVLogger(filename=(name_str + '3.csv'), append=True)\n",
    "    callbacks3 = [early_stopping, ckpt3, reduce_lr, log3]\n",
    "    model3.fit(X_train3, y_train3, epochs=n_epochs, batch_size=128,\n",
    "               validation_split=0.2, callbacks=callbacks3)\n",
    "    model3.load_weights(ckpt_filepath3)\n",
    "    \n",
    "    # Double cross site\n",
    "    # Training on site 2 and 3\n",
    "    sample = y_test.shape[0]//2\n",
    "    sample1 = resample(X_train2, y_train2, n_samples=sample, replace=False)\n",
    "    sample2 = resample(X_train3, y_train3, n_samples=sample, replace=False)\n",
    "    X_train4 = np.concatenate((sample1[0], sample2[0]), axis=0)\n",
    "    y_train4 = np.concatenate((sample1[1], sample2[1]), axis=0)\n",
    "               \n",
    "    X_train4, y_train4 = shuffle(X_train4, y_train4)\n",
    "    X_train4, y_train4 = augment_this(X_train4, y_train4)\n",
    "    X_train4, y_train4 = shuffle(X_train4, y_train4)\n",
    "    \n",
    "    model4 = model_name(input_shape=(100, 72), n_classes=1, output_activation=None, verbose=True)\n",
    "    model4.compile(loss='mean_squared_error',\n",
    "                   optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                   metrics=['mean_squared_error', \n",
    "                            tf.keras.metrics.RootMeanSquaredError(name='rmse'), \n",
    "                            'mean_absolute_error'])\n",
    "    \n",
    "    ckpt_filepath4 = tempfile.NamedTemporaryFile().name + '.h5'\n",
    "    ckpt4 = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = ckpt_filepath4,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"auto\",\n",
    "    )\n",
    "    \n",
    "    log4 = tf.keras.callbacks.CSVLogger(filename=(name_str + '4.csv'), append=True)\n",
    "    callbacks4 = [early_stopping, ckpt4, reduce_lr, log4]\n",
    "    model4.fit(X_train4, y_train4, epochs=n_epochs, batch_size=128,\n",
    "               validation_split=0.2, callbacks=callbacks4)\n",
    "    model4.load_weights(ckpt_filepath4)\n",
    "               \n",
    "    # Testing on site 1\n",
    "    y_predict1 = model1.predict(X_test)\n",
    "    y_predict1 = y_predict1.reshape(y_test.shape)\n",
    "    y_predict2 = model2.predict(X_test)\n",
    "    y_predict2 = y_predict2.reshape(y_test.shape)\n",
    "    y_predict3 = model3.predict(X_test)\n",
    "    y_predict3 = y_predict3.reshape(y_test.shape)\n",
    "    y_predict4 = model4.predict(X_test)\n",
    "    y_predict4 = y_predict4.reshape(y_test.shape)\n",
    "    coef1 = np.corrcoef(y_test, y_predict1)[0,1] ** 2\n",
    "    coef2 = np.corrcoef(y_test, y_predict2)[0,1] ** 2\n",
    "    coef3 = np.corrcoef(y_test, y_predict3)[0,1] ** 2\n",
    "    coef4 = np.corrcoef(y_test, y_predict4)[0,1] ** 2\n",
    "    eval_1 = model1.evaluate(X_test, y_test)\n",
    "    eval_2 = model2.evaluate(X_test, y_test)\n",
    "    eval_3 = model3.evaluate(X_test, y_test)\n",
    "    eval_4 = model4.evaluate(X_test, y_test)\n",
    "    \n",
    "    # Results\n",
    "    result = {'Model': [name_str]*16,\n",
    "              'Train_site': [site_1] * 4 + [site_2] * 4 + [site_3] * 4 + [f'{site_2}, {site_3}'] * 4,\n",
    "              'Test_site': [site_1] * 16,\n",
    "              'Metric': ['MSE', 'RMSE', 'MAE', 'coef'] * 4,\n",
    "              'Value': [eval_1[1], eval_1[2], eval_1[3], coef1,\n",
    "                        eval_2[1], eval_2[2], eval_2[3], coef2,\n",
    "                        eval_3[1], eval_3[2], eval_3[3], coef3,\n",
    "                        eval_4[1], eval_4[2], eval_3[3], coef4]}\n",
    "    df = pd.DataFrame(result)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8573bc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 100, 64)      36928       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 100, 64)     256         ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 100, 64)      0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 100, 64)      20544       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 100, 64)     256         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 100, 64)      0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 100, 64)      12352       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 100, 64)      4672        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 100, 64)     256         ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 100, 64)     256         ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 100, 64)      0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 100, 64)      0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 100, 64)      0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 100, 128)     65664       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 100, 128)    512         ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 100, 128)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 100, 128)     82048       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 100, 128)    512         ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 100, 128)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 100, 128)     49280       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 100, 128)     8320        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 100, 128)    512         ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 100, 128)    512         ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 100, 128)     0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 100, 128)     0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 100, 128)     0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 100, 128)     131200      ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 100, 128)    512         ['conv1d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 100, 128)     0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 100, 128)     82048       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 100, 128)    512         ['conv1d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 100, 128)     0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 100, 128)     49280       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 100, 128)    512         ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 100, 128)    512         ['activation_7[0][0]']           \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 100, 128)     0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 100, 128)     0           ['batch_normalization_11[0][0]', \n",
      "                                                                  'activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 100, 128)     0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['activation_11[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            129         ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - ETA: 0s - loss: 53.2528 - mean_squared_error: 53.2528 - rmse: 7.2975 - mean_absolute_error: 6.1080\n",
      "Epoch 00001: val_loss improved from inf to 5030200.00000, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 4s 467ms/step - loss: 53.2528 - mean_squared_error: 53.2528 - rmse: 7.2975 - mean_absolute_error: 6.1080 - val_loss: 5030200.0000 - val_mean_squared_error: 5030200.0000 - val_rmse: 2242.8108 - val_mean_absolute_error: 2237.7380 - lr: 0.0100\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 7.5112 - mean_squared_error: 7.5112 - rmse: 2.7406 - mean_absolute_error: 2.1121\n",
      "Epoch 00002: val_loss did not improve from 5030200.00000\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 7.5112 - mean_squared_error: 7.5112 - rmse: 2.7406 - mean_absolute_error: 2.1121 - val_loss: 766792064.0000 - val_mean_squared_error: 766792064.0000 - val_rmse: 27691.0098 - val_mean_absolute_error: 27638.7227 - lr: 0.0100\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 9.3779 - mean_squared_error: 9.3779 - rmse: 3.0623 - mean_absolute_error: 2.5361  \n",
      "Epoch 00003: val_loss did not improve from 5030200.00000\n",
      "4/4 [==============================] - 1s 302ms/step - loss: 9.3779 - mean_squared_error: 9.3779 - rmse: 3.0623 - mean_absolute_error: 2.5361 - val_loss: 3134457856.0000 - val_mean_squared_error: 3134457856.0000 - val_rmse: 55986.2305 - val_mean_absolute_error: 55887.2305 - lr: 0.0100\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.5615 - mean_squared_error: 5.5615 - rmse: 2.3583 - mean_absolute_error: 1.8118\n",
      "Epoch 00004: val_loss did not improve from 5030200.00000\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 5.5615 - mean_squared_error: 5.5615 - rmse: 2.3583 - mean_absolute_error: 1.8118 - val_loss: 1588009344.0000 - val_mean_squared_error: 1588009344.0000 - val_rmse: 39849.8359 - val_mean_absolute_error: 39778.5664 - lr: 0.0100\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.6231 - mean_squared_error: 4.6231 - rmse: 2.1501 - mean_absolute_error: 1.6464\n",
      "Epoch 00005: val_loss did not improve from 5030200.00000\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 4.6231 - mean_squared_error: 4.6231 - rmse: 2.1501 - mean_absolute_error: 1.6464 - val_loss: 381794368.0000 - val_mean_squared_error: 381794368.0000 - val_rmse: 19539.5586 - val_mean_absolute_error: 19501.5781 - lr: 0.0100\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.8250 - mean_squared_error: 3.8250 - rmse: 1.9558 - mean_absolute_error: 1.5063\n",
      "Epoch 00006: val_loss did not improve from 5030200.00000\n",
      "4/4 [==============================] - 1s 296ms/step - loss: 3.8250 - mean_squared_error: 3.8250 - rmse: 1.9558 - mean_absolute_error: 1.5063 - val_loss: 170159568.0000 - val_mean_squared_error: 170159568.0000 - val_rmse: 13044.5225 - val_mean_absolute_error: 13016.3604 - lr: 0.0100\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.5517 - mean_squared_error: 3.5517 - rmse: 1.8846 - mean_absolute_error: 1.4870\n",
      "Epoch 00007: val_loss did not improve from 5030200.00000\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 3.5517 - mean_squared_error: 3.5517 - rmse: 1.8846 - mean_absolute_error: 1.4870 - val_loss: 82415160.0000 - val_mean_squared_error: 82415160.0000 - val_rmse: 9078.2793 - val_mean_absolute_error: 9056.3271 - lr: 0.0100\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.0113 - mean_squared_error: 3.0113 - rmse: 1.7353 - mean_absolute_error: 1.3500\n",
      "Epoch 00008: val_loss did not improve from 5030200.00000\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 3.0113 - mean_squared_error: 3.0113 - rmse: 1.7353 - mean_absolute_error: 1.3500 - val_loss: 30917460.0000 - val_mean_squared_error: 30917460.0000 - val_rmse: 5560.3472 - val_mean_absolute_error: 5544.9009 - lr: 0.0100\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.5353 - mean_squared_error: 2.5353 - rmse: 1.5923 - mean_absolute_error: 1.2327\n",
      "Epoch 00009: val_loss did not improve from 5030200.00000\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 2.5353 - mean_squared_error: 2.5353 - rmse: 1.5923 - mean_absolute_error: 1.2327 - val_loss: 7285078.0000 - val_mean_squared_error: 7285078.0000 - val_rmse: 2699.0884 - val_mean_absolute_error: 2690.6755 - lr: 0.0100\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.2226 - mean_squared_error: 2.2226 - rmse: 1.4908 - mean_absolute_error: 1.1565\n",
      "Epoch 00010: val_loss improved from 5030200.00000 to 2685270.25000, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 1s 331ms/step - loss: 2.2226 - mean_squared_error: 2.2226 - rmse: 1.4908 - mean_absolute_error: 1.1565 - val_loss: 2685270.2500 - val_mean_squared_error: 2685270.2500 - val_rmse: 1638.6794 - val_mean_absolute_error: 1633.0735 - lr: 0.0100\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9682 - mean_squared_error: 1.9682 - rmse: 1.4029 - mean_absolute_error: 1.0762\n",
      "Epoch 00011: val_loss improved from 2685270.25000 to 889697.56250, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 1s 326ms/step - loss: 1.9682 - mean_squared_error: 1.9682 - rmse: 1.4029 - mean_absolute_error: 1.0762 - val_loss: 889697.5625 - val_mean_squared_error: 889697.5625 - val_rmse: 943.2378 - val_mean_absolute_error: 939.8301 - lr: 0.0100\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0102 - mean_squared_error: 2.0102 - rmse: 1.4178 - mean_absolute_error: 1.0981\n",
      "Epoch 00012: val_loss improved from 889697.56250 to 562801.37500, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 1s 321ms/step - loss: 2.0102 - mean_squared_error: 2.0102 - rmse: 1.4178 - mean_absolute_error: 1.0981 - val_loss: 562801.3750 - val_mean_squared_error: 562801.3750 - val_rmse: 750.2009 - val_mean_absolute_error: 747.2231 - lr: 0.0100\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0005 - mean_squared_error: 2.0005 - rmse: 1.4144 - mean_absolute_error: 1.0732\n",
      "Epoch 00013: val_loss improved from 562801.37500 to 280333.90625, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 1s 339ms/step - loss: 2.0005 - mean_squared_error: 2.0005 - rmse: 1.4144 - mean_absolute_error: 1.0732 - val_loss: 280333.9062 - val_mean_squared_error: 280333.9062 - val_rmse: 529.4657 - val_mean_absolute_error: 527.0755 - lr: 0.0100\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8479 - mean_squared_error: 1.8479 - rmse: 1.3594 - mean_absolute_error: 1.0463\n",
      "Epoch 00014: val_loss improved from 280333.90625 to 98925.83594, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 1.8479 - mean_squared_error: 1.8479 - rmse: 1.3594 - mean_absolute_error: 1.0463 - val_loss: 98925.8359 - val_mean_squared_error: 98925.8359 - val_rmse: 314.5248 - val_mean_absolute_error: 312.8006 - lr: 0.0100\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7002 - mean_squared_error: 1.7002 - rmse: 1.3039 - mean_absolute_error: 1.0048\n",
      "Epoch 00015: val_loss improved from 98925.83594 to 46324.16406, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 1.7002 - mean_squared_error: 1.7002 - rmse: 1.3039 - mean_absolute_error: 1.0048 - val_loss: 46324.1641 - val_mean_squared_error: 46324.1641 - val_rmse: 215.2305 - val_mean_absolute_error: 213.9871 - lr: 0.0100\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4462 - mean_squared_error: 1.4462 - rmse: 1.2026 - mean_absolute_error: 0.9326\n",
      "Epoch 00016: val_loss improved from 46324.16406 to 25619.22656, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 1s 327ms/step - loss: 1.4462 - mean_squared_error: 1.4462 - rmse: 1.2026 - mean_absolute_error: 0.9326 - val_loss: 25619.2266 - val_mean_squared_error: 25619.2266 - val_rmse: 160.0601 - val_mean_absolute_error: 159.0513 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4425 - mean_squared_error: 1.4425 - rmse: 1.2010 - mean_absolute_error: 0.9133\n",
      "Epoch 00017: val_loss improved from 25619.22656 to 12702.78418, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 1s 333ms/step - loss: 1.4425 - mean_squared_error: 1.4425 - rmse: 1.2010 - mean_absolute_error: 0.9133 - val_loss: 12702.7842 - val_mean_squared_error: 12702.7842 - val_rmse: 112.7066 - val_mean_absolute_error: 111.9637 - lr: 0.0100\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3539 - mean_squared_error: 1.3539 - rmse: 1.1636 - mean_absolute_error: 0.9079\n",
      "Epoch 00018: val_loss improved from 12702.78418 to 2001.38525, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 1.3539 - mean_squared_error: 1.3539 - rmse: 1.1636 - mean_absolute_error: 0.9079 - val_loss: 2001.3853 - val_mean_squared_error: 2001.3853 - val_rmse: 44.7368 - val_mean_absolute_error: 44.3448 - lr: 0.0100\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1210 - mean_squared_error: 1.1210 - rmse: 1.0588 - mean_absolute_error: 0.8233\n",
      "Epoch 00019: val_loss did not improve from 2001.38525\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 1.1210 - mean_squared_error: 1.1210 - rmse: 1.0588 - mean_absolute_error: 0.8233 - val_loss: 3490.8508 - val_mean_squared_error: 3490.8508 - val_rmse: 59.0834 - val_mean_absolute_error: 58.6259 - lr: 0.0100\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3183 - mean_squared_error: 1.3183 - rmse: 1.1482 - mean_absolute_error: 0.8302\n",
      "Epoch 00020: val_loss did not improve from 2001.38525\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 1.3183 - mean_squared_error: 1.3183 - rmse: 1.1482 - mean_absolute_error: 0.8302 - val_loss: 3935.1458 - val_mean_squared_error: 3935.1458 - val_rmse: 62.7307 - val_mean_absolute_error: 62.2321 - lr: 0.0100\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3434 - mean_squared_error: 1.3434 - rmse: 1.1590 - mean_absolute_error: 0.8721\n",
      "Epoch 00021: val_loss improved from 2001.38525 to 1497.15491, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 1.3434 - mean_squared_error: 1.3434 - rmse: 1.1590 - mean_absolute_error: 0.8721 - val_loss: 1497.1549 - val_mean_squared_error: 1497.1549 - val_rmse: 38.6931 - val_mean_absolute_error: 38.2096 - lr: 0.0100\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1546 - mean_squared_error: 1.1546 - rmse: 1.0745 - mean_absolute_error: 0.8500\n",
      "Epoch 00022: val_loss improved from 1497.15491 to 661.95288, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 1.1546 - mean_squared_error: 1.1546 - rmse: 1.0745 - mean_absolute_error: 0.8500 - val_loss: 661.9529 - val_mean_squared_error: 661.9529 - val_rmse: 25.7284 - val_mean_absolute_error: 25.3320 - lr: 0.0100\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1113 - mean_squared_error: 1.1113 - rmse: 1.0542 - mean_absolute_error: 0.7901\n",
      "Epoch 00023: val_loss improved from 661.95288 to 111.14220, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 1s 325ms/step - loss: 1.1113 - mean_squared_error: 1.1113 - rmse: 1.0542 - mean_absolute_error: 0.7901 - val_loss: 111.1422 - val_mean_squared_error: 111.1422 - val_rmse: 10.5424 - val_mean_absolute_error: 10.0468 - lr: 0.0100\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1425 - mean_squared_error: 1.1425 - rmse: 1.0689 - mean_absolute_error: 0.7977\n",
      "Epoch 00024: val_loss improved from 111.14220 to 42.62692, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 1s 328ms/step - loss: 1.1425 - mean_squared_error: 1.1425 - rmse: 1.0689 - mean_absolute_error: 0.7977 - val_loss: 42.6269 - val_mean_squared_error: 42.6269 - val_rmse: 6.5289 - val_mean_absolute_error: 5.8612 - lr: 0.0100\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1097 - mean_squared_error: 1.1097 - rmse: 1.0534 - mean_absolute_error: 0.7642\n",
      "Epoch 00025: val_loss did not improve from 42.62692\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 1.1097 - mean_squared_error: 1.1097 - rmse: 1.0534 - mean_absolute_error: 0.7642 - val_loss: 84.5152 - val_mean_squared_error: 84.5152 - val_rmse: 9.1932 - val_mean_absolute_error: 8.6298 - lr: 0.0100\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8181 - mean_squared_error: 0.8181 - rmse: 0.9045 - mean_absolute_error: 0.6770\n",
      "Epoch 00026: val_loss did not improve from 42.62692\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 0.8181 - mean_squared_error: 0.8181 - rmse: 0.9045 - mean_absolute_error: 0.6770 - val_loss: 55.0917 - val_mean_squared_error: 55.0917 - val_rmse: 7.4224 - val_mean_absolute_error: 6.7899 - lr: 0.0100\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7099 - mean_squared_error: 0.7099 - rmse: 0.8426 - mean_absolute_error: 0.6415\n",
      "Epoch 00027: val_loss improved from 42.62692 to 10.64977, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 1s 325ms/step - loss: 0.7099 - mean_squared_error: 0.7099 - rmse: 0.8426 - mean_absolute_error: 0.6415 - val_loss: 10.6498 - val_mean_squared_error: 10.6498 - val_rmse: 3.2634 - val_mean_absolute_error: 2.8474 - lr: 0.0100\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6754 - mean_squared_error: 0.6754 - rmse: 0.8218 - mean_absolute_error: 0.6294\n",
      "Epoch 00028: val_loss did not improve from 10.64977\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 0.6754 - mean_squared_error: 0.6754 - rmse: 0.8218 - mean_absolute_error: 0.6294 - val_loss: 11.9432 - val_mean_squared_error: 11.9432 - val_rmse: 3.4559 - val_mean_absolute_error: 2.9475 - lr: 0.0100\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7355 - mean_squared_error: 0.7355 - rmse: 0.8576 - mean_absolute_error: 0.6281\n",
      "Epoch 00029: val_loss did not improve from 10.64977\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 0.7355 - mean_squared_error: 0.7355 - rmse: 0.8576 - mean_absolute_error: 0.6281 - val_loss: 31.6230 - val_mean_squared_error: 31.6230 - val_rmse: 5.6234 - val_mean_absolute_error: 4.9170 - lr: 0.0100\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6380 - mean_squared_error: 0.6380 - rmse: 0.7987 - mean_absolute_error: 0.5814\n",
      "Epoch 00030: val_loss did not improve from 10.64977\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.6380 - mean_squared_error: 0.6380 - rmse: 0.7987 - mean_absolute_error: 0.5814 - val_loss: 15.2196 - val_mean_squared_error: 15.2196 - val_rmse: 3.9012 - val_mean_absolute_error: 3.3845 - lr: 0.0100\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6256 - mean_squared_error: 0.6256 - rmse: 0.7910 - mean_absolute_error: 0.5997\n",
      "Epoch 00031: val_loss did not improve from 10.64977\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 0.6256 - mean_squared_error: 0.6256 - rmse: 0.7910 - mean_absolute_error: 0.5997 - val_loss: 18.4796 - val_mean_squared_error: 18.4796 - val_rmse: 4.2988 - val_mean_absolute_error: 3.6472 - lr: 0.0100\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4803 - mean_squared_error: 0.4803 - rmse: 0.6930 - mean_absolute_error: 0.5431\n",
      "Epoch 00032: val_loss did not improve from 10.64977\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 0.4803 - mean_squared_error: 0.4803 - rmse: 0.6930 - mean_absolute_error: 0.5431 - val_loss: 13.3107 - val_mean_squared_error: 13.3107 - val_rmse: 3.6484 - val_mean_absolute_error: 3.2151 - lr: 0.0100\n",
      "Epoch 33/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - ETA: 0s - loss: 0.4874 - mean_squared_error: 0.4874 - rmse: 0.6982 - mean_absolute_error: 0.5281\n",
      "Epoch 00033: val_loss did not improve from 10.64977\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 0.4874 - mean_squared_error: 0.4874 - rmse: 0.6982 - mean_absolute_error: 0.5281 - val_loss: 16.6446 - val_mean_squared_error: 16.6446 - val_rmse: 4.0798 - val_mean_absolute_error: 3.5142 - lr: 0.0100\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4417 - mean_squared_error: 0.4417 - rmse: 0.6646 - mean_absolute_error: 0.4610\n",
      "Epoch 00034: val_loss did not improve from 10.64977\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 0.4417 - mean_squared_error: 0.4417 - rmse: 0.6646 - mean_absolute_error: 0.4610 - val_loss: 16.5150 - val_mean_squared_error: 16.5150 - val_rmse: 4.0639 - val_mean_absolute_error: 3.4923 - lr: 0.0100\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4556 - mean_squared_error: 0.4556 - rmse: 0.6750 - mean_absolute_error: 0.5301\n",
      "Epoch 00035: val_loss did not improve from 10.64977\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 0.4556 - mean_squared_error: 0.4556 - rmse: 0.6750 - mean_absolute_error: 0.5301 - val_loss: 25.7522 - val_mean_squared_error: 25.7522 - val_rmse: 5.0747 - val_mean_absolute_error: 4.3408 - lr: 0.0100\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5847 - mean_squared_error: 0.5847 - rmse: 0.7647 - mean_absolute_error: 0.5865\n",
      "Epoch 00036: val_loss did not improve from 10.64977\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 0.5847 - mean_squared_error: 0.5847 - rmse: 0.7647 - mean_absolute_error: 0.5865 - val_loss: 20.3126 - val_mean_squared_error: 20.3126 - val_rmse: 4.5069 - val_mean_absolute_error: 3.5435 - lr: 0.0100\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4436 - mean_squared_error: 0.4436 - rmse: 0.6661 - mean_absolute_error: 0.5188\n",
      "Epoch 00037: val_loss did not improve from 10.64977\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 0.4436 - mean_squared_error: 0.4436 - rmse: 0.6661 - mean_absolute_error: 0.5188 - val_loss: 17.1561 - val_mean_squared_error: 17.1561 - val_rmse: 4.1420 - val_mean_absolute_error: 3.2796 - lr: 0.0100\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5185 - mean_squared_error: 0.5185 - rmse: 0.7201 - mean_absolute_error: 0.5480\n",
      "Epoch 00038: val_loss did not improve from 10.64977\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 0.5185 - mean_squared_error: 0.5185 - rmse: 0.7201 - mean_absolute_error: 0.5480 - val_loss: 20.6230 - val_mean_squared_error: 20.6230 - val_rmse: 4.5413 - val_mean_absolute_error: 3.7672 - lr: 0.0100\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4450 - mean_squared_error: 0.4450 - rmse: 0.6671 - mean_absolute_error: 0.5299\n",
      "Epoch 00039: val_loss did not improve from 10.64977\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 0.4450 - mean_squared_error: 0.4450 - rmse: 0.6671 - mean_absolute_error: 0.5299 - val_loss: 25.8127 - val_mean_squared_error: 25.8127 - val_rmse: 5.0806 - val_mean_absolute_error: 4.3440 - lr: 0.0100\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4978 - mean_squared_error: 0.4978 - rmse: 0.7055 - mean_absolute_error: 0.5596\n",
      "Epoch 00040: val_loss did not improve from 10.64977\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 0.4978 - mean_squared_error: 0.4978 - rmse: 0.7055 - mean_absolute_error: 0.5596 - val_loss: 18.9662 - val_mean_squared_error: 18.9662 - val_rmse: 4.3550 - val_mean_absolute_error: 3.6183 - lr: 0.0100\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3666 - mean_squared_error: 0.3666 - rmse: 0.6055 - mean_absolute_error: 0.4692\n",
      "Epoch 00041: val_loss did not improve from 10.64977\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 0.3666 - mean_squared_error: 0.3666 - rmse: 0.6055 - mean_absolute_error: 0.4692 - val_loss: 17.7040 - val_mean_squared_error: 17.7040 - val_rmse: 4.2076 - val_mean_absolute_error: 3.2350 - lr: 0.0100\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7179 - mean_squared_error: 0.7179 - rmse: 0.8473 - mean_absolute_error: 0.6334\n",
      "Epoch 00042: val_loss did not improve from 10.64977\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 0.7179 - mean_squared_error: 0.7179 - rmse: 0.8473 - mean_absolute_error: 0.6334 - val_loss: 21.8280 - val_mean_squared_error: 21.8280 - val_rmse: 4.6720 - val_mean_absolute_error: 3.5074 - lr: 0.0100\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9690 - mean_squared_error: 0.9690 - rmse: 0.9844 - mean_absolute_error: 0.7838\n",
      "Epoch 00043: val_loss did not improve from 10.64977\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 0.9690 - mean_squared_error: 0.9690 - rmse: 0.9844 - mean_absolute_error: 0.7838 - val_loss: 36.3859 - val_mean_squared_error: 36.3859 - val_rmse: 6.0321 - val_mean_absolute_error: 5.1797 - lr: 0.0100\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2086 - mean_squared_error: 1.2086 - rmse: 1.0994 - mean_absolute_error: 0.7617\n",
      "Epoch 00044: val_loss did not improve from 10.64977\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 1.2086 - mean_squared_error: 1.2086 - rmse: 1.0994 - mean_absolute_error: 0.7617 - val_loss: 16.9457 - val_mean_squared_error: 16.9457 - val_rmse: 4.1165 - val_mean_absolute_error: 3.2728 - lr: 0.0100\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9258 - mean_squared_error: 0.9258 - rmse: 0.9622 - mean_absolute_error: 0.6688\n",
      "Epoch 00045: val_loss improved from 10.64977 to 10.20870, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 1s 333ms/step - loss: 0.9258 - mean_squared_error: 0.9258 - rmse: 0.9622 - mean_absolute_error: 0.6688 - val_loss: 10.2087 - val_mean_squared_error: 10.2087 - val_rmse: 3.1951 - val_mean_absolute_error: 2.6841 - lr: 0.0100\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7381 - mean_squared_error: 0.7381 - rmse: 0.8592 - mean_absolute_error: 0.6584\n",
      "Epoch 00046: val_loss did not improve from 10.20870\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 0.7381 - mean_squared_error: 0.7381 - rmse: 0.8592 - mean_absolute_error: 0.6584 - val_loss: 21.2087 - val_mean_squared_error: 21.2087 - val_rmse: 4.6053 - val_mean_absolute_error: 3.5797 - lr: 0.0100\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6615 - mean_squared_error: 0.6615 - rmse: 0.8133 - mean_absolute_error: 0.6159\n",
      "Epoch 00047: val_loss did not improve from 10.20870\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 0.6615 - mean_squared_error: 0.6615 - rmse: 0.8133 - mean_absolute_error: 0.6159 - val_loss: 20.2550 - val_mean_squared_error: 20.2550 - val_rmse: 4.5006 - val_mean_absolute_error: 3.3847 - lr: 0.0100\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5570 - mean_squared_error: 0.5570 - rmse: 0.7463 - mean_absolute_error: 0.5747\n",
      "Epoch 00048: val_loss did not improve from 10.20870\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 0.5570 - mean_squared_error: 0.5570 - rmse: 0.7463 - mean_absolute_error: 0.5747 - val_loss: 30.9594 - val_mean_squared_error: 30.9594 - val_rmse: 5.5641 - val_mean_absolute_error: 4.2110 - lr: 0.0100\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7986 - mean_squared_error: 0.7986 - rmse: 0.8936 - mean_absolute_error: 0.6728\n",
      "Epoch 00049: val_loss did not improve from 10.20870\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 0.7986 - mean_squared_error: 0.7986 - rmse: 0.8936 - mean_absolute_error: 0.6728 - val_loss: 17.2485 - val_mean_squared_error: 17.2485 - val_rmse: 4.1531 - val_mean_absolute_error: 3.3034 - lr: 0.0100\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5520 - mean_squared_error: 0.5520 - rmse: 0.7429 - mean_absolute_error: 0.5687\n",
      "Epoch 00050: val_loss did not improve from 10.20870\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 0.5520 - mean_squared_error: 0.5520 - rmse: 0.7429 - mean_absolute_error: 0.5687 - val_loss: 23.2242 - val_mean_squared_error: 23.2242 - val_rmse: 4.8191 - val_mean_absolute_error: 3.6480 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5081 - mean_squared_error: 0.5081 - rmse: 0.7128 - mean_absolute_error: 0.5519\n",
      "Epoch 00051: val_loss did not improve from 10.20870\n",
      "4/4 [==============================] - 1s 344ms/step - loss: 0.5081 - mean_squared_error: 0.5081 - rmse: 0.7128 - mean_absolute_error: 0.5519 - val_loss: 15.3720 - val_mean_squared_error: 15.3720 - val_rmse: 3.9207 - val_mean_absolute_error: 3.3226 - lr: 0.0100\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3996 - mean_squared_error: 0.3996 - rmse: 0.6322 - mean_absolute_error: 0.4954\n",
      "Epoch 00052: val_loss did not improve from 10.20870\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 0.3996 - mean_squared_error: 0.3996 - rmse: 0.6322 - mean_absolute_error: 0.4954 - val_loss: 18.4673 - val_mean_squared_error: 18.4673 - val_rmse: 4.2974 - val_mean_absolute_error: 3.7201 - lr: 0.0100\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6581 - mean_squared_error: 0.6581 - rmse: 0.8112 - mean_absolute_error: 0.6488\n",
      "Epoch 00053: val_loss improved from 10.20870 to 9.52952, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 1s 329ms/step - loss: 0.6581 - mean_squared_error: 0.6581 - rmse: 0.8112 - mean_absolute_error: 0.6488 - val_loss: 9.5295 - val_mean_squared_error: 9.5295 - val_rmse: 3.0870 - val_mean_absolute_error: 2.6030 - lr: 0.0100\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3083 - mean_squared_error: 0.3083 - rmse: 0.5552 - mean_absolute_error: 0.4207\n",
      "Epoch 00054: val_loss did not improve from 9.52952\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 0.3083 - mean_squared_error: 0.3083 - rmse: 0.5552 - mean_absolute_error: 0.4207 - val_loss: 10.6712 - val_mean_squared_error: 10.6712 - val_rmse: 3.2667 - val_mean_absolute_error: 2.7754 - lr: 0.0100\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2519 - mean_squared_error: 0.2519 - rmse: 0.5019 - mean_absolute_error: 0.3975\n",
      "Epoch 00055: val_loss did not improve from 9.52952\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 0.2519 - mean_squared_error: 0.2519 - rmse: 0.5019 - mean_absolute_error: 0.3975 - val_loss: 14.8465 - val_mean_squared_error: 14.8465 - val_rmse: 3.8531 - val_mean_absolute_error: 3.2790 - lr: 0.0100\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3427 - mean_squared_error: 0.3427 - rmse: 0.5854 - mean_absolute_error: 0.4570\n",
      "Epoch 00056: val_loss did not improve from 9.52952\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 0.3427 - mean_squared_error: 0.3427 - rmse: 0.5854 - mean_absolute_error: 0.4570 - val_loss: 18.8213 - val_mean_squared_error: 18.8213 - val_rmse: 4.3384 - val_mean_absolute_error: 3.7348 - lr: 0.0100\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3333 - mean_squared_error: 0.3333 - rmse: 0.5773 - mean_absolute_error: 0.4524\n",
      "Epoch 00057: val_loss did not improve from 9.52952\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 0.3333 - mean_squared_error: 0.3333 - rmse: 0.5773 - mean_absolute_error: 0.4524 - val_loss: 13.7453 - val_mean_squared_error: 13.7453 - val_rmse: 3.7075 - val_mean_absolute_error: 3.1374 - lr: 0.0100\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2415 - mean_squared_error: 0.2415 - rmse: 0.4914 - mean_absolute_error: 0.3897\n",
      "Epoch 00058: val_loss did not improve from 9.52952\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.2415 - mean_squared_error: 0.2415 - rmse: 0.4914 - mean_absolute_error: 0.3897 - val_loss: 11.1365 - val_mean_squared_error: 11.1365 - val_rmse: 3.3371 - val_mean_absolute_error: 2.7989 - lr: 0.0100\n",
      "Epoch 59/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2315 - mean_squared_error: 0.2315 - rmse: 0.4812 - mean_absolute_error: 0.3508\n",
      "Epoch 00059: val_loss did not improve from 9.52952\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 0.2315 - mean_squared_error: 0.2315 - rmse: 0.4812 - mean_absolute_error: 0.3508 - val_loss: 13.2661 - val_mean_squared_error: 13.2661 - val_rmse: 3.6423 - val_mean_absolute_error: 3.0183 - lr: 0.0100\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2478 - mean_squared_error: 0.2478 - rmse: 0.4978 - mean_absolute_error: 0.3781\n",
      "Epoch 00060: val_loss did not improve from 9.52952\n",
      "4/4 [==============================] - 1s 321ms/step - loss: 0.2478 - mean_squared_error: 0.2478 - rmse: 0.4978 - mean_absolute_error: 0.3781 - val_loss: 12.2718 - val_mean_squared_error: 12.2718 - val_rmse: 3.5031 - val_mean_absolute_error: 2.8293 - lr: 0.0100\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1680 - mean_squared_error: 0.1680 - rmse: 0.4099 - mean_absolute_error: 0.3020\n",
      "Epoch 00061: val_loss did not improve from 9.52952\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 0.1680 - mean_squared_error: 0.1680 - rmse: 0.4099 - mean_absolute_error: 0.3020 - val_loss: 10.6312 - val_mean_squared_error: 10.6312 - val_rmse: 3.2605 - val_mean_absolute_error: 2.6397 - lr: 0.0100\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2267 - mean_squared_error: 0.2267 - rmse: 0.4762 - mean_absolute_error: 0.3768\n",
      "Epoch 00062: val_loss did not improve from 9.52952\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 0.2267 - mean_squared_error: 0.2267 - rmse: 0.4762 - mean_absolute_error: 0.3768 - val_loss: 9.9155 - val_mean_squared_error: 9.9155 - val_rmse: 3.1489 - val_mean_absolute_error: 2.6783 - lr: 0.0100\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1824 - mean_squared_error: 0.1824 - rmse: 0.4270 - mean_absolute_error: 0.3010\n",
      "Epoch 00063: val_loss did not improve from 9.52952\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 0.1824 - mean_squared_error: 0.1824 - rmse: 0.4270 - mean_absolute_error: 0.3010 - val_loss: 13.5856 - val_mean_squared_error: 13.5856 - val_rmse: 3.6859 - val_mean_absolute_error: 2.7822 - lr: 0.0100\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3462 - mean_squared_error: 0.3462 - rmse: 0.5884 - mean_absolute_error: 0.4347\n",
      "Epoch 00064: val_loss improved from 9.52952 to 8.07373, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 1s 336ms/step - loss: 0.3462 - mean_squared_error: 0.3462 - rmse: 0.5884 - mean_absolute_error: 0.4347 - val_loss: 8.0737 - val_mean_squared_error: 8.0737 - val_rmse: 2.8414 - val_mean_absolute_error: 2.3338 - lr: 0.0100\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2775 - mean_squared_error: 0.2775 - rmse: 0.5268 - mean_absolute_error: 0.4020\n",
      "Epoch 00065: val_loss did not improve from 8.07373\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 0.2775 - mean_squared_error: 0.2775 - rmse: 0.5268 - mean_absolute_error: 0.4020 - val_loss: 12.0186 - val_mean_squared_error: 12.0186 - val_rmse: 3.4668 - val_mean_absolute_error: 2.7887 - lr: 0.0100\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1421 - mean_squared_error: 0.1421 - rmse: 0.3769 - mean_absolute_error: 0.2806\n",
      "Epoch 00066: val_loss did not improve from 8.07373\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 0.1421 - mean_squared_error: 0.1421 - rmse: 0.3769 - mean_absolute_error: 0.2806 - val_loss: 10.2598 - val_mean_squared_error: 10.2598 - val_rmse: 3.2031 - val_mean_absolute_error: 2.7608 - lr: 0.0100\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1309 - mean_squared_error: 0.1309 - rmse: 0.3617 - mean_absolute_error: 0.2845\n",
      "Epoch 00067: val_loss did not improve from 8.07373\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 0.1309 - mean_squared_error: 0.1309 - rmse: 0.3617 - mean_absolute_error: 0.2845 - val_loss: 15.4192 - val_mean_squared_error: 15.4192 - val_rmse: 3.9267 - val_mean_absolute_error: 2.8550 - lr: 0.0100\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1397 - mean_squared_error: 0.1397 - rmse: 0.3738 - mean_absolute_error: 0.2833\n",
      "Epoch 00068: val_loss did not improve from 8.07373\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.1397 - mean_squared_error: 0.1397 - rmse: 0.3738 - mean_absolute_error: 0.2833 - val_loss: 9.1716 - val_mean_squared_error: 9.1716 - val_rmse: 3.0285 - val_mean_absolute_error: 2.3333 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1644 - mean_squared_error: 0.1644 - rmse: 0.4055 - mean_absolute_error: 0.3235\n",
      "Epoch 00069: val_loss did not improve from 8.07373\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 0.1644 - mean_squared_error: 0.1644 - rmse: 0.4055 - mean_absolute_error: 0.3235 - val_loss: 9.0894 - val_mean_squared_error: 9.0894 - val_rmse: 3.0149 - val_mean_absolute_error: 2.3670 - lr: 0.0100\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1979 - mean_squared_error: 0.1979 - rmse: 0.4448 - mean_absolute_error: 0.3559\n",
      "Epoch 00070: val_loss did not improve from 8.07373\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 0.1979 - mean_squared_error: 0.1979 - rmse: 0.4448 - mean_absolute_error: 0.3559 - val_loss: 10.9797 - val_mean_squared_error: 10.9797 - val_rmse: 3.3136 - val_mean_absolute_error: 2.5123 - lr: 0.0100\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1825 - mean_squared_error: 0.1825 - rmse: 0.4272 - mean_absolute_error: 0.3377\n",
      "Epoch 00071: val_loss did not improve from 8.07373\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.1825 - mean_squared_error: 0.1825 - rmse: 0.4272 - mean_absolute_error: 0.3377 - val_loss: 10.1473 - val_mean_squared_error: 10.1473 - val_rmse: 3.1855 - val_mean_absolute_error: 2.3892 - lr: 0.0100\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2666 - mean_squared_error: 0.2666 - rmse: 0.5163 - mean_absolute_error: 0.3982\n",
      "Epoch 00072: val_loss did not improve from 8.07373\n",
      "4/4 [==============================] - 1s 321ms/step - loss: 0.2666 - mean_squared_error: 0.2666 - rmse: 0.5163 - mean_absolute_error: 0.3982 - val_loss: 8.2255 - val_mean_squared_error: 8.2255 - val_rmse: 2.8680 - val_mean_absolute_error: 2.3137 - lr: 0.0100\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2930 - mean_squared_error: 0.2930 - rmse: 0.5413 - mean_absolute_error: 0.4522\n",
      "Epoch 00073: val_loss did not improve from 8.07373\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 0.2930 - mean_squared_error: 0.2930 - rmse: 0.5413 - mean_absolute_error: 0.4522 - val_loss: 10.2723 - val_mean_squared_error: 10.2723 - val_rmse: 3.2050 - val_mean_absolute_error: 2.4739 - lr: 0.0100\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1184 - mean_squared_error: 0.1184 - rmse: 0.3440 - mean_absolute_error: 0.2818\n",
      "Epoch 00074: val_loss did not improve from 8.07373\n",
      "4/4 [==============================] - 1s 316ms/step - loss: 0.1184 - mean_squared_error: 0.1184 - rmse: 0.3440 - mean_absolute_error: 0.2818 - val_loss: 12.6146 - val_mean_squared_error: 12.6146 - val_rmse: 3.5517 - val_mean_absolute_error: 2.6466 - lr: 0.0100\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1528 - mean_squared_error: 0.1528 - rmse: 0.3909 - mean_absolute_error: 0.3019\n",
      "Epoch 00075: val_loss did not improve from 8.07373\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 0.1528 - mean_squared_error: 0.1528 - rmse: 0.3909 - mean_absolute_error: 0.3019 - val_loss: 8.1310 - val_mean_squared_error: 8.1310 - val_rmse: 2.8515 - val_mean_absolute_error: 2.3093 - lr: 0.0100\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1594 - mean_squared_error: 0.1594 - rmse: 0.3992 - mean_absolute_error: 0.3246\n",
      "Epoch 00076: val_loss did not improve from 8.07373\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.1594 - mean_squared_error: 0.1594 - rmse: 0.3992 - mean_absolute_error: 0.3246 - val_loss: 8.3808 - val_mean_squared_error: 8.3808 - val_rmse: 2.8950 - val_mean_absolute_error: 2.2208 - lr: 0.0100\n",
      "Epoch 77/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2790 - mean_squared_error: 0.2790 - rmse: 0.5282 - mean_absolute_error: 0.4455\n",
      "Epoch 00077: val_loss did not improve from 8.07373\n",
      "4/4 [==============================] - 1s 312ms/step - loss: 0.2790 - mean_squared_error: 0.2790 - rmse: 0.5282 - mean_absolute_error: 0.4455 - val_loss: 11.2775 - val_mean_squared_error: 11.2775 - val_rmse: 3.3582 - val_mean_absolute_error: 2.5246 - lr: 0.0100\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1906 - mean_squared_error: 0.1906 - rmse: 0.4365 - mean_absolute_error: 0.3394\n",
      "Epoch 00078: val_loss did not improve from 8.07373\n",
      "4/4 [==============================] - 1s 313ms/step - loss: 0.1906 - mean_squared_error: 0.1906 - rmse: 0.4365 - mean_absolute_error: 0.3394 - val_loss: 8.1794 - val_mean_squared_error: 8.1794 - val_rmse: 2.8600 - val_mean_absolute_error: 2.2077 - lr: 0.0100\n",
      "Epoch 79/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4735 - mean_squared_error: 0.4735 - rmse: 0.6881 - mean_absolute_error: 0.5542\n",
      "Epoch 00079: val_loss did not improve from 8.07373\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 0.4735 - mean_squared_error: 0.4735 - rmse: 0.6881 - mean_absolute_error: 0.5542 - val_loss: 14.8449 - val_mean_squared_error: 14.8449 - val_rmse: 3.8529 - val_mean_absolute_error: 2.8509 - lr: 0.0100\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2024 - mean_squared_error: 0.2024 - rmse: 0.4499 - mean_absolute_error: 0.3477\n",
      "Epoch 00080: val_loss did not improve from 8.07373\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 0.2024 - mean_squared_error: 0.2024 - rmse: 0.4499 - mean_absolute_error: 0.3477 - val_loss: 13.3810 - val_mean_squared_error: 13.3810 - val_rmse: 3.6580 - val_mean_absolute_error: 3.1198 - lr: 0.0100\n",
      "Epoch 81/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2353 - mean_squared_error: 0.2353 - rmse: 0.4851 - mean_absolute_error: 0.3819\n",
      "Epoch 00081: val_loss did not improve from 8.07373\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 0.2353 - mean_squared_error: 0.2353 - rmse: 0.4851 - mean_absolute_error: 0.3819 - val_loss: 10.8989 - val_mean_squared_error: 10.8989 - val_rmse: 3.3013 - val_mean_absolute_error: 2.8046 - lr: 0.0100\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3545 - mean_squared_error: 0.3545 - rmse: 0.5954 - mean_absolute_error: 0.4412\n",
      "Epoch 00082: val_loss improved from 8.07373 to 7.84815, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 1s 328ms/step - loss: 0.3545 - mean_squared_error: 0.3545 - rmse: 0.5954 - mean_absolute_error: 0.4412 - val_loss: 7.8481 - val_mean_squared_error: 7.8481 - val_rmse: 2.8015 - val_mean_absolute_error: 2.3998 - lr: 0.0100\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4585 - mean_squared_error: 0.4585 - rmse: 0.6771 - mean_absolute_error: 0.5041\n",
      "Epoch 00083: val_loss did not improve from 7.84815\n",
      "4/4 [==============================] - 1s 331ms/step - loss: 0.4585 - mean_squared_error: 0.4585 - rmse: 0.6771 - mean_absolute_error: 0.5041 - val_loss: 12.2237 - val_mean_squared_error: 12.2237 - val_rmse: 3.4962 - val_mean_absolute_error: 2.5418 - lr: 0.0100\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3283 - mean_squared_error: 0.3283 - rmse: 0.5730 - mean_absolute_error: 0.4160\n",
      "Epoch 00084: val_loss improved from 7.84815 to 7.57853, saving model to /var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/tmpwn9zw07d.h5\n",
      "4/4 [==============================] - 2s 393ms/step - loss: 0.3283 - mean_squared_error: 0.3283 - rmse: 0.5730 - mean_absolute_error: 0.4160 - val_loss: 7.5785 - val_mean_squared_error: 7.5785 - val_rmse: 2.7529 - val_mean_absolute_error: 2.2691 - lr: 0.0100\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3105 - mean_squared_error: 0.3105 - rmse: 0.5573 - mean_absolute_error: 0.4227\n",
      "Epoch 00085: val_loss did not improve from 7.57853\n",
      "4/4 [==============================] - 2s 384ms/step - loss: 0.3105 - mean_squared_error: 0.3105 - rmse: 0.5573 - mean_absolute_error: 0.4227 - val_loss: 10.6568 - val_mean_squared_error: 10.6568 - val_rmse: 3.2645 - val_mean_absolute_error: 2.6893 - lr: 0.0100\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3103 - mean_squared_error: 0.3103 - rmse: 0.5571 - mean_absolute_error: 0.4393\n",
      "Epoch 00086: val_loss did not improve from 7.57853\n",
      "4/4 [==============================] - 1s 368ms/step - loss: 0.3103 - mean_squared_error: 0.3103 - rmse: 0.5571 - mean_absolute_error: 0.4393 - val_loss: 10.2636 - val_mean_squared_error: 10.2636 - val_rmse: 3.2037 - val_mean_absolute_error: 2.4361 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2057 - mean_squared_error: 0.2057 - rmse: 0.4536 - mean_absolute_error: 0.3556\n",
      "Epoch 00087: val_loss did not improve from 7.57853\n",
      "4/4 [==============================] - 1s 339ms/step - loss: 0.2057 - mean_squared_error: 0.2057 - rmse: 0.4536 - mean_absolute_error: 0.3556 - val_loss: 9.2748 - val_mean_squared_error: 9.2748 - val_rmse: 3.0455 - val_mean_absolute_error: 2.3264 - lr: 0.0100\n",
      "Epoch 88/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4103 - mean_squared_error: 0.4103 - rmse: 0.6406 - mean_absolute_error: 0.5233"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/ipykernel_63993/2092516319.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_resnet1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_site\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_resnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cnn_resnet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_resnet2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_site\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_resnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cnn_resnet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_resnet3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_site\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_resnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cnn_resnet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_resnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_resnet1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_resnet2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_resnet3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/c_/8lvtjqcn13jcbbdq_sx7f7sr0000gn/T/ipykernel_63993/3091971557.py\u001b[0m in \u001b[0;36mcross_site\u001b[0;34m(model_name, name_str, lr, site_1, site_2, site_3, X, y)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mlog1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCSVLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_str\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mcallbacks1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     model1.fit(X_train1, y_train1, epochs=n_epochs, batch_size=128,\n\u001b[0m\u001b[1;32m     42\u001b[0m                validation_split=0.2, callbacks=callbacks1)\n\u001b[1;32m     43\u001b[0m     \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_filepath1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/afq-deep-learning/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/afq-deep-learning/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/afq-deep-learning/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/afq-deep-learning/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/afq-deep-learning/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/afq-deep-learning/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/afq-deep-learning/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/anaconda3/envs/afq-deep-learning/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/afq-deep-learning/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_resnet1 = cross_site(cnn_resnet, 'cnn_resnet', 0.01, 0, 3, 4, X, y)\n",
    "df_resnet2 = cross_site(cnn_resnet, 'cnn_resnet', 0.01, 3, 0, 4, X, y)\n",
    "df_resnet3 = cross_site(cnn_resnet, 'cnn_resnet', 0.01, 4, 0, 3, X, y)\n",
    "df_resnet = (df_resnet1.merge(df_resnet2, how='outer')).merge(df_resnet3, how='outer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
