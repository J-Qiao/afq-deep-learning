{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f8734f6",
   "metadata": {
    "gather": {
     "logged": 1652212959976
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import afqinsight.nn.tf_models as nn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from afqinsight.datasets import AFQDataset\n",
    "from afqinsight.nn.tf_models import cnn_lenet, mlp4, cnn_vgg, lstm1v0, lstm1, lstm2, blstm1, blstm2, lstm_fcn, cnn_resnet\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os.path\n",
    "# Harmonization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from neurocombat_sklearn import CombatModel\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle, resample\n",
    "from afqinsight.augmentation import jitter, time_warp, scaling\n",
    "import tempfile\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0eccb79",
   "metadata": {
    "gather": {
     "logged": 1652212986960
    }
   },
   "outputs": [],
   "source": [
    "afq_dataset = AFQDataset.from_files(\n",
    "    fn_nodes=\"../data/raw/combined_tract_profiles.csv\",\n",
    "    fn_subjects=\"../data/raw/participants_updated_id.csv\",\n",
    "    dwi_metrics=[\"dki_fa\", \"dki_md\", \"dki_mk\"],\n",
    "    index_col=\"subject_id\",\n",
    "    target_cols=[\"age\", \"dl_qc_score\", \"scan_site_id\"],\n",
    "    label_encode_cols=[\"scan_site_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fc97db2",
   "metadata": {
    "gather": {
     "logged": 1652212987198
    }
   },
   "outputs": [],
   "source": [
    "afq_dataset.drop_target_na()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d47ebb60",
   "metadata": {
    "gather": {
     "logged": 1652212987403
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1865\n",
      "(1865, 7200)\n",
      "(1865, 3)\n"
     ]
    }
   ],
   "source": [
    "print(len(afq_dataset.subjects))\n",
    "print(afq_dataset.X.shape)\n",
    "print(afq_dataset.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c366051",
   "metadata": {
    "gather": {
     "logged": 1652212988137
    }
   },
   "outputs": [],
   "source": [
    "full_dataset = list(afq_dataset.as_tensorflow_dataset().as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d75581",
   "metadata": {
    "gather": {
     "logged": 1652212988321
    }
   },
   "outputs": [],
   "source": [
    "X = np.concatenate([xx[0][None] for xx in full_dataset], 0)\n",
    "y = np.array([yy[1][0] for yy in full_dataset])\n",
    "qc = np.array([yy[1][1] for yy in full_dataset])\n",
    "site = np.array([yy[1][2] for yy in full_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "623180c2",
   "metadata": {
    "gather": {
     "logged": 1652212988490
    }
   },
   "outputs": [],
   "source": [
    "X = X[qc>0]\n",
    "y = y[qc>0]\n",
    "site = site[qc>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86789a05-6d17-4c98-8604-b515c9c8a1dc",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1652212988730
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1817, 100, 72)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "356c33a0",
   "metadata": {
    "gather": {
     "logged": 1652212988908
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "# EarlyStopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.001,\n",
    "    mode=\"min\",\n",
    "    patience=100\n",
    ")\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e11c5b77",
   "metadata": {
    "gather": {
     "logged": 1652212989076
    }
   },
   "outputs": [],
   "source": [
    "def augment_this(X, y, rounds=2): \n",
    "    new_X = X[:]\n",
    "    new_y = y[:]\n",
    "    for f in range(rounds): \n",
    "        aug_X = np.zeros_like(X)\n",
    "        # Do each channel separately:\n",
    "        for channel in range(aug_X.shape[-1]):\n",
    "            this_X = X[..., channel][..., np.newaxis]\n",
    "            this_X = jitter(this_X, sigma=np.mean(this_X)/25)\n",
    "            this_X = scaling(this_X, sigma=np.mean(this_X)/25)\n",
    "            this_X = time_warp(this_X, sigma=np.mean(this_X)/25)\n",
    "            aug_X[..., channel] = this_X[...,0]\n",
    "        new_X = np.concatenate([new_X, aug_X])\n",
    "        new_y = np.concatenate([new_y, y])\n",
    "    return new_X, new_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69834832-d894-4c9c-a58c-55fa2aaf6cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = X[site==0]\n",
    "y0 = y[site==0]\n",
    "X3 = X[site==3]\n",
    "y3 = y[site==3]\n",
    "X4 = X[site==4]\n",
    "y4 = y[site==4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ea59de2-1f4d-4e74-881e-71ae1b75da46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((755, 100, 72), (743, 100, 72), (253, 100, 72))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0.shape, X3.shape, X4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47879b42-76cc-4ff5-9c3e-ce047d25cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(model_func, X_train, y_train):\n",
    "    \n",
    "    model = model_func(input_shape=(100, X_train.shape[-1]), n_classes=1, output_activation=None, verbose=True)\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  metrics=['mean_squared_error', \n",
    "                           tf.keras.metrics.RootMeanSquaredError(name='rmse'), \n",
    "                           'mean_absolute_error'])\n",
    "    # ModelCheckpoint\n",
    "    ckpt_filepath = tempfile.NamedTemporaryFile().name + '.h5'\n",
    "    ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath = ckpt_filepath,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        mode=\"auto\",\n",
    "        )\n",
    "    callbacks = [early_stopping, ckpt, reduce_lr]\n",
    "    history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=128, validation_split=0.2,\n",
    "                        callbacks=callbacks, verbose=0, use_multiprocessing=True)\n",
    "    model.load_weights(ckpt_filepath)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ea47010",
   "metadata": {
    "gather": {
     "logged": 1652212989278
    }
   },
   "outputs": [],
   "source": [
    "def multi_site(model_func, name_str, lr, X, y, random_states, augment=True):\n",
    "    # Split the data by sites\n",
    "    X0 = X[site==0]\n",
    "    y0 = y[site==0]\n",
    "    X3 = X[site==3]\n",
    "    y3 = y[site==3]\n",
    "    X4 = X[site==4]\n",
    "    y4 = y[site==4]\n",
    "\n",
    "    # We downsample each site down to the size of the smallest site:\n",
    "    sample_size = X4.shape[0]\n",
    "    X0, y0 = resample(X0, y0, n_samples=sample_size, replace=False, random_state=random_states[0])\n",
    "    X3, y3 = resample(X3, y3, n_samples=sample_size, replace=False, random_state=random_states[1])\n",
    "    X4, y4 = resample(X4, y4, n_samples=sample_size, replace=False, random_state=random_states[2])\n",
    "    \n",
    "    # Split the data into train and test sets:\n",
    "    X0_train, X0_test, y0_train, y0_test = train_test_split(X0, y0, \n",
    "                                                            test_size=0.2, \n",
    "                                                            random_state=random_states[0])\n",
    "    X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, \n",
    "                                                            test_size=0.2, \n",
    "                                                            random_state=random_states[1])\n",
    "    \n",
    "    X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, \n",
    "                                                            test_size=0.2, \n",
    "                                                            random_state=random_states[2])\n",
    "    \n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    # Impute train and test separately:\n",
    "    X0_train = np.concatenate([imputer.fit_transform(X0_train[..., ii])[:, :, None] for ii in range(X0_train.shape[-1])], -1)\n",
    "    X0_test = np.concatenate([imputer.fit_transform(X0_test[..., ii])[:, :, None] for ii in range(X0_test.shape[-1])], -1)\n",
    "    X3_train = np.concatenate([imputer.fit_transform(X3_train[..., ii])[:, :, None] for ii in range(X3_train.shape[-1])], -1)\n",
    "    X3_test = np.concatenate([imputer.fit_transform(X3_test[..., ii])[:, :, None] for ii in range(X3_test.shape[-1])], -1)\n",
    "    X4_train = np.concatenate([imputer.fit_transform(X4_train[..., ii])[:, :, None] for ii in range(X4_train.shape[-1])], -1)\n",
    "    X4_test = np.concatenate([imputer.fit_transform(X4_test[..., ii])[:, :, None] for ii in range(X4_test.shape[-1])], -1)\n",
    "    \n",
    "    # Downsample again to have the size of the smallest single site training set:\n",
    "    sample_size = X4_train.shape[0]\n",
    "    X0_train, y0_train = resample(X0_train, y0_train, n_samples=sample_size//2, replace=False, random_state=random_states[0])\n",
    "    X3_train, y3_train = resample(X3_train, y3_train, n_samples=sample_size//2, replace=False, random_state=random_states[1])\n",
    "    X4_train, y4_train = resample(X4_train, y4_train, n_samples=sample_size//2, replace=False, random_state=random_states[2])\n",
    "    \n",
    "    X03_train = np.concatenate([X0_train, X3_train])\n",
    "    y03_train = np.concatenate([y0_train, y3_train])\n",
    "    X04_train = np.concatenate([X0_train, X4_train])\n",
    "    y04_train = np.concatenate([y0_train, y4_train])\n",
    "    X43_train = np.concatenate([X4_train, X3_train])\n",
    "    y43_train = np.concatenate([y4_train, y3_train])\n",
    "\n",
    "\n",
    "    if augment:\n",
    "        X03_train, y03_train = augment_this(X03_train, y03_train, rounds=6)\n",
    "        X03_train, y03_train = shuffle(X03_train, y03_train)\n",
    "        X3_train, y3_train = augment_this(X3_train, y3_train, rounds=6)\n",
    "        X3_train, y3_train = shuffle(X3_train, y3_train)\n",
    "        X4_train, y4_train = augment_this(X4_train, y4_train, rounds=6)\n",
    "        X4_train, y4_train = shuffle(X4_train, y4_train)\n",
    "\n",
    "\n",
    "    train_data = {(0, 3): [X03_train, y03_train], \n",
    "                  (0, 4): [X04_train, y04_train],\n",
    "                  (4, 3): [X43_train, y43_train]}\n",
    "\n",
    "    test_data = {0: [X0_test, y0_test], \n",
    "                 3: [X3_test, y3_test],\n",
    "                 4: [X4_test, y4_test]}\n",
    "\n",
    "    train_site = []\n",
    "    test_site = []\n",
    "    metric = []\n",
    "    value = []\n",
    "\n",
    "    # Train on each one separately and test on all of them\n",
    "    for train in train_data: \n",
    "        X_train, y_train = train_data[train]\n",
    "        trained = model_fit(model_func, X_train, y_train)\n",
    "        for test in test_data:\n",
    "            X_test, y_test = test_data[test]\n",
    "            y_pred = trained.predict(X_test)\n",
    "            train_site.append([f\"{train[0]}, {train[1]}\"]*3)\n",
    "            test_site.append([test]*3)\n",
    "            metric.append(\"mae\")\n",
    "            value.append(mean_absolute_error(y_test, y_pred))\n",
    "            metric.append(\"mad\")\n",
    "            value.append(median_absolute_error(y_test, y_pred))\n",
    "            metric.append(\"r2\")\n",
    "            value.append(r2_score(y_test, y_pred))\n",
    "    \n",
    "    result = {'Model': [name_str] * 27,\n",
    "              'Train_site': np.array(train_site).ravel(),\n",
    "              'Test_site': np.array(test_site).ravel(),\n",
    "              'Metric': metric,\n",
    "              'Value': value}\n",
    "    df = pd.DataFrame(result)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0790377c-9b35-4c0c-bb97-fcfc3b5d4c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\"cnn_lenet\": {\"model\": cnn_lenet, \"lr\": 0.001}, \n",
    "              \"mlp4\": {\"model\": mlp4, \"lr\": 0.001},\n",
    "              \"cnn_vgg\": {\"model\": cnn_vgg, \"lr\": 0.001},\n",
    "              \"lstm1v0\": {\"model\": lstm1v0, \"lr\": 0.01},\n",
    "              \"lstm1\": {\"model\": lstm1, \"lr\": 0.01},\n",
    "              \"lstm2\": {\"model\": lstm2, \"lr\": 0.01},\n",
    "              \"blstm1\": {\"model\": blstm1, \"lr\": 0.01},\n",
    "              \"blstm2\": {\"model\": blstm1, \"lr\": 0.01},\n",
    "              \"lstm_fcn\": {\"model\": lstm_fcn, \"lr\": 0.01},\n",
    "              \"cnn_resnet\": {\"model\": cnn_resnet, \"lr\": 0.01}\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7e465bf-19e0-4acf-b687-6140186a1fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "970f7013-3446-463e-855d-a2a434b69e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = np.abs(np.floor(np.random.randn(3 * n_runs )*1000)).astype(int).reshape((n_runs, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e6f46b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "model:  cnn_lenet\n",
      "pooling layers: 4\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 50, 6)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 25, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 12, 26)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 6, 36)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 216)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 50, 6)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 25, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 12, 26)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 6, 36)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 216)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 50, 6)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPooling  (None, 25, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 216)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 117: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 216)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_16 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_18 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_19 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 216)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_20 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_20 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_21 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_21 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_22 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_22 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_23 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 216)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 117: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_24 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_24 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_25 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_25 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_26 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_26 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_27 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_27 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 216)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_28 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_28 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_29 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_29 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_30 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_30 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_31 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_31 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 216)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_32 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_32 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_33 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_33 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_34 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_34 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_35 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_35 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 216)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_36 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_36 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_37 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_37 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_38 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_38 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_39 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_39 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 216)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_40 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_40 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_41 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_41 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_42 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_42 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_43 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_43 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_44 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_44 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_45 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_45 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_46 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_46 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_47 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_47 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_48 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_48 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_49 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_49 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_50 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_50 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_51 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_51 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_52 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_52 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_53 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_53 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_54 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_54 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_55 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_55 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_56 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_56 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_57 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_57 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_58 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_58 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_59 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_59 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_60 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_60 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_61 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_61 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_62 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_62 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_63 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_63 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_64 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_64 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_65 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_65 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_66 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_66 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_67 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_67 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 117: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_68 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_68 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_69 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_69 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_70 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_70 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_71 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_71 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_72 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_72 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_73 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_73 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_74 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_74 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_75 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_75 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_76 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_76 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_77 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_77 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_78 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_78 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_79 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_79 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_80 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_80 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_81 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_81 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_82 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_82 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_83 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_83 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_22 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_84 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_84 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_85 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_85 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_86 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_86 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_87 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_87 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_88 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_88 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_89 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_89 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_90 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_90 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_91 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_91 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_24 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_92 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_92 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_93 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_93 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_94 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_94 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_95 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_95 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_96 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_96 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_97 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_97 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_98 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_98 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_99 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_99 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_26 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_100 (Conv1D)         (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_100 (MaxPooli  (None, 50, 6)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_101 (Conv1D)         (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_101 (MaxPooli  (None, 25, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_102 (Conv1D)         (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_102 (MaxPooli  (None, 12, 26)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_103 (Conv1D)         (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_103 (MaxPooli  (None, 6, 36)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_27 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_104 (Conv1D)         (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_104 (MaxPooli  (None, 50, 6)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_105 (Conv1D)         (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_105 (MaxPooli  (None, 25, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_106 (Conv1D)         (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_106 (MaxPooli  (None, 12, 26)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_107 (Conv1D)         (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_107 (MaxPooli  (None, 6, 36)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_28 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_108 (Conv1D)         (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_108 (MaxPooli  (None, 50, 6)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_109 (Conv1D)         (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_109 (MaxPooli  (None, 25, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_110 (Conv1D)         (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_110 (MaxPooli  (None, 12, 26)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_111 (Conv1D)         (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_111 (MaxPooli  (None, 6, 36)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_27 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_29 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_112 (Conv1D)         (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_112 (MaxPooli  (None, 50, 6)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_113 (Conv1D)         (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_113 (MaxPooli  (None, 25, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_114 (Conv1D)         (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_114 (MaxPooli  (None, 12, 26)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_115 (Conv1D)         (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_115 (MaxPooli  (None, 6, 36)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_30 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_116 (Conv1D)         (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_116 (MaxPooli  (None, 50, 6)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_117 (Conv1D)         (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_117 (MaxPooli  (None, 25, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_118 (Conv1D)         (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_118 (MaxPooli  (None, 12, 26)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_119 (Conv1D)         (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_119 (MaxPooli  (None, 6, 36)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_29 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "##################################################\n",
      "model:  mlp4\n",
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_31 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_32 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_31 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_33 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 169: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 189: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 209: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 229: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 249: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Model: \"model_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_34 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_33 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_35 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_34 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_36 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_35 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_80 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_81 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_82 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_83 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_37 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_36 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_84 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_85 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_86 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_87 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_38 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_37 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_88 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_90 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_91 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_39 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_38 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_92 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_93 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_94 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_95 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_40 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_39 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_96 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_97 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_98 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_99 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_41 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_40 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_100 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_101 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_102 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_103 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_42 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_41 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_104 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_105 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_106 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_107 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_43 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_42 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_108 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_109 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_110 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_111 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 127: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_44 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_43 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_112 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_114 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_115 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_45 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_44 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_116 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_117 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_118 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_119 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_46 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_45 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_120 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_121 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_122 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_123 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_47 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_46 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_124 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_125 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_126 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_127 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 213: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 233: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 365: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 392: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 412: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 458: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 478: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 498: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 518: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 538: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Model: \"model_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_48 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_47 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_128 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_129 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_130 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_160 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_131 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_49 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_48 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_132 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_133 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_134 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_135 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_50 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_49 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_136 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_137 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_138 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_139 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_51 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_50 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_140 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_141 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_142 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_143 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_52 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_51 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_144 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_145 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_146 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_147 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_53 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_52 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_148 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_149 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_150 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_151 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_54 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_53 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_152 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_153 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_154 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_155 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_55 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_54 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_156 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_157 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_158 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_159 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_56 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_55 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_160 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_190 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_161 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_162 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_163 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_57 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_56 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_164 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_165 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_166 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_167 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_58 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_57 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_168 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_169 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_170 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_200 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_171 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 129: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Model: \"model_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_59 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_58 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_172 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_202 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_173 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_174 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_175 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_60 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_59 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_176 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_177 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_178 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_208 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_179 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "##################################################\n",
      "model:  cnn_vgg\n",
      "pooling layers: 4\n",
      "Model: \"model_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_61 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_120 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_121 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_120 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_122 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_123 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_121 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_124 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_125 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_126 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_122 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_127 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_128 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_129 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_123 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_60 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_210 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_180 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_181 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 167: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 192: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 212: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 232: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 252: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 272: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_62 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_130 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_131 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_124 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_132 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_133 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_125 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_134 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_135 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_136 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_126 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_137 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_138 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_139 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_127 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_61 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_182 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_183 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_63 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_140 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_141 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_128 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_142 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_143 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_129 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_144 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_145 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_146 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_130 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_147 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_148 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_149 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_131 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_62 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_216 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_184 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_185 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_218 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_64 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_150 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_151 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_132 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_152 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_153 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_133 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_154 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_155 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_156 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_134 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_157 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_158 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_159 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_135 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_63 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_219 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_186 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_220 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_187 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 146: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 166: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 186: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 206: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_65 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_160 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_161 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_136 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_162 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_163 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_137 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_164 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_165 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_166 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_138 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_167 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_168 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_169 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_139 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_64 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_222 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_188 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_223 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_189 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_224 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 117: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 150: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 170: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 190: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 210: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 230: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_66 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_170 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_171 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_140 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_172 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_173 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_141 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_174 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_175 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_176 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_142 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_177 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_178 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_179 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_143 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_65 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_190 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_226 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_191 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_67 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_180 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_181 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_144 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_182 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_183 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_145 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_184 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_185 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_186 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_146 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_187 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_188 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_189 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_147 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_66 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_228 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_192 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_193 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_230 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_68 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_190 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_191 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_148 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_192 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_193 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_149 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_194 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_195 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_196 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_150 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_197 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_198 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_199 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_151 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_67 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_194 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_232 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_195 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 129: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 149: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_69 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_200 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_201 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_152 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_202 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_203 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_153 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_204 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_205 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_206 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_154 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_207 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_208 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_209 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_155 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_68 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_234 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_196 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_235 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_197 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_236 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 166: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 235: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 292: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 319: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 349: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 369: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 389: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 409: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 429: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "pooling layers: 4\n",
      "Model: \"model_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_70 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_210 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_211 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_156 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_212 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_213 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_157 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_214 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_215 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_216 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_158 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_217 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_218 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_219 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_159 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_69 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_198 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_238 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_199 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 139: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 159: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 179: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 199: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 219: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_71 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_220 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_221 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_160 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_222 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_223 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_161 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_224 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_225 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_226 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_162 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_227 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_228 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_229 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_163 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_70 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_240 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_200 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_201 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_242 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 130: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 236: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 263: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 283: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 303: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 323: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 343: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_72 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_230 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_231 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_164 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_232 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_233 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_165 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_234 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_235 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_236 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_166 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_237 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_238 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_239 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_167 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_71 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_243 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_202 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_244 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_203 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_245 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 156: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 176: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 196: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 216: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_73 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_240 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_241 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_168 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_242 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_243 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_169 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_244 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_245 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_246 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_170 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_247 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_248 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_249 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_171 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_72 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_246 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_204 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_247 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_205 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_248 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_74 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_250 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_251 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_172 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_252 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_253 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_173 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_254 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_255 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_256 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_174 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_257 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_258 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_259 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_175 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_73 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_249 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_206 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_250 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_207 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 192: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_75 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_260 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_261 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_176 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_262 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_263 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_177 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_264 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_265 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_266 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_178 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_267 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_268 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_269 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_179 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_74 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_208 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_209 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_254 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 169: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 189: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 232: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 252: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 272: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 292: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 312: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_76 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_270 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_271 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_180 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_272 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_273 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_181 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_274 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_275 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_276 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_182 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_277 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_278 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_279 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_183 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_75 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_255 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_210 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_256 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_211 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_257 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 120: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 140: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 160: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 180: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 200: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_77 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_280 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_281 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_184 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_282 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_283 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_185 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_284 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_285 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_286 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_186 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_287 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_288 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_289 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_187 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_76 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_258 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_212 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_259 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_213 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_260 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 156: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 176: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 196: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 216: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_78 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_290 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_291 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_188 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_292 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_293 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_189 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_294 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_295 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_296 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_190 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_297 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_298 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_299 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_191 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_77 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_261 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_214 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_262 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_215 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_263 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_79 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_300 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_301 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_192 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_302 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_303 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_193 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_304 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_305 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_306 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_194 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_307 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_308 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_309 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_195 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_78 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_264 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_216 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_265 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_217 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_266 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 147: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 167: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 187: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 207: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 227: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_80 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_310 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_311 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_196 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_312 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_313 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_197 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_314 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_315 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_316 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_198 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_317 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_318 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_319 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_199 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_79 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_267 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_218 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_268 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_219 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_269 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 146: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_81 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_320 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_321 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_200 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_322 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_323 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_201 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_324 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_325 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_326 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_202 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_327 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_328 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_329 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_203 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_80 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_270 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_220 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_271 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_221 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_272 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_82 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_330 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_331 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_204 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_332 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_333 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_205 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_334 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_335 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_336 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_206 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_337 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_338 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_339 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_207 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_81 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_273 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_222 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_274 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_223 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_275 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_83 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_340 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_341 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_208 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_342 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_343 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_209 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_344 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_345 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_346 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_210 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_347 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_348 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_349 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_211 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_82 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_276 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_224 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_277 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_225 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_278 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 164: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 184: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 204: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 224: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_84 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_350 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_351 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_212 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_352 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_353 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_213 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_354 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_355 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_356 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_214 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_357 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_358 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_359 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_215 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_83 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_279 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_226 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_280 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_227 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_281 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_85 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_360 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_361 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_216 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_362 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_363 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_217 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_364 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_365 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_366 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_218 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_367 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_368 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_369 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_219 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_84 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_282 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_228 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_283 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_229 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_284 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_86 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_370 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_371 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_220 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_372 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_373 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_221 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_374 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_375 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_376 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_222 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_377 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_378 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_379 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_223 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_85 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_285 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_230 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_286 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_231 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_287 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 177: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 197: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 217: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 237: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 257: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_87 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_380 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_381 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_224 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_382 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_383 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_225 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_384 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_385 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_386 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_226 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_387 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_388 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_389 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_227 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_86 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_288 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_232 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_289 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_233 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_290 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_88 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_390 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_391 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_228 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_392 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_393 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_229 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_394 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_395 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_396 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_230 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_397 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_398 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_399 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_231 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_87 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_291 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_234 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_292 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_235 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_293 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 171: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_89 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_400 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_401 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_232 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_402 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_403 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_233 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_404 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_405 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_406 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_234 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_407 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_408 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_409 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_235 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_88 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_294 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_236 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_295 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_237 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_296 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 140: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 160: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 180: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 200: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 220: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_90 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_410 (Conv1D)         (None, 100, 64)           13888     \n",
      "                                                                 \n",
      " conv1d_411 (Conv1D)         (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_236 (MaxPooli  (None, 50, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_412 (Conv1D)         (None, 50, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_413 (Conv1D)         (None, 50, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_237 (MaxPooli  (None, 25, 128)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_414 (Conv1D)         (None, 25, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_415 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " conv1d_416 (Conv1D)         (None, 25, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_238 (MaxPooli  (None, 12, 256)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_417 (Conv1D)         (None, 12, 512)           393728    \n",
      "                                                                 \n",
      " conv1d_418 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " conv1d_419 (Conv1D)         (None, 12, 512)           786944    \n",
      "                                                                 \n",
      " max_pooling1d_239 (MaxPooli  (None, 6, 512)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_89 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_297 (Dense)           (None, 4096)              12587008  \n",
      "                                                                 \n",
      " dropout_238 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_298 (Dense)           (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_239 (Dropout)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_299 (Dense)           (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,932,545\n",
      "Trainable params: 31,932,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 119: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 226: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 246: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 266: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 286: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 306: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "##################################################\n",
      "model:  lstm1v0\n",
      "Model: \"model_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_91 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_300 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 167: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 187: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 207: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 227: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 247: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_92 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_301 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 197: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 310: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 330: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 350: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 370: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 390: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_93 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_302 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_94 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_303 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 156: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_95 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_304 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_96 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_305 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 164: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 184: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 204: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 224: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_97 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_306 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 138: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 158: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 178: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 200: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 220: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 240: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 260: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 280: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Model: \"model_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_98 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_307 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 171: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 225: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 269: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 320: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 340: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 360: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 380: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 400: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Model: \"model_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_99 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_308 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 119: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 222: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 248: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 268: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 288: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 308: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 328: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_100 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_309 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 194: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 232: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 271: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 399: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 419: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 439: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 459: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 479: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Model: \"model_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_101 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_310 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_102 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_311 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 159: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 254: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 285: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 305: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 325: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 345: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 365: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_103 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_312 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 213: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 251: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 317: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 337: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 357: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 377: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 397: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Model: \"model_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_104 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_313 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 193: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 298: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 565: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 585: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 605: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 625: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 645: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_105 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_314 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_106 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_315 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 174: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 202: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 222: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 242: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 262: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 282: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_107 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_316 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 224: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 280: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 300: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 320: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 340: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 360: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_108 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_317 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 362: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 510: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 535: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 555: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 575: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 595: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 615: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_108\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_109 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_318 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 202: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 222: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_109\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_110 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_319 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 492: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 512: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 532: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 552: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 572: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Model: \"model_110\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_111 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_320 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 146: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 166: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 186: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 206: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 226: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_111\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_112 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_321 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_112\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_113 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_322 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 178: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 300: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 320: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 340: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 360: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 380: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_113\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_114 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_323 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 183: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 203: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_114\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_115 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_324 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 174: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_115\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_116 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_325 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 272: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 319: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 396: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 422: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 442: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 462: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 482: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\n",
      "Epoch 502: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "Model: \"model_116\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_117 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_26 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_326 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 197: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 217: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 237: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 257: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 277: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Model: \"model_117\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_118 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_27 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_327 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 170: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 190: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 210: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 230: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 250: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_118\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_119 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_28 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_328 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 201: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 260: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 280: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 300: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 320: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 340: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_119\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_120 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 512)               1198080   \n",
      "                                                                 \n",
      " dense_329 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,593\n",
      "Trainable params: 1,198,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 227: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 265: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 285: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 305: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 325: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 345: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "##################################################\n",
      "model:  lstm1\n",
      "Model: \"model_120\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_121 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_30 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_330 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_121\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_122 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_31 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_331 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_122\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_123 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_32 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_332 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_123\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_124 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_33 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_333 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_124\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_125 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_34 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_334 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_125\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_126 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_35 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_335 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 204: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 240: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 260: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 280: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 300: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 320: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_126\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_127 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_36 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_336 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 238: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 317: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 354: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 374: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 394: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 414: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 434: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_127\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_128 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_37 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_337 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_128\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_129 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_38 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_338 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_129\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_130 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_39 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_339 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 201: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 258: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 447: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 479: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 499: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 519: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 539: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 559: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_130\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_131 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_40 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_340 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_131\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_132 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_41 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_341 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 168: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 188: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 208: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 228: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 248: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_132\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_133 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_42 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_342 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 309: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 329: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 349: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 369: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_133\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_134 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_43 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_343 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_134\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_135 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_44 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_344 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_135\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_136 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_45 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_345 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 184: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 204: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 224: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 244: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 264: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_136\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_137 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_46 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_346 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 272: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 292: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 379: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 399: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 419: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 439: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 459: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_137\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_138 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_47 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_347 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_138\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_139 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_48 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_348 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 117: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 137: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 157: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_139\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_140 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_49 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_349 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 127: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 147: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_140\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_141 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_50 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_350 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_141\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_142 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_51 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_351 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_142\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_143 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_52 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_352 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_143\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_144 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_53 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_353 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_144\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_145 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_54 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_354 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 140: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 160: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 180: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 200: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 220: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_145\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_146 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_55 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_355 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_146\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_147 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_56 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_356 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 128: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 148: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 168: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 188: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 208: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_147\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_148 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_57 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_357 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 193: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 213: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 233: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 253: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_148\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_149 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_58 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_358 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_149\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_150 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_59 (LSTM)              (None, 100)               69200     \n",
      "                                                                 \n",
      " dense_359 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,301\n",
      "Trainable params: 69,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 249: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 269: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 289: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 309: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 329: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "##################################################\n",
      "model:  lstm2\n",
      "Model: \"model_150\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_151 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_60 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_61 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_360 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_151\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_152 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_62 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_63 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_361 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Model: \"model_152\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_153 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_64 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_65 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_362 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_153\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_154 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_66 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_67 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_363 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_154\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_155 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_68 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_69 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_364 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 138: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 158: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_155\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_156 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_70 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_71 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_365 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Model: \"model_156\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_157 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_72 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_73 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_366 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_157\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_158 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_74 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_75 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_367 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_158\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_159 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_76 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_77 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_368 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_159\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_160 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_78 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_79 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_369 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Model: \"model_160\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_161 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_80 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_81 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_370 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_161\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_162 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_82 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_83 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_371 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_162\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_163 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_84 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_85 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_372 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 117: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_163\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_164 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_86 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_87 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_373 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_164\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_165 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_88 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_89 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_374 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_165\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_166 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_90 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_91 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_375 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 117: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_166\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_167 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_92 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_93 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_376 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 119: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_167\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_168 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_94 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_95 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_377 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_168\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_169 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_96 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_97 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_378 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_169\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_170 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_98 (LSTM)              (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_99 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_379 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 117: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_170\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_171 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_100 (LSTM)             (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_101 (LSTM)             (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_380 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_171\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_172 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_102 (LSTM)             (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_103 (LSTM)             (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_381 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_172\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_173 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_104 (LSTM)             (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_105 (LSTM)             (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_382 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_173\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_174 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_106 (LSTM)             (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_107 (LSTM)             (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_383 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_174\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_175 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_108 (LSTM)             (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_109 (LSTM)             (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_384 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_175\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_176 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_110 (LSTM)             (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_111 (LSTM)             (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_385 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_176\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_177 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_112 (LSTM)             (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_113 (LSTM)             (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_386 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_177\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_178 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_114 (LSTM)             (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_115 (LSTM)             (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_387 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Model: \"model_178\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_179 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_116 (LSTM)             (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_117 (LSTM)             (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_388 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_179\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_180 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " lstm_118 (LSTM)             (None, 100, 100)          69200     \n",
      "                                                                 \n",
      " lstm_119 (LSTM)             (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_389 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,701\n",
      "Trainable params: 149,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 129: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "##################################################\n",
      "model:  blstm1\n",
      "Model: \"model_180\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_181 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              138400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_390 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 174: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 218: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 238: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 258: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 278: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 298: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_181\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_182 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 200)              138400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_391 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 214: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 234: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 254: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 274: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 294: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_182\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_183 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 200)              138400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_392 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_183\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_184 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 200)              138400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_393 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 159: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 238: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 350: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 370: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 390: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 410: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 430: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_184\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_185 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 200)              138400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_394 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 177: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 223: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 243: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 283: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 303: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 323: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 343: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 363: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_185\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_186 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 200)              138400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_395 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 160: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 318: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 338: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 358: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 378: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 398: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_186\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_187 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 200)              138400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_396 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 146: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 202: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 222: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 242: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 262: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_187\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_188 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 200)              138400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_397 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 183: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 203: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 223: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 243: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_188\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_189 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 200)              138400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_398 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 226: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 276: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 296: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 316: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 336: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 356: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_189\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_190 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 200)              138400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_399 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 155: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 175: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 195: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 215: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 235: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_190\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_191 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_400 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_191\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_192 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_401 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 212: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 232: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 252: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 327: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 347: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 367: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 387: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 407: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Model: \"model_192\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_193 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_12 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_402 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 169: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 215: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 235: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 255: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 275: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 295: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_193\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_194 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_403 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 241: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 276: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 296: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 316: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 336: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 356: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_194\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_195 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_14 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_404 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 167: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 190: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 210: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 230: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 250: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 270: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_195\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_196 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_15 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_405 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 167: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 213: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 260: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 280: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 300: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 320: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 340: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_196\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_197 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_16 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_406 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 202: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 239: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 266: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 298: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 359: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 472: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 517: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 537: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\n",
      "Epoch 557: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "\n",
      "Epoch 577: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n",
      "\n",
      "Epoch 597: ReduceLROnPlateau reducing learning rate to 2.441406195430318e-06.\n",
      "Model: \"model_197\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_198 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_17 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_407 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 210: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 230: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 250: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 270: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 290: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_198\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_199 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_18 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_408 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 202: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 253: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 473: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 515: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 535: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 555: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 575: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 595: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Model: \"model_199\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_200 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_19 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_409 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 174: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 194: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 214: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 234: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_200\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_201 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_20 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_410 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 174: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 194: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 308: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 328: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 348: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 368: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 388: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_201\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_202 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_21 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_411 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_202\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_203 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_22 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_412 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 292: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 312: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 332: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 352: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 372: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_203\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_204 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_23 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_413 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 171: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 191: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 211: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 231: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_204\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_205 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_24 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_414 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 156: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 176: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 196: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_205\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_206 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_25 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_415 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 234: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 270: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 310: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 330: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 350: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 370: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 390: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Model: \"model_206\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_207 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_26 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_416 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 160: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 180: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 200: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 220: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 240: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_207\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_208 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_27 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_417 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 257: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 306: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 326: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 346: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 366: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 386: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Model: \"model_208\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_209 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_28 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_418 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 120: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 140: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 160: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 180: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 200: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_209\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_210 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_29 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_419 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 282: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 302: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 322: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 342: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 362: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "##################################################\n",
      "model:  blstm2\n",
      "Model: \"model_210\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_211 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_30 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_420 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 146: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 244: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 280: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 300: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 320: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\n",
      "Epoch 340: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "Model: \"model_211\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_212 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_31 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_421 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 214: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 234: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 254: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 274: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 294: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_212\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_213 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_32 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_422 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 206: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 236: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 256: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 276: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 296: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 316: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_213\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_214 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_33 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_423 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 269: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 296: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 316: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 336: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 356: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 376: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_214\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_215 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_34 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_424 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 117: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 187: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 207: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 227: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 247: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 267: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_215\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_216 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_35 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_425 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 268: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 318: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 345: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 365: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 385: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 405: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 425: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_216\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_217 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_36 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_426 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 160: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 180: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 200: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 220: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 240: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_217\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_218 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_37 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_427 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 181: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 201: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_218\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_219 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_38 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_428 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 130: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 241: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 269: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 289: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 309: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 329: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 349: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_219\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_220 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_39 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_429 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 229: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 249: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 303: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 323: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 343: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 363: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 383: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_220\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_221 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_40 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_430 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_221\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_222 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_41 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_431 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 178: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 198: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 218: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 238: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 258: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_222\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_223 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_42 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_432 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 158: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 219: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 239: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 259: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 279: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 299: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_223\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_224 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_43 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_433 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 256: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 292: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 312: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 332: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 352: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 372: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_225 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_44 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_434 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 281: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 301: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 321: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 341: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 361: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_225\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_226 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_45 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_435 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 277: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 297: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 317: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 337: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 357: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_226\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_227 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_46 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_436 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 216: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 258: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 321: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 358: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 378: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 398: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 418: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Model: \"model_227\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_228 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_47 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_437 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 146: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 166: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 186: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 206: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 226: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_228\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_229 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_48 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_438 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 147: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 167: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 187: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 207: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 227: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_229\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_230 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_49 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_439 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 119: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 166: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 186: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 206: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 226: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 246: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_230\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_231 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_50 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_440 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 177: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 197: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 224: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 244: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 264: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 284: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 304: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_231\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_232 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_51 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_441 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_232\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_233 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_52 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_442 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 179: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 199: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 219: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 239: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 259: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_233\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_234 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_53 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_443 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_234\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_235 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_54 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_444 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 344: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 364: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 384: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 404: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 424: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Model: \"model_235\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_236 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_55 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_445 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 185: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 209: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 254: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 286: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 306: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 326: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 346: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 366: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_236\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_237 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_56 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_446 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 127: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 147: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_237\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_238 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_57 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_447 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 168: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 188: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 208: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 228: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 248: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_238\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_239 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_58 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_448 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 246: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 281: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 301: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 321: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 341: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 361: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_239\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_240 (InputLayer)      [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " bidirectional_59 (Bidirecti  (None, 200)              138400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_449 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,601\n",
      "Trainable params: 138,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 158: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 178: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 198: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 218: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 238: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "##################################################\n",
      "model:  lstm_fcn\n",
      "Model: \"model_240\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_241 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_420 (Conv1D)            (None, 100, 128)     73856       ['input_241[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 100, 128)    512         ['conv1d_420[0][0]']             \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 100, 128)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_421 (Conv1D)            (None, 100, 256)     164096      ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 100, 256)    1024        ['conv1d_421[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 100, 256)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_422 (Conv1D)            (None, 100, 128)     98432       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " permute (Permute)              (None, 72, 100)      0           ['input_241[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 100, 128)    512         ['conv1d_422[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " lstm_180 (LSTM)                (None, 128)          117248      ['permute[0][0]']                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 100, 128)     0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_240 (Dropout)          (None, 128)          0           ['lstm_180[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['activation_2[0][0]']           \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 256)          0           ['dropout_240[0][0]',            \n",
      "                                                                  'global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_450 (Dense)              (None, 1)            257         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_241\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_242 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_423 (Conv1D)            (None, 100, 128)     73856       ['input_242[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 100, 128)    512         ['conv1d_423[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 100, 128)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_424 (Conv1D)            (None, 100, 256)     164096      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 100, 256)    1024        ['conv1d_424[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 100, 256)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_425 (Conv1D)            (None, 100, 128)     98432       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " permute_1 (Permute)            (None, 72, 100)      0           ['input_242[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 100, 128)    512         ['conv1d_425[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " lstm_181 (LSTM)                (None, 128)          117248      ['permute_1[0][0]']              \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 100, 128)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_241 (Dropout)          (None, 128)          0           ['lstm_181[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 128)         0           ['activation_5[0][0]']           \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 256)          0           ['dropout_241[0][0]',            \n",
      "                                                                  'global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_451 (Dense)              (None, 1)            257         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 130: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 150: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 170: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 190: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 210: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_242\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_243 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_426 (Conv1D)            (None, 100, 128)     73856       ['input_243[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 100, 128)    512         ['conv1d_426[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 100, 128)     0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_427 (Conv1D)            (None, 100, 256)     164096      ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 100, 256)    1024        ['conv1d_427[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 100, 256)     0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_428 (Conv1D)            (None, 100, 128)     98432       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " permute_2 (Permute)            (None, 72, 100)      0           ['input_243[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 100, 128)    512         ['conv1d_428[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " lstm_182 (LSTM)                (None, 128)          117248      ['permute_2[0][0]']              \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 100, 128)     0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_242 (Dropout)          (None, 128)          0           ['lstm_182[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 128)         0           ['activation_8[0][0]']           \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256)          0           ['dropout_242[0][0]',            \n",
      "                                                                  'global_average_pooling1d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_452 (Dense)              (None, 1)            257         ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 156: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 176: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 260: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 296: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 316: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 336: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\n",
      "Epoch 356: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "\n",
      "Epoch 376: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n",
      "Model: \"model_243\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_244 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_429 (Conv1D)            (None, 100, 128)     73856       ['input_244[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 100, 128)    512         ['conv1d_429[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 100, 128)     0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_430 (Conv1D)            (None, 100, 256)     164096      ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 100, 256)    1024        ['conv1d_430[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 100, 256)     0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_431 (Conv1D)            (None, 100, 128)     98432       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " permute_3 (Permute)            (None, 72, 100)      0           ['input_244[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 100, 128)    512         ['conv1d_431[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_183 (LSTM)                (None, 128)          117248      ['permute_3[0][0]']              \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 100, 128)     0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_243 (Dropout)          (None, 128)          0           ['lstm_183[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_3 (Gl  (None, 128)         0           ['activation_11[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 256)          0           ['dropout_243[0][0]',            \n",
      "                                                                  'global_average_pooling1d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_453 (Dense)              (None, 1)            257         ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_244\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_245 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_432 (Conv1D)            (None, 100, 128)     73856       ['input_245[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 100, 128)    512         ['conv1d_432[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 100, 128)     0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_433 (Conv1D)            (None, 100, 256)     164096      ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 100, 256)    1024        ['conv1d_433[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 100, 256)     0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_434 (Conv1D)            (None, 100, 128)     98432       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " permute_4 (Permute)            (None, 72, 100)      0           ['input_245[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 100, 128)    512         ['conv1d_434[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_184 (LSTM)                (None, 128)          117248      ['permute_4[0][0]']              \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 100, 128)     0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_244 (Dropout)          (None, 128)          0           ['lstm_184[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_4 (Gl  (None, 128)         0           ['activation_14[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 256)          0           ['dropout_244[0][0]',            \n",
      "                                                                  'global_average_pooling1d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_454 (Dense)              (None, 1)            257         ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 175: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 195: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 215: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 235: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 255: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_245\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_246 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_435 (Conv1D)            (None, 100, 128)     73856       ['input_246[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 100, 128)    512         ['conv1d_435[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 100, 128)     0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_436 (Conv1D)            (None, 100, 256)     164096      ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 100, 256)    1024        ['conv1d_436[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 100, 256)     0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_437 (Conv1D)            (None, 100, 128)     98432       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " permute_5 (Permute)            (None, 72, 100)      0           ['input_246[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 100, 128)    512         ['conv1d_437[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_185 (LSTM)                (None, 128)          117248      ['permute_5[0][0]']              \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 100, 128)     0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_245 (Dropout)          (None, 128)          0           ['lstm_185[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_5 (Gl  (None, 128)         0           ['activation_17[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 256)          0           ['dropout_245[0][0]',            \n",
      "                                                                  'global_average_pooling1d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_455 (Dense)              (None, 1)            257         ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 167: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 187: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 207: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 227: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 247: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_246\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_247 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_438 (Conv1D)            (None, 100, 128)     73856       ['input_247[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 100, 128)    512         ['conv1d_438[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 100, 128)     0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_439 (Conv1D)            (None, 100, 256)     164096      ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 100, 256)    1024        ['conv1d_439[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 100, 256)     0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_440 (Conv1D)            (None, 100, 128)     98432       ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " permute_6 (Permute)            (None, 72, 100)      0           ['input_247[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 100, 128)    512         ['conv1d_440[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_186 (LSTM)                (None, 128)          117248      ['permute_6[0][0]']              \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 100, 128)     0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_246 (Dropout)          (None, 128)          0           ['lstm_186[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_6 (Gl  (None, 128)         0           ['activation_20[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 256)          0           ['dropout_246[0][0]',            \n",
      "                                                                  'global_average_pooling1d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_456 (Dense)              (None, 1)            257         ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 181: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 201: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 221: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_247\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_248 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_441 (Conv1D)            (None, 100, 128)     73856       ['input_248[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 100, 128)    512         ['conv1d_441[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 100, 128)     0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_442 (Conv1D)            (None, 100, 256)     164096      ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 100, 256)    1024        ['conv1d_442[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 100, 256)     0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_443 (Conv1D)            (None, 100, 128)     98432       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " permute_7 (Permute)            (None, 72, 100)      0           ['input_248[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 100, 128)    512         ['conv1d_443[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_187 (LSTM)                (None, 128)          117248      ['permute_7[0][0]']              \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 100, 128)     0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_247 (Dropout)          (None, 128)          0           ['lstm_187[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_7 (Gl  (None, 128)         0           ['activation_23[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 256)          0           ['dropout_247[0][0]',            \n",
      "                                                                  'global_average_pooling1d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_457 (Dense)              (None, 1)            257         ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 189: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 240: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 260: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 298: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 318: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 356: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 376: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\n",
      "Epoch 396: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "\n",
      "Epoch 416: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n",
      "Model: \"model_248\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_249 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_444 (Conv1D)            (None, 100, 128)     73856       ['input_249[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 100, 128)    512         ['conv1d_444[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 100, 128)     0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_445 (Conv1D)            (None, 100, 256)     164096      ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 100, 256)    1024        ['conv1d_445[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 100, 256)     0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_446 (Conv1D)            (None, 100, 128)     98432       ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " permute_8 (Permute)            (None, 72, 100)      0           ['input_249[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 100, 128)    512         ['conv1d_446[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_188 (LSTM)                (None, 128)          117248      ['permute_8[0][0]']              \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 100, 128)     0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_248 (Dropout)          (None, 128)          0           ['lstm_188[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_8 (Gl  (None, 128)         0           ['activation_26[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 256)          0           ['dropout_248[0][0]',            \n",
      "                                                                  'global_average_pooling1d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_458 (Dense)              (None, 1)            257         ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 164: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 190: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 210: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 230: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 250: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 270: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_249\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_250 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_447 (Conv1D)            (None, 100, 128)     73856       ['input_250[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 100, 128)    512         ['conv1d_447[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 100, 128)     0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_448 (Conv1D)            (None, 100, 256)     164096      ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 100, 256)    1024        ['conv1d_448[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 100, 256)     0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_449 (Conv1D)            (None, 100, 128)     98432       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " permute_9 (Permute)            (None, 72, 100)      0           ['input_250[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 100, 128)    512         ['conv1d_449[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_189 (LSTM)                (None, 128)          117248      ['permute_9[0][0]']              \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 100, 128)     0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_249 (Dropout)          (None, 128)          0           ['lstm_189[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_9 (Gl  (None, 128)         0           ['activation_29[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 256)          0           ['dropout_249[0][0]',            \n",
      "                                                                  'global_average_pooling1d_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_459 (Dense)              (None, 1)            257         ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 183: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_250\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_251 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_450 (Conv1D)            (None, 100, 128)     73856       ['input_251[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 100, 128)    512         ['conv1d_450[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 100, 128)     0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_451 (Conv1D)            (None, 100, 256)     164096      ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 100, 256)    1024        ['conv1d_451[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 100, 256)     0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_452 (Conv1D)            (None, 100, 128)     98432       ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " permute_10 (Permute)           (None, 72, 100)      0           ['input_251[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 100, 128)    512         ['conv1d_452[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_190 (LSTM)                (None, 128)          117248      ['permute_10[0][0]']             \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 100, 128)     0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_250 (Dropout)          (None, 128)          0           ['lstm_190[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_10 (G  (None, 128)         0           ['activation_32[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 256)          0           ['dropout_250[0][0]',            \n",
      "                                                                  'global_average_pooling1d_10[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_460 (Dense)              (None, 1)            257         ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 147: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 167: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 187: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 207: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 227: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_251\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_252 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_453 (Conv1D)            (None, 100, 128)     73856       ['input_252[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 100, 128)    512         ['conv1d_453[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 100, 128)     0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_454 (Conv1D)            (None, 100, 256)     164096      ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 100, 256)    1024        ['conv1d_454[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 100, 256)     0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_455 (Conv1D)            (None, 100, 128)     98432       ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " permute_11 (Permute)           (None, 72, 100)      0           ['input_252[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 100, 128)    512         ['conv1d_455[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_191 (LSTM)                (None, 128)          117248      ['permute_11[0][0]']             \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 100, 128)     0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_251 (Dropout)          (None, 128)          0           ['lstm_191[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_11 (G  (None, 128)         0           ['activation_35[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 256)          0           ['dropout_251[0][0]',            \n",
      "                                                                  'global_average_pooling1d_11[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_461 (Dense)              (None, 1)            257         ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 174: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 225: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 245: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 280: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 300: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\n",
      "Epoch 320: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "\n",
      "Epoch 340: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n",
      "\n",
      "Epoch 360: ReduceLROnPlateau reducing learning rate to 2.441406195430318e-06.\n",
      "Model: \"model_252\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_253 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_456 (Conv1D)            (None, 100, 128)     73856       ['input_253[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 100, 128)    512         ['conv1d_456[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 100, 128)     0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_457 (Conv1D)            (None, 100, 256)     164096      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 100, 256)    1024        ['conv1d_457[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 100, 256)     0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_458 (Conv1D)            (None, 100, 128)     98432       ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " permute_12 (Permute)           (None, 72, 100)      0           ['input_253[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 100, 128)    512         ['conv1d_458[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_192 (LSTM)                (None, 128)          117248      ['permute_12[0][0]']             \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 100, 128)     0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_252 (Dropout)          (None, 128)          0           ['lstm_192[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_12 (G  (None, 128)         0           ['activation_38[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 256)          0           ['dropout_252[0][0]',            \n",
      "                                                                  'global_average_pooling1d_12[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_462 (Dense)              (None, 1)            257         ['concatenate_12[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 159: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 179: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 199: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 262: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\n",
      "Epoch 337: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "\n",
      "Epoch 357: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n",
      "\n",
      "Epoch 377: ReduceLROnPlateau reducing learning rate to 2.441406195430318e-06.\n",
      "\n",
      "Epoch 397: ReduceLROnPlateau reducing learning rate to 1.220703097715159e-06.\n",
      "\n",
      "Epoch 417: ReduceLROnPlateau reducing learning rate to 6.103515488575795e-07.\n",
      "Model: \"model_253\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_254 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_459 (Conv1D)            (None, 100, 128)     73856       ['input_254[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 100, 128)    512         ['conv1d_459[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 100, 128)     0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_460 (Conv1D)            (None, 100, 256)     164096      ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 100, 256)    1024        ['conv1d_460[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 100, 256)     0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_461 (Conv1D)            (None, 100, 128)     98432       ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " permute_13 (Permute)           (None, 72, 100)      0           ['input_254[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 100, 128)    512         ['conv1d_461[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_193 (LSTM)                (None, 128)          117248      ['permute_13[0][0]']             \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 100, 128)     0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_253 (Dropout)          (None, 128)          0           ['lstm_193[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_13 (G  (None, 128)         0           ['activation_41[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 256)          0           ['dropout_253[0][0]',            \n",
      "                                                                  'global_average_pooling1d_13[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_463 (Dense)              (None, 1)            257         ['concatenate_13[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 164: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 184: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 204: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 224: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 244: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_254\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_255 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_462 (Conv1D)            (None, 100, 128)     73856       ['input_255[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 100, 128)    512         ['conv1d_462[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 100, 128)     0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_463 (Conv1D)            (None, 100, 256)     164096      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 100, 256)    1024        ['conv1d_463[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 100, 256)     0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_464 (Conv1D)            (None, 100, 128)     98432       ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " permute_14 (Permute)           (None, 72, 100)      0           ['input_255[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 100, 128)    512         ['conv1d_464[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_194 (LSTM)                (None, 128)          117248      ['permute_14[0][0]']             \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 100, 128)     0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_254 (Dropout)          (None, 128)          0           ['lstm_194[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_14 (G  (None, 128)         0           ['activation_44[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 256)          0           ['dropout_254[0][0]',            \n",
      "                                                                  'global_average_pooling1d_14[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_464 (Dense)              (None, 1)            257         ['concatenate_14[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 156: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 176: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 237: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 257: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 277: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 297: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\n",
      "Epoch 317: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "Model: \"model_255\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_256 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_465 (Conv1D)            (None, 100, 128)     73856       ['input_256[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 100, 128)    512         ['conv1d_465[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 100, 128)     0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_466 (Conv1D)            (None, 100, 256)     164096      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 100, 256)    1024        ['conv1d_466[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 100, 256)     0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_467 (Conv1D)            (None, 100, 128)     98432       ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " permute_15 (Permute)           (None, 72, 100)      0           ['input_256[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 100, 128)    512         ['conv1d_467[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_195 (LSTM)                (None, 128)          117248      ['permute_15[0][0]']             \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 100, 128)     0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_255 (Dropout)          (None, 128)          0           ['lstm_195[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_15 (G  (None, 128)         0           ['activation_47[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 256)          0           ['dropout_255[0][0]',            \n",
      "                                                                  'global_average_pooling1d_15[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_465 (Dense)              (None, 1)            257         ['concatenate_15[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 120: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 140: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 160: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 180: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 200: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_256\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_257 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_468 (Conv1D)            (None, 100, 128)     73856       ['input_257[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 100, 128)    512         ['conv1d_468[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 100, 128)     0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_469 (Conv1D)            (None, 100, 256)     164096      ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 100, 256)    1024        ['conv1d_469[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 100, 256)     0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_470 (Conv1D)            (None, 100, 128)     98432       ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " permute_16 (Permute)           (None, 72, 100)      0           ['input_257[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 100, 128)    512         ['conv1d_470[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_196 (LSTM)                (None, 128)          117248      ['permute_16[0][0]']             \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 100, 128)     0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_256 (Dropout)          (None, 128)          0           ['lstm_196[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_16 (G  (None, 128)         0           ['activation_50[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenate)   (None, 256)          0           ['dropout_256[0][0]',            \n",
      "                                                                  'global_average_pooling1d_16[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_466 (Dense)              (None, 1)            257         ['concatenate_16[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 233: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 253: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 273: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 293: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 313: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_257\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_258 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_471 (Conv1D)            (None, 100, 128)     73856       ['input_258[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 100, 128)    512         ['conv1d_471[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 100, 128)     0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_472 (Conv1D)            (None, 100, 256)     164096      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 100, 256)    1024        ['conv1d_472[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 100, 256)     0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_473 (Conv1D)            (None, 100, 128)     98432       ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " permute_17 (Permute)           (None, 72, 100)      0           ['input_258[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 100, 128)    512         ['conv1d_473[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_197 (LSTM)                (None, 128)          117248      ['permute_17[0][0]']             \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 100, 128)     0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_257 (Dropout)          (None, 128)          0           ['lstm_197[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_17 (G  (None, 128)         0           ['activation_53[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 256)          0           ['dropout_257[0][0]',            \n",
      "                                                                  'global_average_pooling1d_17[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_467 (Dense)              (None, 1)            257         ['concatenate_17[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 200: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 222: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 242: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 262: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 282: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 302: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_258\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_259 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_474 (Conv1D)            (None, 100, 128)     73856       ['input_259[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 100, 128)    512         ['conv1d_474[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 100, 128)     0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_475 (Conv1D)            (None, 100, 256)     164096      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 100, 256)    1024        ['conv1d_475[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 100, 256)     0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_476 (Conv1D)            (None, 100, 128)     98432       ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " permute_18 (Permute)           (None, 72, 100)      0           ['input_259[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 100, 128)    512         ['conv1d_476[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_198 (LSTM)                (None, 128)          117248      ['permute_18[0][0]']             \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 100, 128)     0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_258 (Dropout)          (None, 128)          0           ['lstm_198[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_18 (G  (None, 128)         0           ['activation_56[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenate)   (None, 256)          0           ['dropout_258[0][0]',            \n",
      "                                                                  'global_average_pooling1d_18[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_468 (Dense)              (None, 1)            257         ['concatenate_18[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 216: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 236: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 257: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 277: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 297: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 317: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 337: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Model: \"model_259\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_260 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_477 (Conv1D)            (None, 100, 128)     73856       ['input_260[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 100, 128)    512         ['conv1d_477[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 100, 128)     0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_478 (Conv1D)            (None, 100, 256)     164096      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 100, 256)    1024        ['conv1d_478[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 100, 256)     0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_479 (Conv1D)            (None, 100, 128)     98432       ['activation_58[0][0]']          \n",
      "                                                                                                  \n",
      " permute_19 (Permute)           (None, 72, 100)      0           ['input_260[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 100, 128)    512         ['conv1d_479[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_199 (LSTM)                (None, 128)          117248      ['permute_19[0][0]']             \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 100, 128)     0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_259 (Dropout)          (None, 128)          0           ['lstm_199[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_19 (G  (None, 128)         0           ['activation_59[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_19 (Concatenate)   (None, 256)          0           ['dropout_259[0][0]',            \n",
      "                                                                  'global_average_pooling1d_19[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_469 (Dense)              (None, 1)            257         ['concatenate_19[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 202: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_260\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_261 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_480 (Conv1D)            (None, 100, 128)     73856       ['input_261[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 100, 128)    512         ['conv1d_480[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 100, 128)     0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_481 (Conv1D)            (None, 100, 256)     164096      ['activation_60[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 100, 256)    1024        ['conv1d_481[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 100, 256)     0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_482 (Conv1D)            (None, 100, 128)     98432       ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " permute_20 (Permute)           (None, 72, 100)      0           ['input_261[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 100, 128)    512         ['conv1d_482[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_200 (LSTM)                (None, 128)          117248      ['permute_20[0][0]']             \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 100, 128)     0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_260 (Dropout)          (None, 128)          0           ['lstm_200[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_20 (G  (None, 128)         0           ['activation_62[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenate)   (None, 256)          0           ['dropout_260[0][0]',            \n",
      "                                                                  'global_average_pooling1d_20[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_470 (Dense)              (None, 1)            257         ['concatenate_20[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 129: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 149: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 169: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 189: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 209: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_261\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_262 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_483 (Conv1D)            (None, 100, 128)     73856       ['input_262[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 100, 128)    512         ['conv1d_483[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 100, 128)     0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_484 (Conv1D)            (None, 100, 256)     164096      ['activation_63[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 100, 256)    1024        ['conv1d_484[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 100, 256)     0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_485 (Conv1D)            (None, 100, 128)     98432       ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " permute_21 (Permute)           (None, 72, 100)      0           ['input_262[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 100, 128)    512         ['conv1d_485[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_201 (LSTM)                (None, 128)          117248      ['permute_21[0][0]']             \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 100, 128)     0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_261 (Dropout)          (None, 128)          0           ['lstm_201[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_21 (G  (None, 128)         0           ['activation_65[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_21 (Concatenate)   (None, 256)          0           ['dropout_261[0][0]',            \n",
      "                                                                  'global_average_pooling1d_21[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_471 (Dense)              (None, 1)            257         ['concatenate_21[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 120: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 181: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 201: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 221: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_262\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_263 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_486 (Conv1D)            (None, 100, 128)     73856       ['input_263[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 100, 128)    512         ['conv1d_486[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 100, 128)     0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_487 (Conv1D)            (None, 100, 256)     164096      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 100, 256)    1024        ['conv1d_487[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 100, 256)     0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_488 (Conv1D)            (None, 100, 128)     98432       ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " permute_22 (Permute)           (None, 72, 100)      0           ['input_263[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 100, 128)    512         ['conv1d_488[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_202 (LSTM)                (None, 128)          117248      ['permute_22[0][0]']             \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 100, 128)     0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_262 (Dropout)          (None, 128)          0           ['lstm_202[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_22 (G  (None, 128)         0           ['activation_68[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_22 (Concatenate)   (None, 256)          0           ['dropout_262[0][0]',            \n",
      "                                                                  'global_average_pooling1d_22[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_472 (Dense)              (None, 1)            257         ['concatenate_22[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 147: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 167: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 187: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 207: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 227: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_263\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_264 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_489 (Conv1D)            (None, 100, 128)     73856       ['input_264[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 100, 128)    512         ['conv1d_489[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 100, 128)     0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_490 (Conv1D)            (None, 100, 256)     164096      ['activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 100, 256)    1024        ['conv1d_490[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 100, 256)     0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_491 (Conv1D)            (None, 100, 128)     98432       ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " permute_23 (Permute)           (None, 72, 100)      0           ['input_264[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 100, 128)    512         ['conv1d_491[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_203 (LSTM)                (None, 128)          117248      ['permute_23[0][0]']             \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 100, 128)     0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_263 (Dropout)          (None, 128)          0           ['lstm_203[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_23 (G  (None, 128)         0           ['activation_71[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_23 (Concatenate)   (None, 256)          0           ['dropout_263[0][0]',            \n",
      "                                                                  'global_average_pooling1d_23[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_473 (Dense)              (None, 1)            257         ['concatenate_23[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 110: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 171: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 191: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 211: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Model: \"model_264\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_265 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_492 (Conv1D)            (None, 100, 128)     73856       ['input_265[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 100, 128)    512         ['conv1d_492[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 100, 128)     0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_493 (Conv1D)            (None, 100, 256)     164096      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 100, 256)    1024        ['conv1d_493[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 100, 256)     0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_494 (Conv1D)            (None, 100, 128)     98432       ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " permute_24 (Permute)           (None, 72, 100)      0           ['input_265[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 100, 128)    512         ['conv1d_494[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_204 (LSTM)                (None, 128)          117248      ['permute_24[0][0]']             \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 100, 128)     0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_264 (Dropout)          (None, 128)          0           ['lstm_204[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_24 (G  (None, 128)         0           ['activation_74[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_24 (Concatenate)   (None, 256)          0           ['dropout_264[0][0]',            \n",
      "                                                                  'global_average_pooling1d_24[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_474 (Dense)              (None, 1)            257         ['concatenate_24[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 203: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 226: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 246: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 266: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 286: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\n",
      "Epoch 306: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "Model: \"model_265\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_266 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_495 (Conv1D)            (None, 100, 128)     73856       ['input_266[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 100, 128)    512         ['conv1d_495[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 100, 128)     0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_496 (Conv1D)            (None, 100, 256)     164096      ['activation_75[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 100, 256)    1024        ['conv1d_496[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 100, 256)     0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_497 (Conv1D)            (None, 100, 128)     98432       ['activation_76[0][0]']          \n",
      "                                                                                                  \n",
      " permute_25 (Permute)           (None, 72, 100)      0           ['input_266[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 100, 128)    512         ['conv1d_497[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_205 (LSTM)                (None, 128)          117248      ['permute_25[0][0]']             \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 100, 128)     0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_265 (Dropout)          (None, 128)          0           ['lstm_205[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_25 (G  (None, 128)         0           ['activation_77[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_25 (Concatenate)   (None, 256)          0           ['dropout_265[0][0]',            \n",
      "                                                                  'global_average_pooling1d_25[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_475 (Dense)              (None, 1)            257         ['concatenate_25[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_266\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_267 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_498 (Conv1D)            (None, 100, 128)     73856       ['input_267[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 100, 128)    512         ['conv1d_498[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 100, 128)     0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_499 (Conv1D)            (None, 100, 256)     164096      ['activation_78[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 100, 256)    1024        ['conv1d_499[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 100, 256)     0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_500 (Conv1D)            (None, 100, 128)     98432       ['activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " permute_26 (Permute)           (None, 72, 100)      0           ['input_267[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 100, 128)    512         ['conv1d_500[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_206 (LSTM)                (None, 128)          117248      ['permute_26[0][0]']             \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 100, 128)     0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_266 (Dropout)          (None, 128)          0           ['lstm_206[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_26 (G  (None, 128)         0           ['activation_80[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_26 (Concatenate)   (None, 256)          0           ['dropout_266[0][0]',            \n",
      "                                                                  'global_average_pooling1d_26[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_476 (Dense)              (None, 1)            257         ['concatenate_26[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 192: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 212: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 232: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 252: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_267\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_268 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_501 (Conv1D)            (None, 100, 128)     73856       ['input_268[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 100, 128)    512         ['conv1d_501[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 100, 128)     0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_502 (Conv1D)            (None, 100, 256)     164096      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 100, 256)    1024        ['conv1d_502[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 100, 256)     0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_503 (Conv1D)            (None, 100, 128)     98432       ['activation_82[0][0]']          \n",
      "                                                                                                  \n",
      " permute_27 (Permute)           (None, 72, 100)      0           ['input_268[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 100, 128)    512         ['conv1d_503[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_207 (LSTM)                (None, 128)          117248      ['permute_27[0][0]']             \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 100, 128)     0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_267 (Dropout)          (None, 128)          0           ['lstm_207[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_27 (G  (None, 128)         0           ['activation_83[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_27 (Concatenate)   (None, 256)          0           ['dropout_267[0][0]',            \n",
      "                                                                  'global_average_pooling1d_27[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_477 (Dense)              (None, 1)            257         ['concatenate_27[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 155: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 193: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 213: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 233: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 253: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 273: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Model: \"model_268\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_269 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_504 (Conv1D)            (None, 100, 128)     73856       ['input_269[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 100, 128)    512         ['conv1d_504[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 100, 128)     0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_505 (Conv1D)            (None, 100, 256)     164096      ['activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 100, 256)    1024        ['conv1d_505[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 100, 256)     0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_506 (Conv1D)            (None, 100, 128)     98432       ['activation_85[0][0]']          \n",
      "                                                                                                  \n",
      " permute_28 (Permute)           (None, 72, 100)      0           ['input_269[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 100, 128)    512         ['conv1d_506[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_208 (LSTM)                (None, 128)          117248      ['permute_28[0][0]']             \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 100, 128)     0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_268 (Dropout)          (None, 128)          0           ['lstm_208[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_28 (G  (None, 128)         0           ['activation_86[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_28 (Concatenate)   (None, 256)          0           ['dropout_268[0][0]',            \n",
      "                                                                  'global_average_pooling1d_28[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_478 (Dense)              (None, 1)            257         ['concatenate_28[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 183: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 203: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_269\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_270 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_507 (Conv1D)            (None, 100, 128)     73856       ['input_270[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 100, 128)    512         ['conv1d_507[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 100, 128)     0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_508 (Conv1D)            (None, 100, 256)     164096      ['activation_87[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 100, 256)    1024        ['conv1d_508[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 100, 256)     0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_509 (Conv1D)            (None, 100, 128)     98432       ['activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " permute_29 (Permute)           (None, 72, 100)      0           ['input_270[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 100, 128)    512         ['conv1d_509[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_209 (LSTM)                (None, 128)          117248      ['permute_29[0][0]']             \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 100, 128)     0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_269 (Dropout)          (None, 128)          0           ['lstm_209[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_29 (G  (None, 128)         0           ['activation_89[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_29 (Concatenate)   (None, 256)          0           ['dropout_269[0][0]',            \n",
      "                                                                  'global_average_pooling1d_29[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_479 (Dense)              (None, 1)            257         ['concatenate_29[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,937\n",
      "Trainable params: 454,913\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 160: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 200: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 220: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 240: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 260: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 280: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "##################################################\n",
      "model:  cnn_resnet\n",
      "Model: \"model_270\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_271 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_510 (Conv1D)            (None, 100, 64)      36928       ['input_271[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 100, 64)     256         ['conv1d_510[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 100, 64)      0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_511 (Conv1D)            (None, 100, 64)      20544       ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 100, 64)     256         ['conv1d_511[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 100, 64)      0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_512 (Conv1D)            (None, 100, 64)      12352       ['activation_91[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_513 (Conv1D)            (None, 100, 64)      4672        ['input_271[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 100, 64)     256         ['conv1d_512[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 100, 64)     256         ['conv1d_513[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 100, 64)      0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 100, 64)      0           ['batch_normalization_93[0][0]', \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 100, 64)      0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_514 (Conv1D)            (None, 100, 128)     65664       ['activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, 100, 128)    512         ['conv1d_514[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_94 (Activation)     (None, 100, 128)     0           ['batch_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_515 (Conv1D)            (None, 100, 128)     82048       ['activation_94[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, 100, 128)    512         ['conv1d_515[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_95 (Activation)     (None, 100, 128)     0           ['batch_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_516 (Conv1D)            (None, 100, 128)     49280       ['activation_95[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_517 (Conv1D)            (None, 100, 128)     8320        ['activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_96 (BatchN  (None, 100, 128)    512         ['conv1d_516[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_97 (BatchN  (None, 100, 128)    512         ['conv1d_517[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_96 (Activation)     (None, 100, 128)     0           ['batch_normalization_96[0][0]'] \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 100, 128)     0           ['batch_normalization_97[0][0]', \n",
      "                                                                  'activation_96[0][0]']          \n",
      "                                                                                                  \n",
      " activation_97 (Activation)     (None, 100, 128)     0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_518 (Conv1D)            (None, 100, 128)     131200      ['activation_97[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_98 (BatchN  (None, 100, 128)    512         ['conv1d_518[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_98 (Activation)     (None, 100, 128)     0           ['batch_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_519 (Conv1D)            (None, 100, 128)     82048       ['activation_98[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_99 (BatchN  (None, 100, 128)    512         ['conv1d_519[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_99 (Activation)     (None, 100, 128)     0           ['batch_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_520 (Conv1D)            (None, 100, 128)     49280       ['activation_99[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_100 (Batch  (None, 100, 128)    512         ['conv1d_520[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_101 (Batch  (None, 100, 128)    512         ['activation_97[0][0]']          \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_100 (Activation)    (None, 100, 128)     0           ['batch_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 100, 128)     0           ['batch_normalization_101[0][0]',\n",
      "                                                                  'activation_100[0][0]']         \n",
      "                                                                                                  \n",
      " activation_101 (Activation)    (None, 100, 128)     0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_30 (G  (None, 128)         0           ['activation_101[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_480 (Dense)              (None, 1)            129         ['global_average_pooling1d_30[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 202: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_271\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_272 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_521 (Conv1D)            (None, 100, 64)      36928       ['input_272[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_102 (Batch  (None, 100, 64)     256         ['conv1d_521[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_102 (Activation)    (None, 100, 64)      0           ['batch_normalization_102[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_522 (Conv1D)            (None, 100, 64)      20544       ['activation_102[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_103 (Batch  (None, 100, 64)     256         ['conv1d_522[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_103 (Activation)    (None, 100, 64)      0           ['batch_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_523 (Conv1D)            (None, 100, 64)      12352       ['activation_103[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_524 (Conv1D)            (None, 100, 64)      4672        ['input_272[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_104 (Batch  (None, 100, 64)     256         ['conv1d_523[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_105 (Batch  (None, 100, 64)     256         ['conv1d_524[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_104 (Activation)    (None, 100, 64)      0           ['batch_normalization_104[0][0]']\n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 100, 64)      0           ['batch_normalization_105[0][0]',\n",
      "                                                                  'activation_104[0][0]']         \n",
      "                                                                                                  \n",
      " activation_105 (Activation)    (None, 100, 64)      0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_525 (Conv1D)            (None, 100, 128)     65664       ['activation_105[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_106 (Batch  (None, 100, 128)    512         ['conv1d_525[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_106 (Activation)    (None, 100, 128)     0           ['batch_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_526 (Conv1D)            (None, 100, 128)     82048       ['activation_106[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_107 (Batch  (None, 100, 128)    512         ['conv1d_526[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_107 (Activation)    (None, 100, 128)     0           ['batch_normalization_107[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_527 (Conv1D)            (None, 100, 128)     49280       ['activation_107[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_528 (Conv1D)            (None, 100, 128)     8320        ['activation_105[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_108 (Batch  (None, 100, 128)    512         ['conv1d_527[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_109 (Batch  (None, 100, 128)    512         ['conv1d_528[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_108 (Activation)    (None, 100, 128)     0           ['batch_normalization_108[0][0]']\n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 100, 128)     0           ['batch_normalization_109[0][0]',\n",
      "                                                                  'activation_108[0][0]']         \n",
      "                                                                                                  \n",
      " activation_109 (Activation)    (None, 100, 128)     0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_529 (Conv1D)            (None, 100, 128)     131200      ['activation_109[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_110 (Batch  (None, 100, 128)    512         ['conv1d_529[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_110 (Activation)    (None, 100, 128)     0           ['batch_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_530 (Conv1D)            (None, 100, 128)     82048       ['activation_110[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_111 (Batch  (None, 100, 128)    512         ['conv1d_530[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_111 (Activation)    (None, 100, 128)     0           ['batch_normalization_111[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_531 (Conv1D)            (None, 100, 128)     49280       ['activation_111[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_112 (Batch  (None, 100, 128)    512         ['conv1d_531[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_113 (Batch  (None, 100, 128)    512         ['activation_109[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_112 (Activation)    (None, 100, 128)     0           ['batch_normalization_112[0][0]']\n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 100, 128)     0           ['batch_normalization_113[0][0]',\n",
      "                                                                  'activation_112[0][0]']         \n",
      "                                                                                                  \n",
      " activation_113 (Activation)    (None, 100, 128)     0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_31 (G  (None, 128)         0           ['activation_113[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_481 (Dense)              (None, 1)            129         ['global_average_pooling1d_31[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 183: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 203: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 223: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_272\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_273 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_532 (Conv1D)            (None, 100, 64)      36928       ['input_273[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_114 (Batch  (None, 100, 64)     256         ['conv1d_532[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_114 (Activation)    (None, 100, 64)      0           ['batch_normalization_114[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_533 (Conv1D)            (None, 100, 64)      20544       ['activation_114[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_115 (Batch  (None, 100, 64)     256         ['conv1d_533[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_115 (Activation)    (None, 100, 64)      0           ['batch_normalization_115[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_534 (Conv1D)            (None, 100, 64)      12352       ['activation_115[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_535 (Conv1D)            (None, 100, 64)      4672        ['input_273[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_116 (Batch  (None, 100, 64)     256         ['conv1d_534[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_117 (Batch  (None, 100, 64)     256         ['conv1d_535[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_116 (Activation)    (None, 100, 64)      0           ['batch_normalization_116[0][0]']\n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 100, 64)      0           ['batch_normalization_117[0][0]',\n",
      "                                                                  'activation_116[0][0]']         \n",
      "                                                                                                  \n",
      " activation_117 (Activation)    (None, 100, 64)      0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_536 (Conv1D)            (None, 100, 128)     65664       ['activation_117[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_118 (Batch  (None, 100, 128)    512         ['conv1d_536[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_118 (Activation)    (None, 100, 128)     0           ['batch_normalization_118[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_537 (Conv1D)            (None, 100, 128)     82048       ['activation_118[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_119 (Batch  (None, 100, 128)    512         ['conv1d_537[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_119 (Activation)    (None, 100, 128)     0           ['batch_normalization_119[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_538 (Conv1D)            (None, 100, 128)     49280       ['activation_119[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_539 (Conv1D)            (None, 100, 128)     8320        ['activation_117[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_120 (Batch  (None, 100, 128)    512         ['conv1d_538[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_121 (Batch  (None, 100, 128)    512         ['conv1d_539[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_120 (Activation)    (None, 100, 128)     0           ['batch_normalization_120[0][0]']\n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 100, 128)     0           ['batch_normalization_121[0][0]',\n",
      "                                                                  'activation_120[0][0]']         \n",
      "                                                                                                  \n",
      " activation_121 (Activation)    (None, 100, 128)     0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_540 (Conv1D)            (None, 100, 128)     131200      ['activation_121[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_122 (Batch  (None, 100, 128)    512         ['conv1d_540[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_122 (Activation)    (None, 100, 128)     0           ['batch_normalization_122[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_541 (Conv1D)            (None, 100, 128)     82048       ['activation_122[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_123 (Batch  (None, 100, 128)    512         ['conv1d_541[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_123 (Activation)    (None, 100, 128)     0           ['batch_normalization_123[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_542 (Conv1D)            (None, 100, 128)     49280       ['activation_123[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_124 (Batch  (None, 100, 128)    512         ['conv1d_542[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_125 (Batch  (None, 100, 128)    512         ['activation_121[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_124 (Activation)    (None, 100, 128)     0           ['batch_normalization_124[0][0]']\n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 100, 128)     0           ['batch_normalization_125[0][0]',\n",
      "                                                                  'activation_124[0][0]']         \n",
      "                                                                                                  \n",
      " activation_125 (Activation)    (None, 100, 128)     0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_32 (G  (None, 128)         0           ['activation_125[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_482 (Dense)              (None, 1)            129         ['global_average_pooling1d_32[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 202: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_273\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_274 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_543 (Conv1D)            (None, 100, 64)      36928       ['input_274[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_126 (Batch  (None, 100, 64)     256         ['conv1d_543[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_126 (Activation)    (None, 100, 64)      0           ['batch_normalization_126[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_544 (Conv1D)            (None, 100, 64)      20544       ['activation_126[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_127 (Batch  (None, 100, 64)     256         ['conv1d_544[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_127 (Activation)    (None, 100, 64)      0           ['batch_normalization_127[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_545 (Conv1D)            (None, 100, 64)      12352       ['activation_127[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_546 (Conv1D)            (None, 100, 64)      4672        ['input_274[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_128 (Batch  (None, 100, 64)     256         ['conv1d_545[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_129 (Batch  (None, 100, 64)     256         ['conv1d_546[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_128 (Activation)    (None, 100, 64)      0           ['batch_normalization_128[0][0]']\n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 100, 64)      0           ['batch_normalization_129[0][0]',\n",
      "                                                                  'activation_128[0][0]']         \n",
      "                                                                                                  \n",
      " activation_129 (Activation)    (None, 100, 64)      0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_547 (Conv1D)            (None, 100, 128)     65664       ['activation_129[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_130 (Batch  (None, 100, 128)    512         ['conv1d_547[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_130 (Activation)    (None, 100, 128)     0           ['batch_normalization_130[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_548 (Conv1D)            (None, 100, 128)     82048       ['activation_130[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_131 (Batch  (None, 100, 128)    512         ['conv1d_548[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_131 (Activation)    (None, 100, 128)     0           ['batch_normalization_131[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_549 (Conv1D)            (None, 100, 128)     49280       ['activation_131[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_550 (Conv1D)            (None, 100, 128)     8320        ['activation_129[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_132 (Batch  (None, 100, 128)    512         ['conv1d_549[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_133 (Batch  (None, 100, 128)    512         ['conv1d_550[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_132 (Activation)    (None, 100, 128)     0           ['batch_normalization_132[0][0]']\n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 100, 128)     0           ['batch_normalization_133[0][0]',\n",
      "                                                                  'activation_132[0][0]']         \n",
      "                                                                                                  \n",
      " activation_133 (Activation)    (None, 100, 128)     0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_551 (Conv1D)            (None, 100, 128)     131200      ['activation_133[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_134 (Batch  (None, 100, 128)    512         ['conv1d_551[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_134 (Activation)    (None, 100, 128)     0           ['batch_normalization_134[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_552 (Conv1D)            (None, 100, 128)     82048       ['activation_134[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_135 (Batch  (None, 100, 128)    512         ['conv1d_552[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_135 (Activation)    (None, 100, 128)     0           ['batch_normalization_135[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_553 (Conv1D)            (None, 100, 128)     49280       ['activation_135[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_136 (Batch  (None, 100, 128)    512         ['conv1d_553[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_137 (Batch  (None, 100, 128)    512         ['activation_133[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_136 (Activation)    (None, 100, 128)     0           ['batch_normalization_136[0][0]']\n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 100, 128)     0           ['batch_normalization_137[0][0]',\n",
      "                                                                  'activation_136[0][0]']         \n",
      "                                                                                                  \n",
      " activation_137 (Activation)    (None, 100, 128)     0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_33 (G  (None, 128)         0           ['activation_137[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_483 (Dense)              (None, 1)            129         ['global_average_pooling1d_33[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 119: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 232: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 252: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 272: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 292: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 312: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_274\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_275 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_554 (Conv1D)            (None, 100, 64)      36928       ['input_275[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_138 (Batch  (None, 100, 64)     256         ['conv1d_554[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_138 (Activation)    (None, 100, 64)      0           ['batch_normalization_138[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_555 (Conv1D)            (None, 100, 64)      20544       ['activation_138[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_139 (Batch  (None, 100, 64)     256         ['conv1d_555[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_139 (Activation)    (None, 100, 64)      0           ['batch_normalization_139[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_556 (Conv1D)            (None, 100, 64)      12352       ['activation_139[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_557 (Conv1D)            (None, 100, 64)      4672        ['input_275[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_140 (Batch  (None, 100, 64)     256         ['conv1d_556[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_141 (Batch  (None, 100, 64)     256         ['conv1d_557[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_140 (Activation)    (None, 100, 64)      0           ['batch_normalization_140[0][0]']\n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 100, 64)      0           ['batch_normalization_141[0][0]',\n",
      "                                                                  'activation_140[0][0]']         \n",
      "                                                                                                  \n",
      " activation_141 (Activation)    (None, 100, 64)      0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_558 (Conv1D)            (None, 100, 128)     65664       ['activation_141[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_142 (Batch  (None, 100, 128)    512         ['conv1d_558[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_142 (Activation)    (None, 100, 128)     0           ['batch_normalization_142[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_559 (Conv1D)            (None, 100, 128)     82048       ['activation_142[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_143 (Batch  (None, 100, 128)    512         ['conv1d_559[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_143 (Activation)    (None, 100, 128)     0           ['batch_normalization_143[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_560 (Conv1D)            (None, 100, 128)     49280       ['activation_143[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_561 (Conv1D)            (None, 100, 128)     8320        ['activation_141[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_144 (Batch  (None, 100, 128)    512         ['conv1d_560[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_145 (Batch  (None, 100, 128)    512         ['conv1d_561[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_144 (Activation)    (None, 100, 128)     0           ['batch_normalization_144[0][0]']\n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 100, 128)     0           ['batch_normalization_145[0][0]',\n",
      "                                                                  'activation_144[0][0]']         \n",
      "                                                                                                  \n",
      " activation_145 (Activation)    (None, 100, 128)     0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_562 (Conv1D)            (None, 100, 128)     131200      ['activation_145[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_146 (Batch  (None, 100, 128)    512         ['conv1d_562[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_146 (Activation)    (None, 100, 128)     0           ['batch_normalization_146[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_563 (Conv1D)            (None, 100, 128)     82048       ['activation_146[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_147 (Batch  (None, 100, 128)    512         ['conv1d_563[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_147 (Activation)    (None, 100, 128)     0           ['batch_normalization_147[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_564 (Conv1D)            (None, 100, 128)     49280       ['activation_147[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_148 (Batch  (None, 100, 128)    512         ['conv1d_564[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_149 (Batch  (None, 100, 128)    512         ['activation_145[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_148 (Activation)    (None, 100, 128)     0           ['batch_normalization_148[0][0]']\n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 100, 128)     0           ['batch_normalization_149[0][0]',\n",
      "                                                                  'activation_148[0][0]']         \n",
      "                                                                                                  \n",
      " activation_149 (Activation)    (None, 100, 128)     0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_34 (G  (None, 128)         0           ['activation_149[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_484 (Dense)              (None, 1)            129         ['global_average_pooling1d_34[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 192: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 212: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 232: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_275\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_276 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_565 (Conv1D)            (None, 100, 64)      36928       ['input_276[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_150 (Batch  (None, 100, 64)     256         ['conv1d_565[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_150 (Activation)    (None, 100, 64)      0           ['batch_normalization_150[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_566 (Conv1D)            (None, 100, 64)      20544       ['activation_150[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_151 (Batch  (None, 100, 64)     256         ['conv1d_566[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_151 (Activation)    (None, 100, 64)      0           ['batch_normalization_151[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_567 (Conv1D)            (None, 100, 64)      12352       ['activation_151[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_568 (Conv1D)            (None, 100, 64)      4672        ['input_276[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_152 (Batch  (None, 100, 64)     256         ['conv1d_567[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_153 (Batch  (None, 100, 64)     256         ['conv1d_568[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_152 (Activation)    (None, 100, 64)      0           ['batch_normalization_152[0][0]']\n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 100, 64)      0           ['batch_normalization_153[0][0]',\n",
      "                                                                  'activation_152[0][0]']         \n",
      "                                                                                                  \n",
      " activation_153 (Activation)    (None, 100, 64)      0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_569 (Conv1D)            (None, 100, 128)     65664       ['activation_153[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_154 (Batch  (None, 100, 128)    512         ['conv1d_569[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_154 (Activation)    (None, 100, 128)     0           ['batch_normalization_154[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_570 (Conv1D)            (None, 100, 128)     82048       ['activation_154[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_155 (Batch  (None, 100, 128)    512         ['conv1d_570[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_155 (Activation)    (None, 100, 128)     0           ['batch_normalization_155[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_571 (Conv1D)            (None, 100, 128)     49280       ['activation_155[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_572 (Conv1D)            (None, 100, 128)     8320        ['activation_153[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_156 (Batch  (None, 100, 128)    512         ['conv1d_571[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_157 (Batch  (None, 100, 128)    512         ['conv1d_572[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_156 (Activation)    (None, 100, 128)     0           ['batch_normalization_156[0][0]']\n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 100, 128)     0           ['batch_normalization_157[0][0]',\n",
      "                                                                  'activation_156[0][0]']         \n",
      "                                                                                                  \n",
      " activation_157 (Activation)    (None, 100, 128)     0           ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_573 (Conv1D)            (None, 100, 128)     131200      ['activation_157[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_158 (Batch  (None, 100, 128)    512         ['conv1d_573[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_158 (Activation)    (None, 100, 128)     0           ['batch_normalization_158[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_574 (Conv1D)            (None, 100, 128)     82048       ['activation_158[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_159 (Batch  (None, 100, 128)    512         ['conv1d_574[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_159 (Activation)    (None, 100, 128)     0           ['batch_normalization_159[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_575 (Conv1D)            (None, 100, 128)     49280       ['activation_159[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_160 (Batch  (None, 100, 128)    512         ['conv1d_575[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_161 (Batch  (None, 100, 128)    512         ['activation_157[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_160 (Activation)    (None, 100, 128)     0           ['batch_normalization_160[0][0]']\n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 100, 128)     0           ['batch_normalization_161[0][0]',\n",
      "                                                                  'activation_160[0][0]']         \n",
      "                                                                                                  \n",
      " activation_161 (Activation)    (None, 100, 128)     0           ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_35 (G  (None, 128)         0           ['activation_161[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_485 (Dense)              (None, 1)            129         ['global_average_pooling1d_35[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 174: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 194: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_276\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_277 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_576 (Conv1D)            (None, 100, 64)      36928       ['input_277[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_162 (Batch  (None, 100, 64)     256         ['conv1d_576[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_162 (Activation)    (None, 100, 64)      0           ['batch_normalization_162[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_577 (Conv1D)            (None, 100, 64)      20544       ['activation_162[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_163 (Batch  (None, 100, 64)     256         ['conv1d_577[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_163 (Activation)    (None, 100, 64)      0           ['batch_normalization_163[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_578 (Conv1D)            (None, 100, 64)      12352       ['activation_163[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_579 (Conv1D)            (None, 100, 64)      4672        ['input_277[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_164 (Batch  (None, 100, 64)     256         ['conv1d_578[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_165 (Batch  (None, 100, 64)     256         ['conv1d_579[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_164 (Activation)    (None, 100, 64)      0           ['batch_normalization_164[0][0]']\n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 100, 64)      0           ['batch_normalization_165[0][0]',\n",
      "                                                                  'activation_164[0][0]']         \n",
      "                                                                                                  \n",
      " activation_165 (Activation)    (None, 100, 64)      0           ['add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_580 (Conv1D)            (None, 100, 128)     65664       ['activation_165[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_166 (Batch  (None, 100, 128)    512         ['conv1d_580[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_166 (Activation)    (None, 100, 128)     0           ['batch_normalization_166[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_581 (Conv1D)            (None, 100, 128)     82048       ['activation_166[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_167 (Batch  (None, 100, 128)    512         ['conv1d_581[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_167 (Activation)    (None, 100, 128)     0           ['batch_normalization_167[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_582 (Conv1D)            (None, 100, 128)     49280       ['activation_167[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_583 (Conv1D)            (None, 100, 128)     8320        ['activation_165[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_168 (Batch  (None, 100, 128)    512         ['conv1d_582[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_169 (Batch  (None, 100, 128)    512         ['conv1d_583[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_168 (Activation)    (None, 100, 128)     0           ['batch_normalization_168[0][0]']\n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 100, 128)     0           ['batch_normalization_169[0][0]',\n",
      "                                                                  'activation_168[0][0]']         \n",
      "                                                                                                  \n",
      " activation_169 (Activation)    (None, 100, 128)     0           ['add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_584 (Conv1D)            (None, 100, 128)     131200      ['activation_169[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_170 (Batch  (None, 100, 128)    512         ['conv1d_584[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_170 (Activation)    (None, 100, 128)     0           ['batch_normalization_170[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_585 (Conv1D)            (None, 100, 128)     82048       ['activation_170[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_171 (Batch  (None, 100, 128)    512         ['conv1d_585[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_171 (Activation)    (None, 100, 128)     0           ['batch_normalization_171[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_586 (Conv1D)            (None, 100, 128)     49280       ['activation_171[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_172 (Batch  (None, 100, 128)    512         ['conv1d_586[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_173 (Batch  (None, 100, 128)    512         ['activation_169[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_172 (Activation)    (None, 100, 128)     0           ['batch_normalization_172[0][0]']\n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 100, 128)     0           ['batch_normalization_173[0][0]',\n",
      "                                                                  'activation_172[0][0]']         \n",
      "                                                                                                  \n",
      " activation_173 (Activation)    (None, 100, 128)     0           ['add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_36 (G  (None, 128)         0           ['activation_173[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_486 (Dense)              (None, 1)            129         ['global_average_pooling1d_36[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 138: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 158: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 206: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 226: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 246: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 266: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 286: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_277\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_278 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_587 (Conv1D)            (None, 100, 64)      36928       ['input_278[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_174 (Batch  (None, 100, 64)     256         ['conv1d_587[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_174 (Activation)    (None, 100, 64)      0           ['batch_normalization_174[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_588 (Conv1D)            (None, 100, 64)      20544       ['activation_174[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_175 (Batch  (None, 100, 64)     256         ['conv1d_588[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_175 (Activation)    (None, 100, 64)      0           ['batch_normalization_175[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_589 (Conv1D)            (None, 100, 64)      12352       ['activation_175[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_590 (Conv1D)            (None, 100, 64)      4672        ['input_278[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_176 (Batch  (None, 100, 64)     256         ['conv1d_589[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_177 (Batch  (None, 100, 64)     256         ['conv1d_590[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_176 (Activation)    (None, 100, 64)      0           ['batch_normalization_176[0][0]']\n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 100, 64)      0           ['batch_normalization_177[0][0]',\n",
      "                                                                  'activation_176[0][0]']         \n",
      "                                                                                                  \n",
      " activation_177 (Activation)    (None, 100, 64)      0           ['add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_591 (Conv1D)            (None, 100, 128)     65664       ['activation_177[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_178 (Batch  (None, 100, 128)    512         ['conv1d_591[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_178 (Activation)    (None, 100, 128)     0           ['batch_normalization_178[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_592 (Conv1D)            (None, 100, 128)     82048       ['activation_178[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_179 (Batch  (None, 100, 128)    512         ['conv1d_592[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_179 (Activation)    (None, 100, 128)     0           ['batch_normalization_179[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_593 (Conv1D)            (None, 100, 128)     49280       ['activation_179[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_594 (Conv1D)            (None, 100, 128)     8320        ['activation_177[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_180 (Batch  (None, 100, 128)    512         ['conv1d_593[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_181 (Batch  (None, 100, 128)    512         ['conv1d_594[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_180 (Activation)    (None, 100, 128)     0           ['batch_normalization_180[0][0]']\n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 100, 128)     0           ['batch_normalization_181[0][0]',\n",
      "                                                                  'activation_180[0][0]']         \n",
      "                                                                                                  \n",
      " activation_181 (Activation)    (None, 100, 128)     0           ['add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_595 (Conv1D)            (None, 100, 128)     131200      ['activation_181[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_182 (Batch  (None, 100, 128)    512         ['conv1d_595[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_182 (Activation)    (None, 100, 128)     0           ['batch_normalization_182[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_596 (Conv1D)            (None, 100, 128)     82048       ['activation_182[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_183 (Batch  (None, 100, 128)    512         ['conv1d_596[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_183 (Activation)    (None, 100, 128)     0           ['batch_normalization_183[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_597 (Conv1D)            (None, 100, 128)     49280       ['activation_183[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_184 (Batch  (None, 100, 128)    512         ['conv1d_597[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_185 (Batch  (None, 100, 128)    512         ['activation_181[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_184 (Activation)    (None, 100, 128)     0           ['batch_normalization_184[0][0]']\n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 100, 128)     0           ['batch_normalization_185[0][0]',\n",
      "                                                                  'activation_184[0][0]']         \n",
      "                                                                                                  \n",
      " activation_185 (Activation)    (None, 100, 128)     0           ['add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_37 (G  (None, 128)         0           ['activation_185[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_487 (Dense)              (None, 1)            129         ['global_average_pooling1d_37[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 174: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 196: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 225: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 245: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 265: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 285: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 305: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_278\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_279 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_598 (Conv1D)            (None, 100, 64)      36928       ['input_279[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_186 (Batch  (None, 100, 64)     256         ['conv1d_598[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_186 (Activation)    (None, 100, 64)      0           ['batch_normalization_186[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_599 (Conv1D)            (None, 100, 64)      20544       ['activation_186[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_187 (Batch  (None, 100, 64)     256         ['conv1d_599[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_187 (Activation)    (None, 100, 64)      0           ['batch_normalization_187[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_600 (Conv1D)            (None, 100, 64)      12352       ['activation_187[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_601 (Conv1D)            (None, 100, 64)      4672        ['input_279[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_188 (Batch  (None, 100, 64)     256         ['conv1d_600[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_189 (Batch  (None, 100, 64)     256         ['conv1d_601[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_188 (Activation)    (None, 100, 64)      0           ['batch_normalization_188[0][0]']\n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 100, 64)      0           ['batch_normalization_189[0][0]',\n",
      "                                                                  'activation_188[0][0]']         \n",
      "                                                                                                  \n",
      " activation_189 (Activation)    (None, 100, 64)      0           ['add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_602 (Conv1D)            (None, 100, 128)     65664       ['activation_189[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_190 (Batch  (None, 100, 128)    512         ['conv1d_602[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_190 (Activation)    (None, 100, 128)     0           ['batch_normalization_190[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_603 (Conv1D)            (None, 100, 128)     82048       ['activation_190[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_191 (Batch  (None, 100, 128)    512         ['conv1d_603[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_191 (Activation)    (None, 100, 128)     0           ['batch_normalization_191[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_604 (Conv1D)            (None, 100, 128)     49280       ['activation_191[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_605 (Conv1D)            (None, 100, 128)     8320        ['activation_189[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_192 (Batch  (None, 100, 128)    512         ['conv1d_604[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_193 (Batch  (None, 100, 128)    512         ['conv1d_605[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_192 (Activation)    (None, 100, 128)     0           ['batch_normalization_192[0][0]']\n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 100, 128)     0           ['batch_normalization_193[0][0]',\n",
      "                                                                  'activation_192[0][0]']         \n",
      "                                                                                                  \n",
      " activation_193 (Activation)    (None, 100, 128)     0           ['add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_606 (Conv1D)            (None, 100, 128)     131200      ['activation_193[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_194 (Batch  (None, 100, 128)    512         ['conv1d_606[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_194 (Activation)    (None, 100, 128)     0           ['batch_normalization_194[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_607 (Conv1D)            (None, 100, 128)     82048       ['activation_194[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_195 (Batch  (None, 100, 128)    512         ['conv1d_607[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_195 (Activation)    (None, 100, 128)     0           ['batch_normalization_195[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_608 (Conv1D)            (None, 100, 128)     49280       ['activation_195[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_196 (Batch  (None, 100, 128)    512         ['conv1d_608[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_197 (Batch  (None, 100, 128)    512         ['activation_193[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_196 (Activation)    (None, 100, 128)     0           ['batch_normalization_196[0][0]']\n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 100, 128)     0           ['batch_normalization_197[0][0]',\n",
      "                                                                  'activation_196[0][0]']         \n",
      "                                                                                                  \n",
      " activation_197 (Activation)    (None, 100, 128)     0           ['add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_38 (G  (None, 128)         0           ['activation_197[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_488 (Dense)              (None, 1)            129         ['global_average_pooling1d_38[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 206: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 236: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 267: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 307: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 327: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 347: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 367: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Model: \"model_279\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_280 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_609 (Conv1D)            (None, 100, 64)      36928       ['input_280[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_198 (Batch  (None, 100, 64)     256         ['conv1d_609[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_198 (Activation)    (None, 100, 64)      0           ['batch_normalization_198[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_610 (Conv1D)            (None, 100, 64)      20544       ['activation_198[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_199 (Batch  (None, 100, 64)     256         ['conv1d_610[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_199 (Activation)    (None, 100, 64)      0           ['batch_normalization_199[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_611 (Conv1D)            (None, 100, 64)      12352       ['activation_199[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_612 (Conv1D)            (None, 100, 64)      4672        ['input_280[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_200 (Batch  (None, 100, 64)     256         ['conv1d_611[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_201 (Batch  (None, 100, 64)     256         ['conv1d_612[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_200 (Activation)    (None, 100, 64)      0           ['batch_normalization_200[0][0]']\n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 100, 64)      0           ['batch_normalization_201[0][0]',\n",
      "                                                                  'activation_200[0][0]']         \n",
      "                                                                                                  \n",
      " activation_201 (Activation)    (None, 100, 64)      0           ['add_27[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_613 (Conv1D)            (None, 100, 128)     65664       ['activation_201[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_202 (Batch  (None, 100, 128)    512         ['conv1d_613[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_202 (Activation)    (None, 100, 128)     0           ['batch_normalization_202[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_614 (Conv1D)            (None, 100, 128)     82048       ['activation_202[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_203 (Batch  (None, 100, 128)    512         ['conv1d_614[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_203 (Activation)    (None, 100, 128)     0           ['batch_normalization_203[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_615 (Conv1D)            (None, 100, 128)     49280       ['activation_203[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_616 (Conv1D)            (None, 100, 128)     8320        ['activation_201[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_204 (Batch  (None, 100, 128)    512         ['conv1d_615[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_205 (Batch  (None, 100, 128)    512         ['conv1d_616[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_204 (Activation)    (None, 100, 128)     0           ['batch_normalization_204[0][0]']\n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 100, 128)     0           ['batch_normalization_205[0][0]',\n",
      "                                                                  'activation_204[0][0]']         \n",
      "                                                                                                  \n",
      " activation_205 (Activation)    (None, 100, 128)     0           ['add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_617 (Conv1D)            (None, 100, 128)     131200      ['activation_205[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_206 (Batch  (None, 100, 128)    512         ['conv1d_617[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_206 (Activation)    (None, 100, 128)     0           ['batch_normalization_206[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_618 (Conv1D)            (None, 100, 128)     82048       ['activation_206[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_207 (Batch  (None, 100, 128)    512         ['conv1d_618[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_207 (Activation)    (None, 100, 128)     0           ['batch_normalization_207[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_619 (Conv1D)            (None, 100, 128)     49280       ['activation_207[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_208 (Batch  (None, 100, 128)    512         ['conv1d_619[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_209 (Batch  (None, 100, 128)    512         ['activation_205[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_208 (Activation)    (None, 100, 128)     0           ['batch_normalization_208[0][0]']\n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 100, 128)     0           ['batch_normalization_209[0][0]',\n",
      "                                                                  'activation_208[0][0]']         \n",
      "                                                                                                  \n",
      " activation_209 (Activation)    (None, 100, 128)     0           ['add_29[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_39 (G  (None, 128)         0           ['activation_209[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_489 (Dense)              (None, 1)            129         ['global_average_pooling1d_39[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 184: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 204: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 224: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 244: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 264: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_280\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_281 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_620 (Conv1D)            (None, 100, 64)      36928       ['input_281[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_210 (Batch  (None, 100, 64)     256         ['conv1d_620[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_210 (Activation)    (None, 100, 64)      0           ['batch_normalization_210[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_621 (Conv1D)            (None, 100, 64)      20544       ['activation_210[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_211 (Batch  (None, 100, 64)     256         ['conv1d_621[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_211 (Activation)    (None, 100, 64)      0           ['batch_normalization_211[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_622 (Conv1D)            (None, 100, 64)      12352       ['activation_211[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_623 (Conv1D)            (None, 100, 64)      4672        ['input_281[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_212 (Batch  (None, 100, 64)     256         ['conv1d_622[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_213 (Batch  (None, 100, 64)     256         ['conv1d_623[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_212 (Activation)    (None, 100, 64)      0           ['batch_normalization_212[0][0]']\n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 100, 64)      0           ['batch_normalization_213[0][0]',\n",
      "                                                                  'activation_212[0][0]']         \n",
      "                                                                                                  \n",
      " activation_213 (Activation)    (None, 100, 64)      0           ['add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_624 (Conv1D)            (None, 100, 128)     65664       ['activation_213[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_214 (Batch  (None, 100, 128)    512         ['conv1d_624[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_214 (Activation)    (None, 100, 128)     0           ['batch_normalization_214[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_625 (Conv1D)            (None, 100, 128)     82048       ['activation_214[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_215 (Batch  (None, 100, 128)    512         ['conv1d_625[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_215 (Activation)    (None, 100, 128)     0           ['batch_normalization_215[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_626 (Conv1D)            (None, 100, 128)     49280       ['activation_215[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_627 (Conv1D)            (None, 100, 128)     8320        ['activation_213[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_216 (Batch  (None, 100, 128)    512         ['conv1d_626[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_217 (Batch  (None, 100, 128)    512         ['conv1d_627[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_216 (Activation)    (None, 100, 128)     0           ['batch_normalization_216[0][0]']\n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 100, 128)     0           ['batch_normalization_217[0][0]',\n",
      "                                                                  'activation_216[0][0]']         \n",
      "                                                                                                  \n",
      " activation_217 (Activation)    (None, 100, 128)     0           ['add_31[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_628 (Conv1D)            (None, 100, 128)     131200      ['activation_217[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_218 (Batch  (None, 100, 128)    512         ['conv1d_628[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_218 (Activation)    (None, 100, 128)     0           ['batch_normalization_218[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_629 (Conv1D)            (None, 100, 128)     82048       ['activation_218[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_219 (Batch  (None, 100, 128)    512         ['conv1d_629[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_219 (Activation)    (None, 100, 128)     0           ['batch_normalization_219[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_630 (Conv1D)            (None, 100, 128)     49280       ['activation_219[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_220 (Batch  (None, 100, 128)    512         ['conv1d_630[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_221 (Batch  (None, 100, 128)    512         ['activation_217[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_220 (Activation)    (None, 100, 128)     0           ['batch_normalization_220[0][0]']\n",
      "                                                                                                  \n",
      " add_32 (Add)                   (None, 100, 128)     0           ['batch_normalization_221[0][0]',\n",
      "                                                                  'activation_220[0][0]']         \n",
      "                                                                                                  \n",
      " activation_221 (Activation)    (None, 100, 128)     0           ['add_32[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_40 (G  (None, 128)         0           ['activation_221[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_490 (Dense)              (None, 1)            129         ['global_average_pooling1d_40[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 183: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 203: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 223: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 243: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_281\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_282 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_631 (Conv1D)            (None, 100, 64)      36928       ['input_282[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_222 (Batch  (None, 100, 64)     256         ['conv1d_631[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_222 (Activation)    (None, 100, 64)      0           ['batch_normalization_222[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_632 (Conv1D)            (None, 100, 64)      20544       ['activation_222[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_223 (Batch  (None, 100, 64)     256         ['conv1d_632[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_223 (Activation)    (None, 100, 64)      0           ['batch_normalization_223[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_633 (Conv1D)            (None, 100, 64)      12352       ['activation_223[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_634 (Conv1D)            (None, 100, 64)      4672        ['input_282[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_224 (Batch  (None, 100, 64)     256         ['conv1d_633[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_225 (Batch  (None, 100, 64)     256         ['conv1d_634[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_224 (Activation)    (None, 100, 64)      0           ['batch_normalization_224[0][0]']\n",
      "                                                                                                  \n",
      " add_33 (Add)                   (None, 100, 64)      0           ['batch_normalization_225[0][0]',\n",
      "                                                                  'activation_224[0][0]']         \n",
      "                                                                                                  \n",
      " activation_225 (Activation)    (None, 100, 64)      0           ['add_33[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_635 (Conv1D)            (None, 100, 128)     65664       ['activation_225[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_226 (Batch  (None, 100, 128)    512         ['conv1d_635[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_226 (Activation)    (None, 100, 128)     0           ['batch_normalization_226[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_636 (Conv1D)            (None, 100, 128)     82048       ['activation_226[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_227 (Batch  (None, 100, 128)    512         ['conv1d_636[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_227 (Activation)    (None, 100, 128)     0           ['batch_normalization_227[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_637 (Conv1D)            (None, 100, 128)     49280       ['activation_227[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_638 (Conv1D)            (None, 100, 128)     8320        ['activation_225[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_228 (Batch  (None, 100, 128)    512         ['conv1d_637[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_229 (Batch  (None, 100, 128)    512         ['conv1d_638[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_228 (Activation)    (None, 100, 128)     0           ['batch_normalization_228[0][0]']\n",
      "                                                                                                  \n",
      " add_34 (Add)                   (None, 100, 128)     0           ['batch_normalization_229[0][0]',\n",
      "                                                                  'activation_228[0][0]']         \n",
      "                                                                                                  \n",
      " activation_229 (Activation)    (None, 100, 128)     0           ['add_34[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_639 (Conv1D)            (None, 100, 128)     131200      ['activation_229[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_230 (Batch  (None, 100, 128)    512         ['conv1d_639[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_230 (Activation)    (None, 100, 128)     0           ['batch_normalization_230[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_640 (Conv1D)            (None, 100, 128)     82048       ['activation_230[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_231 (Batch  (None, 100, 128)    512         ['conv1d_640[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_231 (Activation)    (None, 100, 128)     0           ['batch_normalization_231[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_641 (Conv1D)            (None, 100, 128)     49280       ['activation_231[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_232 (Batch  (None, 100, 128)    512         ['conv1d_641[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_233 (Batch  (None, 100, 128)    512         ['activation_229[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_232 (Activation)    (None, 100, 128)     0           ['batch_normalization_232[0][0]']\n",
      "                                                                                                  \n",
      " add_35 (Add)                   (None, 100, 128)     0           ['batch_normalization_233[0][0]',\n",
      "                                                                  'activation_232[0][0]']         \n",
      "                                                                                                  \n",
      " activation_233 (Activation)    (None, 100, 128)     0           ['add_35[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_41 (G  (None, 128)         0           ['activation_233[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_491 (Dense)              (None, 1)            129         ['global_average_pooling1d_41[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 155: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 175: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 195: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_282\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_283 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_642 (Conv1D)            (None, 100, 64)      36928       ['input_283[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_234 (Batch  (None, 100, 64)     256         ['conv1d_642[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_234 (Activation)    (None, 100, 64)      0           ['batch_normalization_234[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_643 (Conv1D)            (None, 100, 64)      20544       ['activation_234[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_235 (Batch  (None, 100, 64)     256         ['conv1d_643[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_235 (Activation)    (None, 100, 64)      0           ['batch_normalization_235[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_644 (Conv1D)            (None, 100, 64)      12352       ['activation_235[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_645 (Conv1D)            (None, 100, 64)      4672        ['input_283[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_236 (Batch  (None, 100, 64)     256         ['conv1d_644[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_237 (Batch  (None, 100, 64)     256         ['conv1d_645[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_236 (Activation)    (None, 100, 64)      0           ['batch_normalization_236[0][0]']\n",
      "                                                                                                  \n",
      " add_36 (Add)                   (None, 100, 64)      0           ['batch_normalization_237[0][0]',\n",
      "                                                                  'activation_236[0][0]']         \n",
      "                                                                                                  \n",
      " activation_237 (Activation)    (None, 100, 64)      0           ['add_36[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_646 (Conv1D)            (None, 100, 128)     65664       ['activation_237[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_238 (Batch  (None, 100, 128)    512         ['conv1d_646[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_238 (Activation)    (None, 100, 128)     0           ['batch_normalization_238[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_647 (Conv1D)            (None, 100, 128)     82048       ['activation_238[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_239 (Batch  (None, 100, 128)    512         ['conv1d_647[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_239 (Activation)    (None, 100, 128)     0           ['batch_normalization_239[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_648 (Conv1D)            (None, 100, 128)     49280       ['activation_239[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_649 (Conv1D)            (None, 100, 128)     8320        ['activation_237[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_240 (Batch  (None, 100, 128)    512         ['conv1d_648[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_241 (Batch  (None, 100, 128)    512         ['conv1d_649[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_240 (Activation)    (None, 100, 128)     0           ['batch_normalization_240[0][0]']\n",
      "                                                                                                  \n",
      " add_37 (Add)                   (None, 100, 128)     0           ['batch_normalization_241[0][0]',\n",
      "                                                                  'activation_240[0][0]']         \n",
      "                                                                                                  \n",
      " activation_241 (Activation)    (None, 100, 128)     0           ['add_37[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_650 (Conv1D)            (None, 100, 128)     131200      ['activation_241[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_242 (Batch  (None, 100, 128)    512         ['conv1d_650[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_242 (Activation)    (None, 100, 128)     0           ['batch_normalization_242[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_651 (Conv1D)            (None, 100, 128)     82048       ['activation_242[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_243 (Batch  (None, 100, 128)    512         ['conv1d_651[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_243 (Activation)    (None, 100, 128)     0           ['batch_normalization_243[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_652 (Conv1D)            (None, 100, 128)     49280       ['activation_243[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_244 (Batch  (None, 100, 128)    512         ['conv1d_652[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_245 (Batch  (None, 100, 128)    512         ['activation_241[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_244 (Activation)    (None, 100, 128)     0           ['batch_normalization_244[0][0]']\n",
      "                                                                                                  \n",
      " add_38 (Add)                   (None, 100, 128)     0           ['batch_normalization_245[0][0]',\n",
      "                                                                  'activation_244[0][0]']         \n",
      "                                                                                                  \n",
      " activation_245 (Activation)    (None, 100, 128)     0           ['add_38[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_42 (G  (None, 128)         0           ['activation_245[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_492 (Dense)              (None, 1)            129         ['global_average_pooling1d_42[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 190: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 210: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 230: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 250: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 270: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_283\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_284 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_653 (Conv1D)            (None, 100, 64)      36928       ['input_284[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_246 (Batch  (None, 100, 64)     256         ['conv1d_653[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_246 (Activation)    (None, 100, 64)      0           ['batch_normalization_246[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_654 (Conv1D)            (None, 100, 64)      20544       ['activation_246[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_247 (Batch  (None, 100, 64)     256         ['conv1d_654[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_247 (Activation)    (None, 100, 64)      0           ['batch_normalization_247[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_655 (Conv1D)            (None, 100, 64)      12352       ['activation_247[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_656 (Conv1D)            (None, 100, 64)      4672        ['input_284[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_248 (Batch  (None, 100, 64)     256         ['conv1d_655[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_249 (Batch  (None, 100, 64)     256         ['conv1d_656[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_248 (Activation)    (None, 100, 64)      0           ['batch_normalization_248[0][0]']\n",
      "                                                                                                  \n",
      " add_39 (Add)                   (None, 100, 64)      0           ['batch_normalization_249[0][0]',\n",
      "                                                                  'activation_248[0][0]']         \n",
      "                                                                                                  \n",
      " activation_249 (Activation)    (None, 100, 64)      0           ['add_39[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_657 (Conv1D)            (None, 100, 128)     65664       ['activation_249[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_250 (Batch  (None, 100, 128)    512         ['conv1d_657[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_250 (Activation)    (None, 100, 128)     0           ['batch_normalization_250[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_658 (Conv1D)            (None, 100, 128)     82048       ['activation_250[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_251 (Batch  (None, 100, 128)    512         ['conv1d_658[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_251 (Activation)    (None, 100, 128)     0           ['batch_normalization_251[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_659 (Conv1D)            (None, 100, 128)     49280       ['activation_251[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_660 (Conv1D)            (None, 100, 128)     8320        ['activation_249[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_252 (Batch  (None, 100, 128)    512         ['conv1d_659[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_253 (Batch  (None, 100, 128)    512         ['conv1d_660[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_252 (Activation)    (None, 100, 128)     0           ['batch_normalization_252[0][0]']\n",
      "                                                                                                  \n",
      " add_40 (Add)                   (None, 100, 128)     0           ['batch_normalization_253[0][0]',\n",
      "                                                                  'activation_252[0][0]']         \n",
      "                                                                                                  \n",
      " activation_253 (Activation)    (None, 100, 128)     0           ['add_40[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_661 (Conv1D)            (None, 100, 128)     131200      ['activation_253[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_254 (Batch  (None, 100, 128)    512         ['conv1d_661[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_254 (Activation)    (None, 100, 128)     0           ['batch_normalization_254[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_662 (Conv1D)            (None, 100, 128)     82048       ['activation_254[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_255 (Batch  (None, 100, 128)    512         ['conv1d_662[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_255 (Activation)    (None, 100, 128)     0           ['batch_normalization_255[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_663 (Conv1D)            (None, 100, 128)     49280       ['activation_255[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_256 (Batch  (None, 100, 128)    512         ['conv1d_663[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_257 (Batch  (None, 100, 128)    512         ['activation_253[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_256 (Activation)    (None, 100, 128)     0           ['batch_normalization_256[0][0]']\n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, 100, 128)     0           ['batch_normalization_257[0][0]',\n",
      "                                                                  'activation_256[0][0]']         \n",
      "                                                                                                  \n",
      " activation_257 (Activation)    (None, 100, 128)     0           ['add_41[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_43 (G  (None, 128)         0           ['activation_257[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_493 (Dense)              (None, 1)            129         ['global_average_pooling1d_43[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 140: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 206: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 226: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 246: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 266: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 286: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_284\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_285 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_664 (Conv1D)            (None, 100, 64)      36928       ['input_285[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_258 (Batch  (None, 100, 64)     256         ['conv1d_664[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_258 (Activation)    (None, 100, 64)      0           ['batch_normalization_258[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_665 (Conv1D)            (None, 100, 64)      20544       ['activation_258[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_259 (Batch  (None, 100, 64)     256         ['conv1d_665[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_259 (Activation)    (None, 100, 64)      0           ['batch_normalization_259[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_666 (Conv1D)            (None, 100, 64)      12352       ['activation_259[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_667 (Conv1D)            (None, 100, 64)      4672        ['input_285[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_260 (Batch  (None, 100, 64)     256         ['conv1d_666[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_261 (Batch  (None, 100, 64)     256         ['conv1d_667[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_260 (Activation)    (None, 100, 64)      0           ['batch_normalization_260[0][0]']\n",
      "                                                                                                  \n",
      " add_42 (Add)                   (None, 100, 64)      0           ['batch_normalization_261[0][0]',\n",
      "                                                                  'activation_260[0][0]']         \n",
      "                                                                                                  \n",
      " activation_261 (Activation)    (None, 100, 64)      0           ['add_42[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_668 (Conv1D)            (None, 100, 128)     65664       ['activation_261[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_262 (Batch  (None, 100, 128)    512         ['conv1d_668[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_262 (Activation)    (None, 100, 128)     0           ['batch_normalization_262[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_669 (Conv1D)            (None, 100, 128)     82048       ['activation_262[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_263 (Batch  (None, 100, 128)    512         ['conv1d_669[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_263 (Activation)    (None, 100, 128)     0           ['batch_normalization_263[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_670 (Conv1D)            (None, 100, 128)     49280       ['activation_263[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_671 (Conv1D)            (None, 100, 128)     8320        ['activation_261[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_264 (Batch  (None, 100, 128)    512         ['conv1d_670[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_265 (Batch  (None, 100, 128)    512         ['conv1d_671[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_264 (Activation)    (None, 100, 128)     0           ['batch_normalization_264[0][0]']\n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, 100, 128)     0           ['batch_normalization_265[0][0]',\n",
      "                                                                  'activation_264[0][0]']         \n",
      "                                                                                                  \n",
      " activation_265 (Activation)    (None, 100, 128)     0           ['add_43[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_672 (Conv1D)            (None, 100, 128)     131200      ['activation_265[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_266 (Batch  (None, 100, 128)    512         ['conv1d_672[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_266 (Activation)    (None, 100, 128)     0           ['batch_normalization_266[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_673 (Conv1D)            (None, 100, 128)     82048       ['activation_266[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_267 (Batch  (None, 100, 128)    512         ['conv1d_673[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_267 (Activation)    (None, 100, 128)     0           ['batch_normalization_267[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_674 (Conv1D)            (None, 100, 128)     49280       ['activation_267[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_268 (Batch  (None, 100, 128)    512         ['conv1d_674[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_269 (Batch  (None, 100, 128)    512         ['activation_265[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_268 (Activation)    (None, 100, 128)     0           ['batch_normalization_268[0][0]']\n",
      "                                                                                                  \n",
      " add_44 (Add)                   (None, 100, 128)     0           ['batch_normalization_269[0][0]',\n",
      "                                                                  'activation_268[0][0]']         \n",
      "                                                                                                  \n",
      " activation_269 (Activation)    (None, 100, 128)     0           ['add_44[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_44 (G  (None, 128)         0           ['activation_269[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_494 (Dense)              (None, 1)            129         ['global_average_pooling1d_44[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 243: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 263: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 283: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 327: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 347: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\n",
      "Epoch 367: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "\n",
      "Epoch 387: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n",
      "\n",
      "Epoch 407: ReduceLROnPlateau reducing learning rate to 2.441406195430318e-06.\n",
      "Model: \"model_285\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_286 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_675 (Conv1D)            (None, 100, 64)      36928       ['input_286[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_270 (Batch  (None, 100, 64)     256         ['conv1d_675[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_270 (Activation)    (None, 100, 64)      0           ['batch_normalization_270[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_676 (Conv1D)            (None, 100, 64)      20544       ['activation_270[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_271 (Batch  (None, 100, 64)     256         ['conv1d_676[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_271 (Activation)    (None, 100, 64)      0           ['batch_normalization_271[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_677 (Conv1D)            (None, 100, 64)      12352       ['activation_271[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_678 (Conv1D)            (None, 100, 64)      4672        ['input_286[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_272 (Batch  (None, 100, 64)     256         ['conv1d_677[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_273 (Batch  (None, 100, 64)     256         ['conv1d_678[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_272 (Activation)    (None, 100, 64)      0           ['batch_normalization_272[0][0]']\n",
      "                                                                                                  \n",
      " add_45 (Add)                   (None, 100, 64)      0           ['batch_normalization_273[0][0]',\n",
      "                                                                  'activation_272[0][0]']         \n",
      "                                                                                                  \n",
      " activation_273 (Activation)    (None, 100, 64)      0           ['add_45[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_679 (Conv1D)            (None, 100, 128)     65664       ['activation_273[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_274 (Batch  (None, 100, 128)    512         ['conv1d_679[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_274 (Activation)    (None, 100, 128)     0           ['batch_normalization_274[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_680 (Conv1D)            (None, 100, 128)     82048       ['activation_274[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_275 (Batch  (None, 100, 128)    512         ['conv1d_680[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_275 (Activation)    (None, 100, 128)     0           ['batch_normalization_275[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_681 (Conv1D)            (None, 100, 128)     49280       ['activation_275[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_682 (Conv1D)            (None, 100, 128)     8320        ['activation_273[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_276 (Batch  (None, 100, 128)    512         ['conv1d_681[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_277 (Batch  (None, 100, 128)    512         ['conv1d_682[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_276 (Activation)    (None, 100, 128)     0           ['batch_normalization_276[0][0]']\n",
      "                                                                                                  \n",
      " add_46 (Add)                   (None, 100, 128)     0           ['batch_normalization_277[0][0]',\n",
      "                                                                  'activation_276[0][0]']         \n",
      "                                                                                                  \n",
      " activation_277 (Activation)    (None, 100, 128)     0           ['add_46[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_683 (Conv1D)            (None, 100, 128)     131200      ['activation_277[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_278 (Batch  (None, 100, 128)    512         ['conv1d_683[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_278 (Activation)    (None, 100, 128)     0           ['batch_normalization_278[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_684 (Conv1D)            (None, 100, 128)     82048       ['activation_278[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_279 (Batch  (None, 100, 128)    512         ['conv1d_684[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_279 (Activation)    (None, 100, 128)     0           ['batch_normalization_279[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_685 (Conv1D)            (None, 100, 128)     49280       ['activation_279[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_280 (Batch  (None, 100, 128)    512         ['conv1d_685[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_281 (Batch  (None, 100, 128)    512         ['activation_277[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_280 (Activation)    (None, 100, 128)     0           ['batch_normalization_280[0][0]']\n",
      "                                                                                                  \n",
      " add_47 (Add)                   (None, 100, 128)     0           ['batch_normalization_281[0][0]',\n",
      "                                                                  'activation_280[0][0]']         \n",
      "                                                                                                  \n",
      " activation_281 (Activation)    (None, 100, 128)     0           ['add_47[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_45 (G  (None, 128)         0           ['activation_281[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_495 (Dense)              (None, 1)            129         ['global_average_pooling1d_45[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 110: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 202: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 222: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 242: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 262: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_286\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_287 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_686 (Conv1D)            (None, 100, 64)      36928       ['input_287[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_282 (Batch  (None, 100, 64)     256         ['conv1d_686[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_282 (Activation)    (None, 100, 64)      0           ['batch_normalization_282[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_687 (Conv1D)            (None, 100, 64)      20544       ['activation_282[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_283 (Batch  (None, 100, 64)     256         ['conv1d_687[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_283 (Activation)    (None, 100, 64)      0           ['batch_normalization_283[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_688 (Conv1D)            (None, 100, 64)      12352       ['activation_283[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_689 (Conv1D)            (None, 100, 64)      4672        ['input_287[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_284 (Batch  (None, 100, 64)     256         ['conv1d_688[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_285 (Batch  (None, 100, 64)     256         ['conv1d_689[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_284 (Activation)    (None, 100, 64)      0           ['batch_normalization_284[0][0]']\n",
      "                                                                                                  \n",
      " add_48 (Add)                   (None, 100, 64)      0           ['batch_normalization_285[0][0]',\n",
      "                                                                  'activation_284[0][0]']         \n",
      "                                                                                                  \n",
      " activation_285 (Activation)    (None, 100, 64)      0           ['add_48[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_690 (Conv1D)            (None, 100, 128)     65664       ['activation_285[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_286 (Batch  (None, 100, 128)    512         ['conv1d_690[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_286 (Activation)    (None, 100, 128)     0           ['batch_normalization_286[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_691 (Conv1D)            (None, 100, 128)     82048       ['activation_286[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_287 (Batch  (None, 100, 128)    512         ['conv1d_691[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_287 (Activation)    (None, 100, 128)     0           ['batch_normalization_287[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_692 (Conv1D)            (None, 100, 128)     49280       ['activation_287[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_693 (Conv1D)            (None, 100, 128)     8320        ['activation_285[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_288 (Batch  (None, 100, 128)    512         ['conv1d_692[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_289 (Batch  (None, 100, 128)    512         ['conv1d_693[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_288 (Activation)    (None, 100, 128)     0           ['batch_normalization_288[0][0]']\n",
      "                                                                                                  \n",
      " add_49 (Add)                   (None, 100, 128)     0           ['batch_normalization_289[0][0]',\n",
      "                                                                  'activation_288[0][0]']         \n",
      "                                                                                                  \n",
      " activation_289 (Activation)    (None, 100, 128)     0           ['add_49[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_694 (Conv1D)            (None, 100, 128)     131200      ['activation_289[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_290 (Batch  (None, 100, 128)    512         ['conv1d_694[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_290 (Activation)    (None, 100, 128)     0           ['batch_normalization_290[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_695 (Conv1D)            (None, 100, 128)     82048       ['activation_290[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_291 (Batch  (None, 100, 128)    512         ['conv1d_695[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_291 (Activation)    (None, 100, 128)     0           ['batch_normalization_291[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_696 (Conv1D)            (None, 100, 128)     49280       ['activation_291[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_292 (Batch  (None, 100, 128)    512         ['conv1d_696[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_293 (Batch  (None, 100, 128)    512         ['activation_289[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_292 (Activation)    (None, 100, 128)     0           ['batch_normalization_292[0][0]']\n",
      "                                                                                                  \n",
      " add_50 (Add)                   (None, 100, 128)     0           ['batch_normalization_293[0][0]',\n",
      "                                                                  'activation_292[0][0]']         \n",
      "                                                                                                  \n",
      " activation_293 (Activation)    (None, 100, 128)     0           ['add_50[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_46 (G  (None, 128)         0           ['activation_293[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_496 (Dense)              (None, 1)            129         ['global_average_pooling1d_46[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 119: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 207: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 227: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 247: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 267: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\n",
      "Epoch 287: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "Model: \"model_287\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_288 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_697 (Conv1D)            (None, 100, 64)      36928       ['input_288[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_294 (Batch  (None, 100, 64)     256         ['conv1d_697[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_294 (Activation)    (None, 100, 64)      0           ['batch_normalization_294[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_698 (Conv1D)            (None, 100, 64)      20544       ['activation_294[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_295 (Batch  (None, 100, 64)     256         ['conv1d_698[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_295 (Activation)    (None, 100, 64)      0           ['batch_normalization_295[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_699 (Conv1D)            (None, 100, 64)      12352       ['activation_295[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_700 (Conv1D)            (None, 100, 64)      4672        ['input_288[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_296 (Batch  (None, 100, 64)     256         ['conv1d_699[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_297 (Batch  (None, 100, 64)     256         ['conv1d_700[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_296 (Activation)    (None, 100, 64)      0           ['batch_normalization_296[0][0]']\n",
      "                                                                                                  \n",
      " add_51 (Add)                   (None, 100, 64)      0           ['batch_normalization_297[0][0]',\n",
      "                                                                  'activation_296[0][0]']         \n",
      "                                                                                                  \n",
      " activation_297 (Activation)    (None, 100, 64)      0           ['add_51[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_701 (Conv1D)            (None, 100, 128)     65664       ['activation_297[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_298 (Batch  (None, 100, 128)    512         ['conv1d_701[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_298 (Activation)    (None, 100, 128)     0           ['batch_normalization_298[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_702 (Conv1D)            (None, 100, 128)     82048       ['activation_298[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_299 (Batch  (None, 100, 128)    512         ['conv1d_702[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_299 (Activation)    (None, 100, 128)     0           ['batch_normalization_299[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_703 (Conv1D)            (None, 100, 128)     49280       ['activation_299[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_704 (Conv1D)            (None, 100, 128)     8320        ['activation_297[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_300 (Batch  (None, 100, 128)    512         ['conv1d_703[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_301 (Batch  (None, 100, 128)    512         ['conv1d_704[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_300 (Activation)    (None, 100, 128)     0           ['batch_normalization_300[0][0]']\n",
      "                                                                                                  \n",
      " add_52 (Add)                   (None, 100, 128)     0           ['batch_normalization_301[0][0]',\n",
      "                                                                  'activation_300[0][0]']         \n",
      "                                                                                                  \n",
      " activation_301 (Activation)    (None, 100, 128)     0           ['add_52[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_705 (Conv1D)            (None, 100, 128)     131200      ['activation_301[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_302 (Batch  (None, 100, 128)    512         ['conv1d_705[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_302 (Activation)    (None, 100, 128)     0           ['batch_normalization_302[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_706 (Conv1D)            (None, 100, 128)     82048       ['activation_302[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_303 (Batch  (None, 100, 128)    512         ['conv1d_706[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_303 (Activation)    (None, 100, 128)     0           ['batch_normalization_303[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_707 (Conv1D)            (None, 100, 128)     49280       ['activation_303[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_304 (Batch  (None, 100, 128)    512         ['conv1d_707[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_305 (Batch  (None, 100, 128)    512         ['activation_301[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_304 (Activation)    (None, 100, 128)     0           ['batch_normalization_304[0][0]']\n",
      "                                                                                                  \n",
      " add_53 (Add)                   (None, 100, 128)     0           ['batch_normalization_305[0][0]',\n",
      "                                                                  'activation_304[0][0]']         \n",
      "                                                                                                  \n",
      " activation_305 (Activation)    (None, 100, 128)     0           ['add_53[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_47 (G  (None, 128)         0           ['activation_305[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_497 (Dense)              (None, 1)            129         ['global_average_pooling1d_47[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 199: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 219: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 266: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 286: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 306: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 326: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 346: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_288\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_289 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_708 (Conv1D)            (None, 100, 64)      36928       ['input_289[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_306 (Batch  (None, 100, 64)     256         ['conv1d_708[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_306 (Activation)    (None, 100, 64)      0           ['batch_normalization_306[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_709 (Conv1D)            (None, 100, 64)      20544       ['activation_306[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_307 (Batch  (None, 100, 64)     256         ['conv1d_709[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_307 (Activation)    (None, 100, 64)      0           ['batch_normalization_307[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_710 (Conv1D)            (None, 100, 64)      12352       ['activation_307[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_711 (Conv1D)            (None, 100, 64)      4672        ['input_289[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_308 (Batch  (None, 100, 64)     256         ['conv1d_710[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_309 (Batch  (None, 100, 64)     256         ['conv1d_711[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_308 (Activation)    (None, 100, 64)      0           ['batch_normalization_308[0][0]']\n",
      "                                                                                                  \n",
      " add_54 (Add)                   (None, 100, 64)      0           ['batch_normalization_309[0][0]',\n",
      "                                                                  'activation_308[0][0]']         \n",
      "                                                                                                  \n",
      " activation_309 (Activation)    (None, 100, 64)      0           ['add_54[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_712 (Conv1D)            (None, 100, 128)     65664       ['activation_309[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_310 (Batch  (None, 100, 128)    512         ['conv1d_712[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_310 (Activation)    (None, 100, 128)     0           ['batch_normalization_310[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_713 (Conv1D)            (None, 100, 128)     82048       ['activation_310[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_311 (Batch  (None, 100, 128)    512         ['conv1d_713[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_311 (Activation)    (None, 100, 128)     0           ['batch_normalization_311[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_714 (Conv1D)            (None, 100, 128)     49280       ['activation_311[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_715 (Conv1D)            (None, 100, 128)     8320        ['activation_309[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_312 (Batch  (None, 100, 128)    512         ['conv1d_714[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_313 (Batch  (None, 100, 128)    512         ['conv1d_715[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_312 (Activation)    (None, 100, 128)     0           ['batch_normalization_312[0][0]']\n",
      "                                                                                                  \n",
      " add_55 (Add)                   (None, 100, 128)     0           ['batch_normalization_313[0][0]',\n",
      "                                                                  'activation_312[0][0]']         \n",
      "                                                                                                  \n",
      " activation_313 (Activation)    (None, 100, 128)     0           ['add_55[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_716 (Conv1D)            (None, 100, 128)     131200      ['activation_313[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_314 (Batch  (None, 100, 128)    512         ['conv1d_716[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_314 (Activation)    (None, 100, 128)     0           ['batch_normalization_314[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_717 (Conv1D)            (None, 100, 128)     82048       ['activation_314[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_315 (Batch  (None, 100, 128)    512         ['conv1d_717[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_315 (Activation)    (None, 100, 128)     0           ['batch_normalization_315[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_718 (Conv1D)            (None, 100, 128)     49280       ['activation_315[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_316 (Batch  (None, 100, 128)    512         ['conv1d_718[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_317 (Batch  (None, 100, 128)    512         ['activation_313[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_316 (Activation)    (None, 100, 128)     0           ['batch_normalization_316[0][0]']\n",
      "                                                                                                  \n",
      " add_56 (Add)                   (None, 100, 128)     0           ['batch_normalization_317[0][0]',\n",
      "                                                                  'activation_316[0][0]']         \n",
      "                                                                                                  \n",
      " activation_317 (Activation)    (None, 100, 128)     0           ['add_56[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_48 (G  (None, 128)         0           ['activation_317[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_498 (Dense)              (None, 1)            129         ['global_average_pooling1d_48[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 193: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 213: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_289\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_290 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_719 (Conv1D)            (None, 100, 64)      36928       ['input_290[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_318 (Batch  (None, 100, 64)     256         ['conv1d_719[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_318 (Activation)    (None, 100, 64)      0           ['batch_normalization_318[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_720 (Conv1D)            (None, 100, 64)      20544       ['activation_318[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_319 (Batch  (None, 100, 64)     256         ['conv1d_720[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_319 (Activation)    (None, 100, 64)      0           ['batch_normalization_319[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_721 (Conv1D)            (None, 100, 64)      12352       ['activation_319[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_722 (Conv1D)            (None, 100, 64)      4672        ['input_290[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_320 (Batch  (None, 100, 64)     256         ['conv1d_721[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_321 (Batch  (None, 100, 64)     256         ['conv1d_722[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_320 (Activation)    (None, 100, 64)      0           ['batch_normalization_320[0][0]']\n",
      "                                                                                                  \n",
      " add_57 (Add)                   (None, 100, 64)      0           ['batch_normalization_321[0][0]',\n",
      "                                                                  'activation_320[0][0]']         \n",
      "                                                                                                  \n",
      " activation_321 (Activation)    (None, 100, 64)      0           ['add_57[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_723 (Conv1D)            (None, 100, 128)     65664       ['activation_321[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_322 (Batch  (None, 100, 128)    512         ['conv1d_723[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_322 (Activation)    (None, 100, 128)     0           ['batch_normalization_322[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_724 (Conv1D)            (None, 100, 128)     82048       ['activation_322[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_323 (Batch  (None, 100, 128)    512         ['conv1d_724[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_323 (Activation)    (None, 100, 128)     0           ['batch_normalization_323[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_725 (Conv1D)            (None, 100, 128)     49280       ['activation_323[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_726 (Conv1D)            (None, 100, 128)     8320        ['activation_321[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_324 (Batch  (None, 100, 128)    512         ['conv1d_725[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_325 (Batch  (None, 100, 128)    512         ['conv1d_726[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_324 (Activation)    (None, 100, 128)     0           ['batch_normalization_324[0][0]']\n",
      "                                                                                                  \n",
      " add_58 (Add)                   (None, 100, 128)     0           ['batch_normalization_325[0][0]',\n",
      "                                                                  'activation_324[0][0]']         \n",
      "                                                                                                  \n",
      " activation_325 (Activation)    (None, 100, 128)     0           ['add_58[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_727 (Conv1D)            (None, 100, 128)     131200      ['activation_325[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_326 (Batch  (None, 100, 128)    512         ['conv1d_727[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_326 (Activation)    (None, 100, 128)     0           ['batch_normalization_326[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_728 (Conv1D)            (None, 100, 128)     82048       ['activation_326[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_327 (Batch  (None, 100, 128)    512         ['conv1d_728[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_327 (Activation)    (None, 100, 128)     0           ['batch_normalization_327[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_729 (Conv1D)            (None, 100, 128)     49280       ['activation_327[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_328 (Batch  (None, 100, 128)    512         ['conv1d_729[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_329 (Batch  (None, 100, 128)    512         ['activation_325[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_328 (Activation)    (None, 100, 128)     0           ['batch_normalization_328[0][0]']\n",
      "                                                                                                  \n",
      " add_59 (Add)                   (None, 100, 128)     0           ['batch_normalization_329[0][0]',\n",
      "                                                                  'activation_328[0][0]']         \n",
      "                                                                                                  \n",
      " activation_329 (Activation)    (None, 100, 128)     0           ['add_59[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_49 (G  (None, 128)         0           ['activation_329[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_499 (Dense)              (None, 1)            129         ['global_average_pooling1d_49[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 156: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 176: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 196: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 216: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_290\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_291 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_730 (Conv1D)            (None, 100, 64)      36928       ['input_291[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_330 (Batch  (None, 100, 64)     256         ['conv1d_730[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_330 (Activation)    (None, 100, 64)      0           ['batch_normalization_330[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_731 (Conv1D)            (None, 100, 64)      20544       ['activation_330[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_331 (Batch  (None, 100, 64)     256         ['conv1d_731[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_331 (Activation)    (None, 100, 64)      0           ['batch_normalization_331[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_732 (Conv1D)            (None, 100, 64)      12352       ['activation_331[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_733 (Conv1D)            (None, 100, 64)      4672        ['input_291[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_332 (Batch  (None, 100, 64)     256         ['conv1d_732[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_333 (Batch  (None, 100, 64)     256         ['conv1d_733[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_332 (Activation)    (None, 100, 64)      0           ['batch_normalization_332[0][0]']\n",
      "                                                                                                  \n",
      " add_60 (Add)                   (None, 100, 64)      0           ['batch_normalization_333[0][0]',\n",
      "                                                                  'activation_332[0][0]']         \n",
      "                                                                                                  \n",
      " activation_333 (Activation)    (None, 100, 64)      0           ['add_60[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_734 (Conv1D)            (None, 100, 128)     65664       ['activation_333[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_334 (Batch  (None, 100, 128)    512         ['conv1d_734[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_334 (Activation)    (None, 100, 128)     0           ['batch_normalization_334[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_735 (Conv1D)            (None, 100, 128)     82048       ['activation_334[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_335 (Batch  (None, 100, 128)    512         ['conv1d_735[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_335 (Activation)    (None, 100, 128)     0           ['batch_normalization_335[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_736 (Conv1D)            (None, 100, 128)     49280       ['activation_335[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_737 (Conv1D)            (None, 100, 128)     8320        ['activation_333[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_336 (Batch  (None, 100, 128)    512         ['conv1d_736[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_337 (Batch  (None, 100, 128)    512         ['conv1d_737[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_336 (Activation)    (None, 100, 128)     0           ['batch_normalization_336[0][0]']\n",
      "                                                                                                  \n",
      " add_61 (Add)                   (None, 100, 128)     0           ['batch_normalization_337[0][0]',\n",
      "                                                                  'activation_336[0][0]']         \n",
      "                                                                                                  \n",
      " activation_337 (Activation)    (None, 100, 128)     0           ['add_61[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_738 (Conv1D)            (None, 100, 128)     131200      ['activation_337[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_338 (Batch  (None, 100, 128)    512         ['conv1d_738[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_338 (Activation)    (None, 100, 128)     0           ['batch_normalization_338[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_739 (Conv1D)            (None, 100, 128)     82048       ['activation_338[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_339 (Batch  (None, 100, 128)    512         ['conv1d_739[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_339 (Activation)    (None, 100, 128)     0           ['batch_normalization_339[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_740 (Conv1D)            (None, 100, 128)     49280       ['activation_339[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_340 (Batch  (None, 100, 128)    512         ['conv1d_740[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_341 (Batch  (None, 100, 128)    512         ['activation_337[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_340 (Activation)    (None, 100, 128)     0           ['batch_normalization_340[0][0]']\n",
      "                                                                                                  \n",
      " add_62 (Add)                   (None, 100, 128)     0           ['batch_normalization_341[0][0]',\n",
      "                                                                  'activation_340[0][0]']         \n",
      "                                                                                                  \n",
      " activation_341 (Activation)    (None, 100, 128)     0           ['add_62[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_50 (G  (None, 128)         0           ['activation_341[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_500 (Dense)              (None, 1)            129         ['global_average_pooling1d_50[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 197: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 235: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 260: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 280: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 300: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 320: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\n",
      "Epoch 340: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "Model: \"model_291\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_292 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_741 (Conv1D)            (None, 100, 64)      36928       ['input_292[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_342 (Batch  (None, 100, 64)     256         ['conv1d_741[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_342 (Activation)    (None, 100, 64)      0           ['batch_normalization_342[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_742 (Conv1D)            (None, 100, 64)      20544       ['activation_342[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_343 (Batch  (None, 100, 64)     256         ['conv1d_742[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_343 (Activation)    (None, 100, 64)      0           ['batch_normalization_343[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_743 (Conv1D)            (None, 100, 64)      12352       ['activation_343[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_744 (Conv1D)            (None, 100, 64)      4672        ['input_292[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_344 (Batch  (None, 100, 64)     256         ['conv1d_743[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_345 (Batch  (None, 100, 64)     256         ['conv1d_744[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_344 (Activation)    (None, 100, 64)      0           ['batch_normalization_344[0][0]']\n",
      "                                                                                                  \n",
      " add_63 (Add)                   (None, 100, 64)      0           ['batch_normalization_345[0][0]',\n",
      "                                                                  'activation_344[0][0]']         \n",
      "                                                                                                  \n",
      " activation_345 (Activation)    (None, 100, 64)      0           ['add_63[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_745 (Conv1D)            (None, 100, 128)     65664       ['activation_345[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_346 (Batch  (None, 100, 128)    512         ['conv1d_745[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_346 (Activation)    (None, 100, 128)     0           ['batch_normalization_346[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_746 (Conv1D)            (None, 100, 128)     82048       ['activation_346[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_347 (Batch  (None, 100, 128)    512         ['conv1d_746[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_347 (Activation)    (None, 100, 128)     0           ['batch_normalization_347[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_747 (Conv1D)            (None, 100, 128)     49280       ['activation_347[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_748 (Conv1D)            (None, 100, 128)     8320        ['activation_345[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_348 (Batch  (None, 100, 128)    512         ['conv1d_747[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_349 (Batch  (None, 100, 128)    512         ['conv1d_748[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_348 (Activation)    (None, 100, 128)     0           ['batch_normalization_348[0][0]']\n",
      "                                                                                                  \n",
      " add_64 (Add)                   (None, 100, 128)     0           ['batch_normalization_349[0][0]',\n",
      "                                                                  'activation_348[0][0]']         \n",
      "                                                                                                  \n",
      " activation_349 (Activation)    (None, 100, 128)     0           ['add_64[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_749 (Conv1D)            (None, 100, 128)     131200      ['activation_349[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_350 (Batch  (None, 100, 128)    512         ['conv1d_749[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_350 (Activation)    (None, 100, 128)     0           ['batch_normalization_350[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_750 (Conv1D)            (None, 100, 128)     82048       ['activation_350[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_351 (Batch  (None, 100, 128)    512         ['conv1d_750[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_351 (Activation)    (None, 100, 128)     0           ['batch_normalization_351[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_751 (Conv1D)            (None, 100, 128)     49280       ['activation_351[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_352 (Batch  (None, 100, 128)    512         ['conv1d_751[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_353 (Batch  (None, 100, 128)    512         ['activation_349[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_352 (Activation)    (None, 100, 128)     0           ['batch_normalization_352[0][0]']\n",
      "                                                                                                  \n",
      " add_65 (Add)                   (None, 100, 128)     0           ['batch_normalization_353[0][0]',\n",
      "                                                                  'activation_352[0][0]']         \n",
      "                                                                                                  \n",
      " activation_353 (Activation)    (None, 100, 128)     0           ['add_65[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_51 (G  (None, 128)         0           ['activation_353[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_501 (Dense)              (None, 1)            129         ['global_average_pooling1d_51[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Model: \"model_292\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_293 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_752 (Conv1D)            (None, 100, 64)      36928       ['input_293[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_354 (Batch  (None, 100, 64)     256         ['conv1d_752[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_354 (Activation)    (None, 100, 64)      0           ['batch_normalization_354[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_753 (Conv1D)            (None, 100, 64)      20544       ['activation_354[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_355 (Batch  (None, 100, 64)     256         ['conv1d_753[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_355 (Activation)    (None, 100, 64)      0           ['batch_normalization_355[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_754 (Conv1D)            (None, 100, 64)      12352       ['activation_355[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_755 (Conv1D)            (None, 100, 64)      4672        ['input_293[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_356 (Batch  (None, 100, 64)     256         ['conv1d_754[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_357 (Batch  (None, 100, 64)     256         ['conv1d_755[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_356 (Activation)    (None, 100, 64)      0           ['batch_normalization_356[0][0]']\n",
      "                                                                                                  \n",
      " add_66 (Add)                   (None, 100, 64)      0           ['batch_normalization_357[0][0]',\n",
      "                                                                  'activation_356[0][0]']         \n",
      "                                                                                                  \n",
      " activation_357 (Activation)    (None, 100, 64)      0           ['add_66[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_756 (Conv1D)            (None, 100, 128)     65664       ['activation_357[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_358 (Batch  (None, 100, 128)    512         ['conv1d_756[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_358 (Activation)    (None, 100, 128)     0           ['batch_normalization_358[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_757 (Conv1D)            (None, 100, 128)     82048       ['activation_358[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_359 (Batch  (None, 100, 128)    512         ['conv1d_757[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_359 (Activation)    (None, 100, 128)     0           ['batch_normalization_359[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_758 (Conv1D)            (None, 100, 128)     49280       ['activation_359[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_759 (Conv1D)            (None, 100, 128)     8320        ['activation_357[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_360 (Batch  (None, 100, 128)    512         ['conv1d_758[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_361 (Batch  (None, 100, 128)    512         ['conv1d_759[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_360 (Activation)    (None, 100, 128)     0           ['batch_normalization_360[0][0]']\n",
      "                                                                                                  \n",
      " add_67 (Add)                   (None, 100, 128)     0           ['batch_normalization_361[0][0]',\n",
      "                                                                  'activation_360[0][0]']         \n",
      "                                                                                                  \n",
      " activation_361 (Activation)    (None, 100, 128)     0           ['add_67[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_760 (Conv1D)            (None, 100, 128)     131200      ['activation_361[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_362 (Batch  (None, 100, 128)    512         ['conv1d_760[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_362 (Activation)    (None, 100, 128)     0           ['batch_normalization_362[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_761 (Conv1D)            (None, 100, 128)     82048       ['activation_362[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_363 (Batch  (None, 100, 128)    512         ['conv1d_761[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_363 (Activation)    (None, 100, 128)     0           ['batch_normalization_363[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_762 (Conv1D)            (None, 100, 128)     49280       ['activation_363[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_364 (Batch  (None, 100, 128)    512         ['conv1d_762[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_365 (Batch  (None, 100, 128)    512         ['activation_361[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_364 (Activation)    (None, 100, 128)     0           ['batch_normalization_364[0][0]']\n",
      "                                                                                                  \n",
      " add_68 (Add)                   (None, 100, 128)     0           ['batch_normalization_365[0][0]',\n",
      "                                                                  'activation_364[0][0]']         \n",
      "                                                                                                  \n",
      " activation_365 (Activation)    (None, 100, 128)     0           ['add_68[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_52 (G  (None, 128)         0           ['activation_365[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_502 (Dense)              (None, 1)            129         ['global_average_pooling1d_52[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 193: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 213: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 233: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_293\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_294 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_763 (Conv1D)            (None, 100, 64)      36928       ['input_294[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_366 (Batch  (None, 100, 64)     256         ['conv1d_763[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_366 (Activation)    (None, 100, 64)      0           ['batch_normalization_366[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_764 (Conv1D)            (None, 100, 64)      20544       ['activation_366[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_367 (Batch  (None, 100, 64)     256         ['conv1d_764[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_367 (Activation)    (None, 100, 64)      0           ['batch_normalization_367[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_765 (Conv1D)            (None, 100, 64)      12352       ['activation_367[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_766 (Conv1D)            (None, 100, 64)      4672        ['input_294[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_368 (Batch  (None, 100, 64)     256         ['conv1d_765[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_369 (Batch  (None, 100, 64)     256         ['conv1d_766[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_368 (Activation)    (None, 100, 64)      0           ['batch_normalization_368[0][0]']\n",
      "                                                                                                  \n",
      " add_69 (Add)                   (None, 100, 64)      0           ['batch_normalization_369[0][0]',\n",
      "                                                                  'activation_368[0][0]']         \n",
      "                                                                                                  \n",
      " activation_369 (Activation)    (None, 100, 64)      0           ['add_69[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_767 (Conv1D)            (None, 100, 128)     65664       ['activation_369[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_370 (Batch  (None, 100, 128)    512         ['conv1d_767[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_370 (Activation)    (None, 100, 128)     0           ['batch_normalization_370[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_768 (Conv1D)            (None, 100, 128)     82048       ['activation_370[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_371 (Batch  (None, 100, 128)    512         ['conv1d_768[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_371 (Activation)    (None, 100, 128)     0           ['batch_normalization_371[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_769 (Conv1D)            (None, 100, 128)     49280       ['activation_371[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_770 (Conv1D)            (None, 100, 128)     8320        ['activation_369[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_372 (Batch  (None, 100, 128)    512         ['conv1d_769[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_373 (Batch  (None, 100, 128)    512         ['conv1d_770[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_372 (Activation)    (None, 100, 128)     0           ['batch_normalization_372[0][0]']\n",
      "                                                                                                  \n",
      " add_70 (Add)                   (None, 100, 128)     0           ['batch_normalization_373[0][0]',\n",
      "                                                                  'activation_372[0][0]']         \n",
      "                                                                                                  \n",
      " activation_373 (Activation)    (None, 100, 128)     0           ['add_70[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_771 (Conv1D)            (None, 100, 128)     131200      ['activation_373[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_374 (Batch  (None, 100, 128)    512         ['conv1d_771[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_374 (Activation)    (None, 100, 128)     0           ['batch_normalization_374[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_772 (Conv1D)            (None, 100, 128)     82048       ['activation_374[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_375 (Batch  (None, 100, 128)    512         ['conv1d_772[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_375 (Activation)    (None, 100, 128)     0           ['batch_normalization_375[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_773 (Conv1D)            (None, 100, 128)     49280       ['activation_375[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_376 (Batch  (None, 100, 128)    512         ['conv1d_773[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_377 (Batch  (None, 100, 128)    512         ['activation_373[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_376 (Activation)    (None, 100, 128)     0           ['batch_normalization_376[0][0]']\n",
      "                                                                                                  \n",
      " add_71 (Add)                   (None, 100, 128)     0           ['batch_normalization_377[0][0]',\n",
      "                                                                  'activation_376[0][0]']         \n",
      "                                                                                                  \n",
      " activation_377 (Activation)    (None, 100, 128)     0           ['add_71[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_53 (G  (None, 128)         0           ['activation_377[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_503 (Dense)              (None, 1)            129         ['global_average_pooling1d_53[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 202: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 222: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 242: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 262: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Model: \"model_294\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_295 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_774 (Conv1D)            (None, 100, 64)      36928       ['input_295[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_378 (Batch  (None, 100, 64)     256         ['conv1d_774[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_378 (Activation)    (None, 100, 64)      0           ['batch_normalization_378[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_775 (Conv1D)            (None, 100, 64)      20544       ['activation_378[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_379 (Batch  (None, 100, 64)     256         ['conv1d_775[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_379 (Activation)    (None, 100, 64)      0           ['batch_normalization_379[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_776 (Conv1D)            (None, 100, 64)      12352       ['activation_379[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_777 (Conv1D)            (None, 100, 64)      4672        ['input_295[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_380 (Batch  (None, 100, 64)     256         ['conv1d_776[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_381 (Batch  (None, 100, 64)     256         ['conv1d_777[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_380 (Activation)    (None, 100, 64)      0           ['batch_normalization_380[0][0]']\n",
      "                                                                                                  \n",
      " add_72 (Add)                   (None, 100, 64)      0           ['batch_normalization_381[0][0]',\n",
      "                                                                  'activation_380[0][0]']         \n",
      "                                                                                                  \n",
      " activation_381 (Activation)    (None, 100, 64)      0           ['add_72[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_778 (Conv1D)            (None, 100, 128)     65664       ['activation_381[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_382 (Batch  (None, 100, 128)    512         ['conv1d_778[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_382 (Activation)    (None, 100, 128)     0           ['batch_normalization_382[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_779 (Conv1D)            (None, 100, 128)     82048       ['activation_382[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_383 (Batch  (None, 100, 128)    512         ['conv1d_779[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_383 (Activation)    (None, 100, 128)     0           ['batch_normalization_383[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_780 (Conv1D)            (None, 100, 128)     49280       ['activation_383[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_781 (Conv1D)            (None, 100, 128)     8320        ['activation_381[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_384 (Batch  (None, 100, 128)    512         ['conv1d_780[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_385 (Batch  (None, 100, 128)    512         ['conv1d_781[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_384 (Activation)    (None, 100, 128)     0           ['batch_normalization_384[0][0]']\n",
      "                                                                                                  \n",
      " add_73 (Add)                   (None, 100, 128)     0           ['batch_normalization_385[0][0]',\n",
      "                                                                  'activation_384[0][0]']         \n",
      "                                                                                                  \n",
      " activation_385 (Activation)    (None, 100, 128)     0           ['add_73[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_782 (Conv1D)            (None, 100, 128)     131200      ['activation_385[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_386 (Batch  (None, 100, 128)    512         ['conv1d_782[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_386 (Activation)    (None, 100, 128)     0           ['batch_normalization_386[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_783 (Conv1D)            (None, 100, 128)     82048       ['activation_386[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_387 (Batch  (None, 100, 128)    512         ['conv1d_783[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_387 (Activation)    (None, 100, 128)     0           ['batch_normalization_387[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_784 (Conv1D)            (None, 100, 128)     49280       ['activation_387[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_388 (Batch  (None, 100, 128)    512         ['conv1d_784[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_389 (Batch  (None, 100, 128)    512         ['activation_385[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_388 (Activation)    (None, 100, 128)     0           ['batch_normalization_388[0][0]']\n",
      "                                                                                                  \n",
      " add_74 (Add)                   (None, 100, 128)     0           ['batch_normalization_389[0][0]',\n",
      "                                                                  'activation_388[0][0]']         \n",
      "                                                                                                  \n",
      " activation_389 (Activation)    (None, 100, 128)     0           ['add_74[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_54 (G  (None, 128)         0           ['activation_389[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_504 (Dense)              (None, 1)            129         ['global_average_pooling1d_54[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 181: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 205: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 225: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 245: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 265: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 285: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Model: \"model_295\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_296 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_785 (Conv1D)            (None, 100, 64)      36928       ['input_296[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_390 (Batch  (None, 100, 64)     256         ['conv1d_785[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_390 (Activation)    (None, 100, 64)      0           ['batch_normalization_390[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_786 (Conv1D)            (None, 100, 64)      20544       ['activation_390[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_391 (Batch  (None, 100, 64)     256         ['conv1d_786[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_391 (Activation)    (None, 100, 64)      0           ['batch_normalization_391[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_787 (Conv1D)            (None, 100, 64)      12352       ['activation_391[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_788 (Conv1D)            (None, 100, 64)      4672        ['input_296[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_392 (Batch  (None, 100, 64)     256         ['conv1d_787[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_393 (Batch  (None, 100, 64)     256         ['conv1d_788[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_392 (Activation)    (None, 100, 64)      0           ['batch_normalization_392[0][0]']\n",
      "                                                                                                  \n",
      " add_75 (Add)                   (None, 100, 64)      0           ['batch_normalization_393[0][0]',\n",
      "                                                                  'activation_392[0][0]']         \n",
      "                                                                                                  \n",
      " activation_393 (Activation)    (None, 100, 64)      0           ['add_75[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_789 (Conv1D)            (None, 100, 128)     65664       ['activation_393[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_394 (Batch  (None, 100, 128)    512         ['conv1d_789[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_394 (Activation)    (None, 100, 128)     0           ['batch_normalization_394[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_790 (Conv1D)            (None, 100, 128)     82048       ['activation_394[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_395 (Batch  (None, 100, 128)    512         ['conv1d_790[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_395 (Activation)    (None, 100, 128)     0           ['batch_normalization_395[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_791 (Conv1D)            (None, 100, 128)     49280       ['activation_395[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_792 (Conv1D)            (None, 100, 128)     8320        ['activation_393[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_396 (Batch  (None, 100, 128)    512         ['conv1d_791[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_397 (Batch  (None, 100, 128)    512         ['conv1d_792[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_396 (Activation)    (None, 100, 128)     0           ['batch_normalization_396[0][0]']\n",
      "                                                                                                  \n",
      " add_76 (Add)                   (None, 100, 128)     0           ['batch_normalization_397[0][0]',\n",
      "                                                                  'activation_396[0][0]']         \n",
      "                                                                                                  \n",
      " activation_397 (Activation)    (None, 100, 128)     0           ['add_76[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_793 (Conv1D)            (None, 100, 128)     131200      ['activation_397[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_398 (Batch  (None, 100, 128)    512         ['conv1d_793[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_398 (Activation)    (None, 100, 128)     0           ['batch_normalization_398[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_794 (Conv1D)            (None, 100, 128)     82048       ['activation_398[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_399 (Batch  (None, 100, 128)    512         ['conv1d_794[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_399 (Activation)    (None, 100, 128)     0           ['batch_normalization_399[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_795 (Conv1D)            (None, 100, 128)     49280       ['activation_399[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_400 (Batch  (None, 100, 128)    512         ['conv1d_795[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_401 (Batch  (None, 100, 128)    512         ['activation_397[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_400 (Activation)    (None, 100, 128)     0           ['batch_normalization_400[0][0]']\n",
      "                                                                                                  \n",
      " add_77 (Add)                   (None, 100, 128)     0           ['batch_normalization_401[0][0]',\n",
      "                                                                  'activation_400[0][0]']         \n",
      "                                                                                                  \n",
      " activation_401 (Activation)    (None, 100, 128)     0           ['add_77[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_55 (G  (None, 128)         0           ['activation_401[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_505 (Dense)              (None, 1)            129         ['global_average_pooling1d_55[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 245: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 266: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 286: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 306: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\n",
      "Epoch 326: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "\n",
      "Epoch 346: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n",
      "Model: \"model_296\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_297 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_796 (Conv1D)            (None, 100, 64)      36928       ['input_297[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_402 (Batch  (None, 100, 64)     256         ['conv1d_796[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_402 (Activation)    (None, 100, 64)      0           ['batch_normalization_402[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_797 (Conv1D)            (None, 100, 64)      20544       ['activation_402[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_403 (Batch  (None, 100, 64)     256         ['conv1d_797[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_403 (Activation)    (None, 100, 64)      0           ['batch_normalization_403[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_798 (Conv1D)            (None, 100, 64)      12352       ['activation_403[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_799 (Conv1D)            (None, 100, 64)      4672        ['input_297[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_404 (Batch  (None, 100, 64)     256         ['conv1d_798[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_405 (Batch  (None, 100, 64)     256         ['conv1d_799[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_404 (Activation)    (None, 100, 64)      0           ['batch_normalization_404[0][0]']\n",
      "                                                                                                  \n",
      " add_78 (Add)                   (None, 100, 64)      0           ['batch_normalization_405[0][0]',\n",
      "                                                                  'activation_404[0][0]']         \n",
      "                                                                                                  \n",
      " activation_405 (Activation)    (None, 100, 64)      0           ['add_78[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_800 (Conv1D)            (None, 100, 128)     65664       ['activation_405[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_406 (Batch  (None, 100, 128)    512         ['conv1d_800[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_406 (Activation)    (None, 100, 128)     0           ['batch_normalization_406[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_801 (Conv1D)            (None, 100, 128)     82048       ['activation_406[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_407 (Batch  (None, 100, 128)    512         ['conv1d_801[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_407 (Activation)    (None, 100, 128)     0           ['batch_normalization_407[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_802 (Conv1D)            (None, 100, 128)     49280       ['activation_407[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_803 (Conv1D)            (None, 100, 128)     8320        ['activation_405[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_408 (Batch  (None, 100, 128)    512         ['conv1d_802[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_409 (Batch  (None, 100, 128)    512         ['conv1d_803[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_408 (Activation)    (None, 100, 128)     0           ['batch_normalization_408[0][0]']\n",
      "                                                                                                  \n",
      " add_79 (Add)                   (None, 100, 128)     0           ['batch_normalization_409[0][0]',\n",
      "                                                                  'activation_408[0][0]']         \n",
      "                                                                                                  \n",
      " activation_409 (Activation)    (None, 100, 128)     0           ['add_79[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_804 (Conv1D)            (None, 100, 128)     131200      ['activation_409[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_410 (Batch  (None, 100, 128)    512         ['conv1d_804[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_410 (Activation)    (None, 100, 128)     0           ['batch_normalization_410[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_805 (Conv1D)            (None, 100, 128)     82048       ['activation_410[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_411 (Batch  (None, 100, 128)    512         ['conv1d_805[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_411 (Activation)    (None, 100, 128)     0           ['batch_normalization_411[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_806 (Conv1D)            (None, 100, 128)     49280       ['activation_411[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_412 (Batch  (None, 100, 128)    512         ['conv1d_806[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_413 (Batch  (None, 100, 128)    512         ['activation_409[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_412 (Activation)    (None, 100, 128)     0           ['batch_normalization_412[0][0]']\n",
      "                                                                                                  \n",
      " add_80 (Add)                   (None, 100, 128)     0           ['batch_normalization_413[0][0]',\n",
      "                                                                  'activation_412[0][0]']         \n",
      "                                                                                                  \n",
      " activation_413 (Activation)    (None, 100, 128)     0           ['add_80[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_56 (G  (None, 128)         0           ['activation_413[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_506 (Dense)              (None, 1)            129         ['global_average_pooling1d_56[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 150: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 170: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 207: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 227: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 247: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 267: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 287: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Model: \"model_297\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_298 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_807 (Conv1D)            (None, 100, 64)      36928       ['input_298[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_414 (Batch  (None, 100, 64)     256         ['conv1d_807[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_414 (Activation)    (None, 100, 64)      0           ['batch_normalization_414[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_808 (Conv1D)            (None, 100, 64)      20544       ['activation_414[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_415 (Batch  (None, 100, 64)     256         ['conv1d_808[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_415 (Activation)    (None, 100, 64)      0           ['batch_normalization_415[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_809 (Conv1D)            (None, 100, 64)      12352       ['activation_415[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_810 (Conv1D)            (None, 100, 64)      4672        ['input_298[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_416 (Batch  (None, 100, 64)     256         ['conv1d_809[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_417 (Batch  (None, 100, 64)     256         ['conv1d_810[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_416 (Activation)    (None, 100, 64)      0           ['batch_normalization_416[0][0]']\n",
      "                                                                                                  \n",
      " add_81 (Add)                   (None, 100, 64)      0           ['batch_normalization_417[0][0]',\n",
      "                                                                  'activation_416[0][0]']         \n",
      "                                                                                                  \n",
      " activation_417 (Activation)    (None, 100, 64)      0           ['add_81[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_811 (Conv1D)            (None, 100, 128)     65664       ['activation_417[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_418 (Batch  (None, 100, 128)    512         ['conv1d_811[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_418 (Activation)    (None, 100, 128)     0           ['batch_normalization_418[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_812 (Conv1D)            (None, 100, 128)     82048       ['activation_418[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_419 (Batch  (None, 100, 128)    512         ['conv1d_812[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_419 (Activation)    (None, 100, 128)     0           ['batch_normalization_419[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_813 (Conv1D)            (None, 100, 128)     49280       ['activation_419[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_814 (Conv1D)            (None, 100, 128)     8320        ['activation_417[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_420 (Batch  (None, 100, 128)    512         ['conv1d_813[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_421 (Batch  (None, 100, 128)    512         ['conv1d_814[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_420 (Activation)    (None, 100, 128)     0           ['batch_normalization_420[0][0]']\n",
      "                                                                                                  \n",
      " add_82 (Add)                   (None, 100, 128)     0           ['batch_normalization_421[0][0]',\n",
      "                                                                  'activation_420[0][0]']         \n",
      "                                                                                                  \n",
      " activation_421 (Activation)    (None, 100, 128)     0           ['add_82[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_815 (Conv1D)            (None, 100, 128)     131200      ['activation_421[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_422 (Batch  (None, 100, 128)    512         ['conv1d_815[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_422 (Activation)    (None, 100, 128)     0           ['batch_normalization_422[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_816 (Conv1D)            (None, 100, 128)     82048       ['activation_422[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_423 (Batch  (None, 100, 128)    512         ['conv1d_816[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_423 (Activation)    (None, 100, 128)     0           ['batch_normalization_423[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_817 (Conv1D)            (None, 100, 128)     49280       ['activation_423[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_424 (Batch  (None, 100, 128)    512         ['conv1d_817[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_425 (Batch  (None, 100, 128)    512         ['activation_421[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_424 (Activation)    (None, 100, 128)     0           ['batch_normalization_424[0][0]']\n",
      "                                                                                                  \n",
      " add_83 (Add)                   (None, 100, 128)     0           ['batch_normalization_425[0][0]',\n",
      "                                                                  'activation_424[0][0]']         \n",
      "                                                                                                  \n",
      " activation_425 (Activation)    (None, 100, 128)     0           ['add_83[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_57 (G  (None, 128)         0           ['activation_425[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_507 (Dense)              (None, 1)            129         ['global_average_pooling1d_57[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 155: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 175: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 242: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 262: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 282: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\n",
      "Epoch 302: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "\n",
      "Epoch 322: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n",
      "Model: \"model_298\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_299 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_818 (Conv1D)            (None, 100, 64)      36928       ['input_299[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_426 (Batch  (None, 100, 64)     256         ['conv1d_818[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_426 (Activation)    (None, 100, 64)      0           ['batch_normalization_426[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_819 (Conv1D)            (None, 100, 64)      20544       ['activation_426[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_427 (Batch  (None, 100, 64)     256         ['conv1d_819[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_427 (Activation)    (None, 100, 64)      0           ['batch_normalization_427[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_820 (Conv1D)            (None, 100, 64)      12352       ['activation_427[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_821 (Conv1D)            (None, 100, 64)      4672        ['input_299[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_428 (Batch  (None, 100, 64)     256         ['conv1d_820[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_429 (Batch  (None, 100, 64)     256         ['conv1d_821[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_428 (Activation)    (None, 100, 64)      0           ['batch_normalization_428[0][0]']\n",
      "                                                                                                  \n",
      " add_84 (Add)                   (None, 100, 64)      0           ['batch_normalization_429[0][0]',\n",
      "                                                                  'activation_428[0][0]']         \n",
      "                                                                                                  \n",
      " activation_429 (Activation)    (None, 100, 64)      0           ['add_84[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_822 (Conv1D)            (None, 100, 128)     65664       ['activation_429[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_430 (Batch  (None, 100, 128)    512         ['conv1d_822[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_430 (Activation)    (None, 100, 128)     0           ['batch_normalization_430[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_823 (Conv1D)            (None, 100, 128)     82048       ['activation_430[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_431 (Batch  (None, 100, 128)    512         ['conv1d_823[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_431 (Activation)    (None, 100, 128)     0           ['batch_normalization_431[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_824 (Conv1D)            (None, 100, 128)     49280       ['activation_431[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_825 (Conv1D)            (None, 100, 128)     8320        ['activation_429[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_432 (Batch  (None, 100, 128)    512         ['conv1d_824[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_433 (Batch  (None, 100, 128)    512         ['conv1d_825[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_432 (Activation)    (None, 100, 128)     0           ['batch_normalization_432[0][0]']\n",
      "                                                                                                  \n",
      " add_85 (Add)                   (None, 100, 128)     0           ['batch_normalization_433[0][0]',\n",
      "                                                                  'activation_432[0][0]']         \n",
      "                                                                                                  \n",
      " activation_433 (Activation)    (None, 100, 128)     0           ['add_85[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_826 (Conv1D)            (None, 100, 128)     131200      ['activation_433[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_434 (Batch  (None, 100, 128)    512         ['conv1d_826[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_434 (Activation)    (None, 100, 128)     0           ['batch_normalization_434[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_827 (Conv1D)            (None, 100, 128)     82048       ['activation_434[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_435 (Batch  (None, 100, 128)    512         ['conv1d_827[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_435 (Activation)    (None, 100, 128)     0           ['batch_normalization_435[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_828 (Conv1D)            (None, 100, 128)     49280       ['activation_435[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_436 (Batch  (None, 100, 128)    512         ['conv1d_828[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_437 (Batch  (None, 100, 128)    512         ['activation_433[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_436 (Activation)    (None, 100, 128)     0           ['batch_normalization_436[0][0]']\n",
      "                                                                                                  \n",
      " add_86 (Add)                   (None, 100, 128)     0           ['batch_normalization_437[0][0]',\n",
      "                                                                  'activation_436[0][0]']         \n",
      "                                                                                                  \n",
      " activation_437 (Activation)    (None, 100, 128)     0           ['add_86[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_58 (G  (None, 128)         0           ['activation_437[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_508 (Dense)              (None, 1)            129         ['global_average_pooling1d_58[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 245: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 265: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 285: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\n",
      "Epoch 305: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\n",
      "Epoch 325: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "Model: \"model_299\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_300 (InputLayer)         [(None, 100, 72)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_829 (Conv1D)            (None, 100, 64)      36928       ['input_300[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_438 (Batch  (None, 100, 64)     256         ['conv1d_829[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_438 (Activation)    (None, 100, 64)      0           ['batch_normalization_438[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_830 (Conv1D)            (None, 100, 64)      20544       ['activation_438[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_439 (Batch  (None, 100, 64)     256         ['conv1d_830[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_439 (Activation)    (None, 100, 64)      0           ['batch_normalization_439[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_831 (Conv1D)            (None, 100, 64)      12352       ['activation_439[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_832 (Conv1D)            (None, 100, 64)      4672        ['input_300[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_440 (Batch  (None, 100, 64)     256         ['conv1d_831[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_441 (Batch  (None, 100, 64)     256         ['conv1d_832[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_440 (Activation)    (None, 100, 64)      0           ['batch_normalization_440[0][0]']\n",
      "                                                                                                  \n",
      " add_87 (Add)                   (None, 100, 64)      0           ['batch_normalization_441[0][0]',\n",
      "                                                                  'activation_440[0][0]']         \n",
      "                                                                                                  \n",
      " activation_441 (Activation)    (None, 100, 64)      0           ['add_87[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_833 (Conv1D)            (None, 100, 128)     65664       ['activation_441[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_442 (Batch  (None, 100, 128)    512         ['conv1d_833[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_442 (Activation)    (None, 100, 128)     0           ['batch_normalization_442[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_834 (Conv1D)            (None, 100, 128)     82048       ['activation_442[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_443 (Batch  (None, 100, 128)    512         ['conv1d_834[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_443 (Activation)    (None, 100, 128)     0           ['batch_normalization_443[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_835 (Conv1D)            (None, 100, 128)     49280       ['activation_443[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_836 (Conv1D)            (None, 100, 128)     8320        ['activation_441[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_444 (Batch  (None, 100, 128)    512         ['conv1d_835[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_445 (Batch  (None, 100, 128)    512         ['conv1d_836[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_444 (Activation)    (None, 100, 128)     0           ['batch_normalization_444[0][0]']\n",
      "                                                                                                  \n",
      " add_88 (Add)                   (None, 100, 128)     0           ['batch_normalization_445[0][0]',\n",
      "                                                                  'activation_444[0][0]']         \n",
      "                                                                                                  \n",
      " activation_445 (Activation)    (None, 100, 128)     0           ['add_88[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_837 (Conv1D)            (None, 100, 128)     131200      ['activation_445[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_446 (Batch  (None, 100, 128)    512         ['conv1d_837[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_446 (Activation)    (None, 100, 128)     0           ['batch_normalization_446[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_838 (Conv1D)            (None, 100, 128)     82048       ['activation_446[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_447 (Batch  (None, 100, 128)    512         ['conv1d_838[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_447 (Activation)    (None, 100, 128)     0           ['batch_normalization_447[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_839 (Conv1D)            (None, 100, 128)     49280       ['activation_447[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_448 (Batch  (None, 100, 128)    512         ['conv1d_839[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_449 (Batch  (None, 100, 128)    512         ['activation_445[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_448 (Activation)    (None, 100, 128)     0           ['batch_normalization_448[0][0]']\n",
      "                                                                                                  \n",
      " add_89 (Add)                   (None, 100, 128)     0           ['batch_normalization_449[0][0]',\n",
      "                                                                  'activation_448[0][0]']         \n",
      "                                                                                                  \n",
      " activation_449 (Activation)    (None, 100, 128)     0           ['add_89[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_59 (G  (None, 128)         0           ['activation_449[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_509 (Dense)              (None, 1)            129         ['global_average_pooling1d_59[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 547,585\n",
      "Trainable params: 545,025\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 130: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 150: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 170: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 190: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 210: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for model_name in model_dict:\n",
    "    model_func = model_dict[model_name][\"model\"]\n",
    "    lr = model_dict[model_name][\"lr\"]\n",
    "    print(\"##################################################\")\n",
    "    print(\"model: \", model_name)\n",
    "    for ii in range(n_runs):     \n",
    "        dfs.append(multi_site(model_func, model_name, lr, X, y, random_states[ii], augment=False))\n",
    "        one_df = pd.concat(dfs)\n",
    "        one_df.to_csv(\"multi_site_noaug.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54c9f49b-30aa-469f-97f4-f9e5d6b53b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "debug\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "azureml_py38_pt_tf"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - Pytorch and Tensorflow",
   "language": "python",
   "name": "azureml_py38_pt_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
