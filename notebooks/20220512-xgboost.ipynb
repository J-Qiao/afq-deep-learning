{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f8734f6",
   "metadata": {
    "gather": {
     "logged": 1652119071245
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import afqinsight.nn.tf_models as nn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from afqinsight.datasets import AFQDataset\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os.path\n",
    "# Harmonization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from neurocombat_sklearn import CombatModel\n",
    "import pickle\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from skopt import BayesSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0eccb79",
   "metadata": {
    "gather": {
     "logged": 1652119099910
    }
   },
   "outputs": [],
   "source": [
    "afq_dataset = AFQDataset.from_files(\n",
    "    fn_nodes=\"../data/raw/combined_tract_profiles.csv\",\n",
    "    fn_subjects=\"../data/raw/participants_updated_id.csv\",\n",
    "    dwi_metrics=[\"dki_fa\", \"dki_md\", \"dki_mk\"],\n",
    "    index_col=\"subject_id\",\n",
    "    target_cols=[\"age\", \"dl_qc_score\", \"scan_site_id\"],\n",
    "    label_encode_cols=[\"scan_site_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fc97db2",
   "metadata": {
    "gather": {
     "logged": 1652119100074
    }
   },
   "outputs": [],
   "source": [
    "afq_dataset.drop_target_na()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d47ebb60",
   "metadata": {
    "gather": {
     "logged": 1652119100214
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1865\n",
      "(1865, 7200)\n",
      "(1865, 3)\n"
     ]
    }
   ],
   "source": [
    "print(len(afq_dataset.subjects))\n",
    "print(afq_dataset.X.shape)\n",
    "print(afq_dataset.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c366051",
   "metadata": {
    "gather": {
     "logged": 1652119101512
    }
   },
   "outputs": [],
   "source": [
    "full_dataset = list(afq_dataset.as_tensorflow_dataset().as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23c2e7ff",
   "metadata": {
    "gather": {
     "logged": 1652119101663
    }
   },
   "outputs": [],
   "source": [
    "X = np.concatenate([xx[0][None] for xx in full_dataset], 0)\n",
    "y = np.array([yy[1][0] for yy in full_dataset])\n",
    "qc = np.array([yy[1][1] for yy in full_dataset])\n",
    "site = np.array([yy[1][2] for yy in full_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51b259a0",
   "metadata": {
    "gather": {
     "logged": 1652119101816
    }
   },
   "outputs": [],
   "source": [
    "X = X[qc>0]\n",
    "y = y[qc>0]\n",
    "site = site[qc>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cd2e9ca",
   "metadata": {
    "gather": {
     "logged": 1652119104214
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "# EarlyStopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.001,\n",
    "    mode=\"min\",\n",
    "    patience=100\n",
    ")\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fe3fa6a",
   "metadata": {
    "gather": {
     "logged": 1652119104392
    }
   },
   "outputs": [],
   "source": [
    "from afqinsight.augmentation import jitter, time_warp, scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bb58b1b",
   "metadata": {
    "gather": {
     "logged": 1652119104562
    }
   },
   "outputs": [],
   "source": [
    "def augment_this(X, y, rounds=2): \n",
    "    new_X = X[:]\n",
    "    new_y = y[:]\n",
    "    for f in range(rounds): \n",
    "        aug_X = np.zeros_like(X)\n",
    "        # Do each channel separately:\n",
    "        for channel in range(aug_X.shape[-1]):\n",
    "            this_X = X[..., channel][..., np.newaxis]\n",
    "            this_X = jitter(this_X, sigma=np.mean(this_X)/25)\n",
    "            this_X = scaling(this_X, sigma=np.mean(this_X)/25)\n",
    "            this_X = time_warp(this_X, sigma=np.mean(this_X)/25)\n",
    "            aug_X[..., channel] = this_X[...,0]\n",
    "        new_X = np.concatenate([new_X, aug_X])\n",
    "        new_y = np.concatenate([new_y, y])\n",
    "    return new_X, new_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abffc58d-e5bf-47e3-a82f-94df7f92ee56",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1652119104750
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle, resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f091370-5672-4d9e-8fd5-14cc924e8ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebf713d5",
   "metadata": {
    "gather": {
     "logged": 1652119104978
    }
   },
   "outputs": [],
   "source": [
    "# Generate evaluation results, training history, number of epochs\n",
    "def fit_model(X, y, random_state, augment=True):\n",
    "    # Split the data into train and test sets:\n",
    "    X_train, X_test, y_train, y_test, site_train, site_test = train_test_split(X, y, site, test_size=0.2, random_state=random_state)\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    # Impute train and test separately:\n",
    "    X_train = np.concatenate([imputer.fit_transform(X_train[..., ii])[:, :, None] for ii in range(X_train.shape[-1])], -1)\n",
    "    X_test = np.concatenate([imputer.fit_transform(X_test[..., ii])[:, :, None] for ii in range(X_test.shape[-1])], -1)\n",
    "    # Combat\n",
    "    X_train = np.concatenate([CombatModel().fit_transform(X_train[..., ii], site_train[:, None], None, None)[:, :, None] for ii in range(X_train.shape[-1])], -1)\n",
    "    X_test = np.concatenate([CombatModel().fit_transform(X_test[..., ii], site_test[:, None], None, None)[:, :, None] for ii in range(X_test.shape[-1])], -1)\n",
    "    \n",
    "    # Reshape for xgboost\n",
    "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "    \n",
    "    params = {\n",
    "    \"n_estimators\": (50, 2001),\n",
    "    \"min_child_weight\": (1, 11),\n",
    "    \"gamma\": (0.01, 5.0, \"log-uniform\"),\n",
    "    \"eta\": (0.005, 0.5, \"log-uniform\"),\n",
    "    \"subsample\": (0.2, 1.0),\n",
    "    \"colsample_bytree\": (0.2, 1.0),\n",
    "    \"max_depth\": (2, 6),\n",
    "    }\n",
    "    xgb = XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        nthread=32,\n",
    "        verbosity=1,\n",
    "    )\n",
    "    opt = BayesSearchCV(\n",
    "        xgb,\n",
    "        params,\n",
    "        n_iter=100,\n",
    "    )\n",
    "    if augment:\n",
    "        X_train, y_train = augment_this(X_train, y_train, rounds=6)\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "    \n",
    "    _ = opt.fit(X_train, y_train)\n",
    "        \n",
    "    y_pred = opt.predict(X_test)    \n",
    "    eval_model = [mean_absolute_error(y_test, y_pred), median_absolute_error(y_test, y_pred), r2_score(y_test, y_pred)]\n",
    "    return eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b3a4145-6070-417f-b859-4f001cef9c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3abcbeb5-f109-4d84-90e1-92aecc61b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "augment=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df4f3387-bb0c-4b6c-ac9a-8f6e87be0314",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = np.array([np.abs(np.floor(np.random.randn()*1000)) for ii in range(n_runs)], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a37d42a-876e-4fb4-abed-f8ab7b784698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd035f48",
   "metadata": {
    "gather": {
     "logged": 1652213549742
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"##################################################\")\n",
    "results = []\n",
    "\n",
    "for ii in range(n_runs): \n",
    "    print(ii)\n",
    "    this_eval = fit_model(X, y, random_state=seeds[ii], augment=augment)\n",
    "    results.append(this_eval)\n",
    "    with open(f'results_xgboost.pickle', 'wb') as file:\n",
    "        pickle.dump(results, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12595999-03fa-484d-a7e4-22608ba7605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4367d4-4dd5-4463-9fd7-073112622f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "azureml_py38_pt_tf"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - Pytorch and Tensorflow",
   "language": "python",
   "name": "azureml_py38_pt_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
