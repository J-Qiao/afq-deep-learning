{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import afqinsight.nn.tf_models as nn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from afqinsight.datasets import AFQDataset\n",
    "from afqinsight.nn.tf_models import mlp4, cnn_lenet\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "afq_dataset = AFQDataset(\n",
    "    fn_nodes=\"../data/raw/combined_tract_profiles.csv\",\n",
    "    fn_subjects=\"../data/raw/participants_updated_id.csv\",\n",
    "    dwi_metrics=[\"dki_fa\", \"dki_md\"],\n",
    "    target_cols=[\"age\"],\n",
    "    index_col=\"subject_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "afq_dataset.drop_target_na()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1867\n",
      "(1867, 4800)\n",
      "(1867,)\n"
     ]
    }
   ],
   "source": [
    "print(len(afq_dataset.subjects))\n",
    "print(afq_dataset.X.shape)\n",
    "print(afq_dataset.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we impute missing bundles.\n",
    "# We impute using the entire dataset, which permits data leakage between the train and test set.\n",
    "# THIS IS BAD AND SHOULDN'T BE DONE IN PRODUCTION\n",
    "# But we do it here to move straight to model training\n",
    "# When we are more comfortabel with the models, we should come back\n",
    "# here and train the imputer only on the training set.\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "afq_dataset.X = imputer.fit_transform(afq_dataset.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 19:51:03.887256: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Separate into training, test, and validation sets\n",
    "dataset_size = len(afq_dataset.subjects)\n",
    "train_size = int(0.7 * dataset_size)\n",
    "val_size = int(0.15 * dataset_size)\n",
    "test_size = int(0.15 * dataset_size)\n",
    "\n",
    "full_dataset = afq_dataset.as_tensorflow_dataset()\n",
    "full_dataset = full_dataset.shuffle(buffer_size=dataset_size, seed=0)\n",
    "\n",
    "train_dataset = full_dataset.take(train_size)\n",
    "test_dataset = full_dataset.skip(train_size)\n",
    "val_dataset = test_dataset.skip(val_size)\n",
    "test_dataset = test_dataset.take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooling layers: 4\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 48)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 100, 6)            870       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 50, 6)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 25, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 12, 26)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 6, 36)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 216)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,581\n",
      "Trainable params: 41,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# First let's check out the ``cnn_lenet`` from the tf_models module\n",
    "model_cnn_lenet= cnn_lenet(input_shape=(100, 48) , n_classes=1, output_activation=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 11.0077 - mean_squared_error: 11.0077 - val_loss: 7.4126 - val_mean_squared_error: 7.4126\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 11.1235 - mean_squared_error: 11.1235 - val_loss: 6.0198 - val_mean_squared_error: 6.0198\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 10.2741 - mean_squared_error: 10.2741 - val_loss: 6.7171 - val_mean_squared_error: 6.7171\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 10.0846 - mean_squared_error: 10.0846 - val_loss: 6.3082 - val_mean_squared_error: 6.3082\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 9.6707 - mean_squared_error: 9.6707 - val_loss: 6.3514 - val_mean_squared_error: 6.3514\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 9.7272 - mean_squared_error: 9.7272 - val_loss: 7.0819 - val_mean_squared_error: 7.0819\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 10.0557 - mean_squared_error: 10.0557 - val_loss: 5.6375 - val_mean_squared_error: 5.6375\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 10.0196 - mean_squared_error: 10.0196 - val_loss: 6.4302 - val_mean_squared_error: 6.4302\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.9042 - mean_squared_error: 8.9042 - val_loss: 7.1890 - val_mean_squared_error: 7.1890\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 10.0238 - mean_squared_error: 10.0238 - val_loss: 5.9664 - val_mean_squared_error: 5.9664\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 9.9647 - mean_squared_error: 9.9647 - val_loss: 5.5835 - val_mean_squared_error: 5.5835\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 9.8296 - mean_squared_error: 9.8296 - val_loss: 6.9359 - val_mean_squared_error: 6.9359\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 9.2562 - mean_squared_error: 9.2562 - val_loss: 6.0774 - val_mean_squared_error: 6.0774\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 8.7207 - mean_squared_error: 8.7207 - val_loss: 5.8135 - val_mean_squared_error: 5.8135\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 9.2255 - mean_squared_error: 9.2255 - val_loss: 6.0873 - val_mean_squared_error: 6.0873\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 9.0193 - mean_squared_error: 9.0193 - val_loss: 7.5897 - val_mean_squared_error: 7.5897\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 9.1307 - mean_squared_error: 9.1307 - val_loss: 5.4717 - val_mean_squared_error: 5.4717\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 9.0005 - mean_squared_error: 9.0005 - val_loss: 6.0244 - val_mean_squared_error: 6.0244\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 9.7382 - mean_squared_error: 9.7382 - val_loss: 5.9751 - val_mean_squared_error: 5.9751\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 9.3755 - mean_squared_error: 9.3755 - val_loss: 6.5185 - val_mean_squared_error: 6.5185\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.9946 - mean_squared_error: 8.9946 - val_loss: 6.7408 - val_mean_squared_error: 6.7408\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 9.5924 - mean_squared_error: 9.5924 - val_loss: 7.2755 - val_mean_squared_error: 7.2755\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 9.0529 - mean_squared_error: 9.0529 - val_loss: 5.8315 - val_mean_squared_error: 5.8315\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.9992 - mean_squared_error: 8.9992 - val_loss: 6.0499 - val_mean_squared_error: 6.0499\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 9.1300 - mean_squared_error: 9.1300 - val_loss: 6.5423 - val_mean_squared_error: 6.5423\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 9.0019 - mean_squared_error: 9.0019 - val_loss: 6.5271 - val_mean_squared_error: 6.5271\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.5929 - mean_squared_error: 8.5929 - val_loss: 5.2810 - val_mean_squared_error: 5.2810\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.3662 - mean_squared_error: 8.3662 - val_loss: 6.1073 - val_mean_squared_error: 6.1073\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 9.3339 - mean_squared_error: 9.3339 - val_loss: 5.1824 - val_mean_squared_error: 5.1824\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 9.2575 - mean_squared_error: 9.2575 - val_loss: 6.1815 - val_mean_squared_error: 6.1815\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.9887 - mean_squared_error: 8.9887 - val_loss: 5.8358 - val_mean_squared_error: 5.8358\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 9.5791 - mean_squared_error: 9.5791 - val_loss: 6.9433 - val_mean_squared_error: 6.9433\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.9143 - mean_squared_error: 8.9143 - val_loss: 6.4662 - val_mean_squared_error: 6.4662\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 8.4734 - mean_squared_error: 8.4734 - val_loss: 5.7432 - val_mean_squared_error: 5.7432\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 9.4571 - mean_squared_error: 9.4571 - val_loss: 5.8248 - val_mean_squared_error: 5.8248\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 8.6957 - mean_squared_error: 8.6957 - val_loss: 5.1642 - val_mean_squared_error: 5.1642\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 8.6351 - mean_squared_error: 8.6351 - val_loss: 5.9889 - val_mean_squared_error: 5.9889\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 9.1732 - mean_squared_error: 9.1732 - val_loss: 6.3145 - val_mean_squared_error: 6.3145\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 9.6176 - mean_squared_error: 9.6176 - val_loss: 6.1370 - val_mean_squared_error: 6.1370\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.6844 - mean_squared_error: 8.6844 - val_loss: 7.7785 - val_mean_squared_error: 7.7785\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.4477 - mean_squared_error: 8.4477 - val_loss: 6.5986 - val_mean_squared_error: 6.5986\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.9259 - mean_squared_error: 8.9259 - val_loss: 5.4869 - val_mean_squared_error: 5.4869\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 8.8266 - mean_squared_error: 8.8266 - val_loss: 5.9188 - val_mean_squared_error: 5.9188\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 9.2935 - mean_squared_error: 9.2935 - val_loss: 5.4529 - val_mean_squared_error: 5.4529\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.3766 - mean_squared_error: 8.3766 - val_loss: 6.3209 - val_mean_squared_error: 6.3209\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.9320 - mean_squared_error: 8.9320 - val_loss: 5.5733 - val_mean_squared_error: 5.5733\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.5843 - mean_squared_error: 8.5843 - val_loss: 6.0018 - val_mean_squared_error: 6.0018\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.2616 - mean_squared_error: 8.2616 - val_loss: 5.2081 - val_mean_squared_error: 5.2081\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.5054 - mean_squared_error: 8.5054 - val_loss: 5.3270 - val_mean_squared_error: 5.3270\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 8.9246 - mean_squared_error: 8.9246 - val_loss: 5.6926 - val_mean_squared_error: 5.6926\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 26ms/step - loss: 8.6187 - mean_squared_error: 8.6187 - val_loss: 5.4408 - val_mean_squared_error: 5.4408\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 8.2261 - mean_squared_error: 8.2261 - val_loss: 5.6231 - val_mean_squared_error: 5.6231\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.9730 - mean_squared_error: 7.9730 - val_loss: 6.3035 - val_mean_squared_error: 6.3035\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 8.5418 - mean_squared_error: 8.5418 - val_loss: 5.5108 - val_mean_squared_error: 5.5108\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.4324 - mean_squared_error: 8.4324 - val_loss: 5.2955 - val_mean_squared_error: 5.2955\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.1491 - mean_squared_error: 8.1491 - val_loss: 6.1753 - val_mean_squared_error: 6.1753\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.5335 - mean_squared_error: 8.5335 - val_loss: 5.2943 - val_mean_squared_error: 5.2943\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.2674 - mean_squared_error: 8.2674 - val_loss: 6.9055 - val_mean_squared_error: 6.9055\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.8593 - mean_squared_error: 8.8593 - val_loss: 5.1407 - val_mean_squared_error: 5.1407\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.3876 - mean_squared_error: 8.3876 - val_loss: 5.3976 - val_mean_squared_error: 5.3976\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.7423 - mean_squared_error: 8.7423 - val_loss: 5.6800 - val_mean_squared_error: 5.6800\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 7.6005 - mean_squared_error: 7.6005 - val_loss: 5.3393 - val_mean_squared_error: 5.3393\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.1073 - mean_squared_error: 8.1073 - val_loss: 4.7847 - val_mean_squared_error: 4.7847\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.1365 - mean_squared_error: 8.1365 - val_loss: 5.2251 - val_mean_squared_error: 5.2251\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.2024 - mean_squared_error: 7.2024 - val_loss: 5.5106 - val_mean_squared_error: 5.5106\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.1624 - mean_squared_error: 8.1624 - val_loss: 5.7291 - val_mean_squared_error: 5.7291\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.7180 - mean_squared_error: 7.7180 - val_loss: 5.3503 - val_mean_squared_error: 5.3503\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.4323 - mean_squared_error: 7.4323 - val_loss: 5.3874 - val_mean_squared_error: 5.3874\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.6088 - mean_squared_error: 7.6088 - val_loss: 4.7880 - val_mean_squared_error: 4.7880\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 8.7458 - mean_squared_error: 8.7458 - val_loss: 5.5721 - val_mean_squared_error: 5.5721\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 8.3579 - mean_squared_error: 8.3579 - val_loss: 5.1076 - val_mean_squared_error: 5.1076\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.1807 - mean_squared_error: 7.1807 - val_loss: 5.4077 - val_mean_squared_error: 5.4077\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 7.5758 - mean_squared_error: 7.5758 - val_loss: 5.9341 - val_mean_squared_error: 5.9341\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.9765 - mean_squared_error: 7.9765 - val_loss: 5.2619 - val_mean_squared_error: 5.2619\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.5203 - mean_squared_error: 7.5203 - val_loss: 5.6319 - val_mean_squared_error: 5.6319\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.4257 - mean_squared_error: 7.4257 - val_loss: 4.8247 - val_mean_squared_error: 4.8247\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.7576 - mean_squared_error: 7.7576 - val_loss: 5.5122 - val_mean_squared_error: 5.5122\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 7.7518 - mean_squared_error: 7.7518 - val_loss: 4.6142 - val_mean_squared_error: 4.6142\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.9839 - mean_squared_error: 7.9839 - val_loss: 5.0889 - val_mean_squared_error: 5.0889\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 7.1567 - mean_squared_error: 7.1567 - val_loss: 6.7682 - val_mean_squared_error: 6.7682\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.3960 - mean_squared_error: 8.3960 - val_loss: 4.7977 - val_mean_squared_error: 4.7977\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.6878 - mean_squared_error: 7.6878 - val_loss: 7.2310 - val_mean_squared_error: 7.2310\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.0324 - mean_squared_error: 8.0324 - val_loss: 6.3629 - val_mean_squared_error: 6.3629\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.6800 - mean_squared_error: 7.6800 - val_loss: 5.4124 - val_mean_squared_error: 5.4124\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.0696 - mean_squared_error: 7.0696 - val_loss: 4.6943 - val_mean_squared_error: 4.6943\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.1751 - mean_squared_error: 7.1751 - val_loss: 7.1293 - val_mean_squared_error: 7.1293\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.1108 - mean_squared_error: 8.1108 - val_loss: 6.3243 - val_mean_squared_error: 6.3243\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.7363 - mean_squared_error: 7.7363 - val_loss: 5.3237 - val_mean_squared_error: 5.3237\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.2871 - mean_squared_error: 7.2871 - val_loss: 5.1373 - val_mean_squared_error: 5.1373\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.0084 - mean_squared_error: 7.0084 - val_loss: 5.4700 - val_mean_squared_error: 5.4700\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 6.8667 - mean_squared_error: 6.8667 - val_loss: 4.4882 - val_mean_squared_error: 4.4882\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.5042 - mean_squared_error: 7.5042 - val_loss: 4.7995 - val_mean_squared_error: 4.7995\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 7.8903 - mean_squared_error: 7.8903 - val_loss: 4.7659 - val_mean_squared_error: 4.7659\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.0605 - mean_squared_error: 7.0605 - val_loss: 4.1581 - val_mean_squared_error: 4.1581\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 6.9156 - mean_squared_error: 6.9156 - val_loss: 4.0446 - val_mean_squared_error: 4.0446\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.5840 - mean_squared_error: 7.5840 - val_loss: 6.0950 - val_mean_squared_error: 6.0950\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.2163 - mean_squared_error: 7.2163 - val_loss: 4.7439 - val_mean_squared_error: 4.7439\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.5011 - mean_squared_error: 7.5011 - val_loss: 4.5483 - val_mean_squared_error: 4.5483\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 7.6074 - mean_squared_error: 7.6074 - val_loss: 3.9821 - val_mean_squared_error: 3.9821\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 6.8901 - mean_squared_error: 6.8901 - val_loss: 4.6446 - val_mean_squared_error: 4.6446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe204d176a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model and fit it using training data\n",
    "model_cnn_lenet.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "model_cnn_lenet.fit(train_dataset, epochs=100, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 4.3186 - mean_squared_error: 4.3186\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "eval_cnn_lenet = model_cnn_lenet.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this model achieves a mean squared error of ~7.59, or an RMSE of ~2.5 years. This is probably an overly optimistic estimate because we imputed using the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an empty dictionary for results comparisons\n",
    "results = {'cnn_lenet' : eval_cnn_lenet}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 48)]         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4800)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 500)               2400500   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,902,001\n",
      "Trainable params: 2,902,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 14ms/step - loss: 42.3184 - mean_squared_error: 42.3184\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 14.8835 - mean_squared_error: 14.8835\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 15.7321 - mean_squared_error: 15.7321\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 14.2004 - mean_squared_error: 14.2004\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 13.2147 - mean_squared_error: 13.2147\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 13.4650 - mean_squared_error: 13.4650\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 13.6186 - mean_squared_error: 13.6186\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 13.4407 - mean_squared_error: 13.4407\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 13.3568 - mean_squared_error: 13.3568\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 13.8054 - mean_squared_error: 13.8054\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 13.6103 - mean_squared_error: 13.6103\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 14.0601 - mean_squared_error: 14.0601\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 13.0167 - mean_squared_error: 13.0167\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 13.6727 - mean_squared_error: 13.6727\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 12.8336 - mean_squared_error: 12.8336\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 13.0675 - mean_squared_error: 13.0675\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 12.3505 - mean_squared_error: 12.3505\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 12.1096 - mean_squared_error: 12.1096\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 11.9552 - mean_squared_error: 11.9552\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 13.0130 - mean_squared_error: 13.0130\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 14.3120 - mean_squared_error: 14.3120\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 13.3596 - mean_squared_error: 13.3596\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 13.3085 - mean_squared_error: 13.3085\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 11.6840 - mean_squared_error: 11.6840\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 11.3879 - mean_squared_error: 11.3879\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 11.4569 - mean_squared_error: 11.4569\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 11.3865 - mean_squared_error: 11.3865\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 11.5526 - mean_squared_error: 11.5526\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 11.3062 - mean_squared_error: 11.3062\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 12.0628 - mean_squared_error: 12.0628\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 11.6241 - mean_squared_error: 11.6241\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.1712 - mean_squared_error: 10.1712\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.5054 - mean_squared_error: 10.5054\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.0113 - mean_squared_error: 10.0113\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 12.5949 - mean_squared_error: 12.5949\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.1964 - mean_squared_error: 10.1964\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.2379 - mean_squared_error: 10.2379\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.8461 - mean_squared_error: 9.8461\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.2264 - mean_squared_error: 10.2264\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.6726 - mean_squared_error: 9.6726\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.4611 - mean_squared_error: 9.4611\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.1460 - mean_squared_error: 9.1460\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.5817 - mean_squared_error: 9.5817\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.5445 - mean_squared_error: 9.5445\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.4787 - mean_squared_error: 10.4787\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.1580 - mean_squared_error: 10.1580\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 12.2874 - mean_squared_error: 12.2874\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 12.1712 - mean_squared_error: 12.1712\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 11.1437 - mean_squared_error: 11.1437\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.6608 - mean_squared_error: 10.6608\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 11.4446 - mean_squared_error: 11.4446\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.3364 - mean_squared_error: 10.3364\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.6154 - mean_squared_error: 9.6154\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.6141 - mean_squared_error: 10.6141\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 11.0178 - mean_squared_error: 11.0178\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.9272 - mean_squared_error: 10.9272\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.4682 - mean_squared_error: 9.4682\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 9.1025 - mean_squared_error: 9.1025\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 10.2859 - mean_squared_error: 10.2859\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 9.4601 - mean_squared_error: 9.4601\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.7961 - mean_squared_error: 8.7961\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 9.2761 - mean_squared_error: 9.2761\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.2841 - mean_squared_error: 9.2841\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.0491 - mean_squared_error: 9.0491\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 10.3105 - mean_squared_error: 10.3105\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.2692 - mean_squared_error: 10.2692\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.1898 - mean_squared_error: 10.1898\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.8106 - mean_squared_error: 9.8106\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.8685 - mean_squared_error: 8.8685\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.1278 - mean_squared_error: 9.1278\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.7274 - mean_squared_error: 9.7274\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.7399 - mean_squared_error: 8.7399\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.8647 - mean_squared_error: 8.8647\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.5597 - mean_squared_error: 10.5597\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.5896 - mean_squared_error: 8.5896\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 8.9644 - mean_squared_error: 8.9644\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.9437 - mean_squared_error: 8.9437\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.8510 - mean_squared_error: 8.8510\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.5738 - mean_squared_error: 8.5738\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.4326 - mean_squared_error: 8.4326\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.7391 - mean_squared_error: 10.7391\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.9073 - mean_squared_error: 9.9073\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.9344 - mean_squared_error: 8.9344\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.3436 - mean_squared_error: 9.3436\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.9000 - mean_squared_error: 9.9000\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.2886 - mean_squared_error: 10.2886\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.1160 - mean_squared_error: 10.1160\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.5070 - mean_squared_error: 9.5070\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.4748 - mean_squared_error: 10.4748\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.7114 - mean_squared_error: 8.7114\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.4004 - mean_squared_error: 8.4004\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.8909 - mean_squared_error: 8.8909\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.5800 - mean_squared_error: 8.5800\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.3744 - mean_squared_error: 8.3744\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.6842 - mean_squared_error: 9.6842\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 8.9615 - mean_squared_error: 8.9615\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.5161 - mean_squared_error: 10.5161\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.4611 - mean_squared_error: 8.4611\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.1928 - mean_squared_error: 9.1928\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.7814 - mean_squared_error: 8.7814\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 10.7685 - mean_squared_error: 10.7685\n"
     ]
    }
   ],
   "source": [
    "#``mlp4`` from the tf_models module\n",
    "model_mlp4= mlp4(input_shape=(100, 48) , n_classes=1, output_activation=None, verbose=True)\n",
    "# Compile the model and fit it using training data\n",
    "model_mlp4.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "model_mlp4.fit(train_dataset, epochs=100)\n",
    "# Evaluate the model on the validation set\n",
    "eval_mlp4 = model_mlp4.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# update the result\n",
    "results.update({'mlp4': eval_mlp4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from afqinsight.nn.tf_models import cnn_vgg, lstm1v0, lstm1, lstm2, blstm1, blstm2, lstm_fcn, cnn_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#``cnn_vgg`` from the tf_models module\n",
    "model_cnn_vgg= cnn_vgg(input_shape=(100, 48) , n_classes=1, output_activation=None, verbose=True)\n",
    "# Compile the model and fit it using training data\n",
    "model_cnn_vgg.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "model_cnn_vgg.fit(train_dataset, epochs=100)\n",
    "# Evaluate the model on the validation set\n",
    "eval_cnn_vgg = model_cnn_vgg.evaluate(val_dataset)\n",
    "# update the result\n",
    "results.update({'cnn_vgg': eval_cnn_vgg})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM(100) has changed to n_units=512; the change should impact following models: lstm1v0, lstm1, lstm2, blstm1, blstm2, lstm_fcn;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#``lstm1v0`` from the tf_models module\n",
    "model_lstm1v0= lstm1v0(input_shape=(100, 48) , n_classes=1, output_activation=None, verbose=True)\n",
    "# Compile themodel and fit it using training data\n",
    "model_lstm1v0.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "model_lstm1v0.fit(train_dataset, epochs=100)\n",
    "# Evaluate the model on the validation set\n",
    "eval_lstm1v0 = model_lstm1v0.evaluate(val_dataset)\n",
    "# update the result\n",
    "results.update({'lstm1v0': eval_lstm1v0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#``lstm1`` from the tf_models module\n",
    "model_lstm1= lstm1(input_shape=(100, 48) , n_classes=1, output_activation=None, verbose=True)\n",
    "# Compile the model and fit it using training data\n",
    "model_lstm1.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "model_lstm1.fit(train_dataset, epochs=100, validation_data=val_dataset)\n",
    "# Evaluate the model on the validation set\n",
    "eval_lstm1 = model_lstm1.evaluate(val_dataset)\n",
    "# update the result\n",
    "results.update({'lstm1': eval_lstm1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#``lstm2`` from the tf_models module\n",
    "model_lstm2= lstm2(input_shape=(100, 48) , n_classes=1, output_activation=None, verbose=True)\n",
    "# Compile the model and fit it using training data\n",
    "model_lstm2.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "model_lstm2.fit(train_dataset, epochs=100)\n",
    "# Evaluate the model on the validation set\n",
    "eval_lstm2 = model_lstm2.evaluate(val_dataset)\n",
    "# update the result\n",
    "results.update({'lstm2': eval_lstm2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#``blstm1`` from the tf_models module\n",
    "model_blstm1= blstm1(input_shape=(100, 48) , n_classes=1, output_activation=None, verbose=True)\n",
    "# Compile the model and fit it using training data\n",
    "model_blstm1.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "model_blstm1.fit(train_dataset, epochs=100)\n",
    "# Evaluate the model on the validation set\n",
    "eval_blstm1 = model_blstm1.evaluate(val_dataset)\n",
    "# update the result\n",
    "results.update({'blstm1': eval_blstm1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#``blstm2`` from the tf_models module\n",
    "model_blstm2= blstm2(input_shape=(100, 48) , n_classes=1, output_activation=None, verbose=True)\n",
    "# Compile the model and fit it using training data\n",
    "model_blstm2.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "model_blstm2.fit(train_dataset, epochs=100)\n",
    "# Evaluate the model on the validation set\n",
    "eval_blstm2 = model_blstm2.evaluate(val_dataset)\n",
    "# update the result\n",
    "results.update({'blstm2': eval_blstm2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#``lstm_fcn`` from the tf_models module\n",
    "model_lstm_fcn= lstm_fcn(input_shape=(100, 48) , n_classes=1, output_activation=None, verbose=True)\n",
    "# Compile the model and fit it using training data\n",
    "model_lstm_fcn.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "model_lstm_fcn.fit(train_dataset, epochs=100)\n",
    "# Evaluate the model on the validation set\n",
    "eval_lstm_fcn = model_lstm_fcn.evaluate(val_dataset)\n",
    "# update the result\n",
    "results.update({'lstm_fcn': eval_lstm_fcn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#``cnn_resnet`` from the tf_models module\n",
    "model_cnn_resnet= cnn_resnet(input_shape=(100, 48) , n_classes=1, output_activation=None, verbose=True)\n",
    "# Compile the model and fit it using training data\n",
    "model_cnn_resnet.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "model_cnn_resnet.fit(train_dataset, epochs=100)\n",
    "# Evaluate the model on the validation set\n",
    "eval_cnn_resnet = model_cnn_resnet.evaluate(val_dataset)\n",
    "# update the result\n",
    "results.update({'cnn_resnet': eval_cnn_resnet})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cnn_lenet': [4.318637371063232, 4.318637371063232],\n",
       " 'mlp4': [10.768474578857422, 10.768474578857422],\n",
       " 'cnn_vgg': [1.699886679649353, 1.699886679649353],\n",
       " 'lstm1v0': [13.068290710449219, 13.068290710449219],\n",
       " 'lstm1': [11.704986572265625, 11.704986572265625],\n",
       " 'lstm2': [11.669118881225586, 11.669118881225586],\n",
       " 'blstm1': [11.930325508117676, 11.930325508117676],\n",
       " 'blstm2': [12.850606918334961, 12.850606918334961],\n",
       " 'lstm_fcn': [7.87362813949585, 7.873629093170166],\n",
       " 'cnn_resnet': [3.3275482654571533, 3.3275482654571533]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to conditions where n_units = 100, lstm_fcn became over-expressive when n_units = 512 and error increases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
