{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f8734f6",
   "metadata": {
    "gather": {
     "logged": 1652212959976
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import afqinsight.nn.tf_models as nn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from afqinsight.datasets import AFQDataset\n",
    "from afqinsight.nn.tf_models import cnn_lenet, mlp4, cnn_vgg, lstm1v0, lstm1, lstm2, blstm1, blstm2, lstm_fcn, cnn_resnet\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os.path\n",
    "# Harmonization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from neurocombat_sklearn import CombatModel\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle, resample\n",
    "from afqinsight.augmentation import jitter, time_warp, scaling\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0eccb79",
   "metadata": {
    "gather": {
     "logged": 1652212986960
    }
   },
   "outputs": [],
   "source": [
    "afq_dataset = AFQDataset.from_files(\n",
    "    fn_nodes=\"./data/combined_tract_profiles.csv\",\n",
    "    fn_subjects=\"./data/participants_updated_id.csv\",\n",
    "    dwi_metrics=[\"dki_fa\", \"dki_md\", \"dki_mk\"],\n",
    "    index_col=\"subject_id\",\n",
    "    target_cols=[\"age\", \"dl_qc_score\", \"scan_site_id\"],\n",
    "    label_encode_cols=[\"scan_site_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fc97db2",
   "metadata": {
    "gather": {
     "logged": 1652212987198
    }
   },
   "outputs": [],
   "source": [
    "afq_dataset.drop_target_na()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d47ebb60",
   "metadata": {
    "gather": {
     "logged": 1652212987403
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1865\n",
      "(1865, 2400)\n",
      "(1865, 3)\n"
     ]
    }
   ],
   "source": [
    "print(len(afq_dataset.subjects))\n",
    "print(afq_dataset.X.shape)\n",
    "print(afq_dataset.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c366051",
   "metadata": {
    "gather": {
     "logged": 1652212988137
    }
   },
   "outputs": [],
   "source": [
    "full_dataset = list(afq_dataset.as_tensorflow_dataset().as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d75581",
   "metadata": {
    "gather": {
     "logged": 1652212988321
    }
   },
   "outputs": [],
   "source": [
    "X = np.concatenate([xx[0][None] for xx in full_dataset], 0)\n",
    "y = np.array([yy[1][0] for yy in full_dataset])\n",
    "qc = np.array([yy[1][1] for yy in full_dataset])\n",
    "site = np.array([yy[1][2] for yy in full_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "623180c2",
   "metadata": {
    "gather": {
     "logged": 1652212988490
    }
   },
   "outputs": [],
   "source": [
    "X = X[qc>0]\n",
    "y = y[qc>0]\n",
    "site = site[qc>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86789a05-6d17-4c98-8604-b515c9c8a1dc",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1652212988730
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1817, 100, 24)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "356c33a0",
   "metadata": {
    "gather": {
     "logged": 1652212988908
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "# EarlyStopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.001,\n",
    "    mode=\"min\",\n",
    "    patience=100\n",
    ")\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e11c5b77",
   "metadata": {
    "gather": {
     "logged": 1652212989076
    }
   },
   "outputs": [],
   "source": [
    "def augment_this(X, y, rounds=2): \n",
    "    new_X = X[:]\n",
    "    new_y = y[:]\n",
    "    for f in range(rounds): \n",
    "        aug_X = np.zeros_like(X)\n",
    "        # Do each channel separately:\n",
    "        for channel in range(aug_X.shape[-1]):\n",
    "            this_X = X[..., channel][..., np.newaxis]\n",
    "            this_X = jitter(this_X, sigma=np.mean(this_X)/25)\n",
    "            this_X = scaling(this_X, sigma=np.mean(this_X)/25)\n",
    "            this_X = time_warp(this_X, sigma=np.mean(this_X)/25)\n",
    "            aug_X[..., channel] = this_X[...,0]\n",
    "        new_X = np.concatenate([new_X, aug_X])\n",
    "        new_y = np.concatenate([new_y, y])\n",
    "    return new_X, new_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ea47010",
   "metadata": {
    "gather": {
     "logged": 1652212989278
    }
   },
   "outputs": [],
   "source": [
    "# Generate evaluation results and correlation coeffcients combined in a dataframe, and history\n",
    "def single_cross_site(model_name, name_str, lr,\n",
    "                      site_1, site_2, site_3, X, y):\n",
    "    # Split the data by sites\n",
    "    X_1 = X[site==site_1]\n",
    "    y_1 = y[site==site_1]\n",
    "    X_2 = X[site==site_2]\n",
    "    y_2 = y[site==site_2]\n",
    "    X_3 = X[site==site_3]\n",
    "    y_3 = y[site==site_3]\n",
    "    # Split the data into train and test sets:\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(X_1, y_1, test_size=0.2)\n",
    "    X_train2, X_test2, y_train2, y_test2 = train_test_split(X_2, y_2, test_size=0.2)\n",
    "    X_train3, X_test3, y_train3, y_test3 = train_test_split(X_3, y_3, test_size=0.2)\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    # Impute train and test separately:\n",
    "    X_train = np.concatenate([imputer.fit_transform(X_train[..., ii])[:, :, None] for ii in range(X_train.shape[-1])], -1)\n",
    "    X_test1 = np.concatenate([imputer.fit_transform(X_test1[..., ii])[:, :, None] for ii in range(X_test1.shape[-1])], -1)\n",
    "    X_test2 = np.concatenate([imputer.fit_transform(X_test2[..., ii])[:, :, None] for ii in range(X_test2.shape[-1])], -1)\n",
    "    X_test3 = np.concatenate([imputer.fit_transform(X_test3[..., ii])[:, :, None] for ii in range(X_test3.shape[-1])], -1)\n",
    "    \n",
    "    # Always the test set:\n",
    "    X_test1, y_test1\n",
    "\n",
    "    # Augment\n",
    "    X_train, y_train = augment_this(X_train, y_train, rounds=6)\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    \n",
    "    model = model_name(input_shape=(100, X_train.shape[-1]), n_classes=1, output_activation=None, verbose=True)\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  metrics=['mean_squared_error', \n",
    "                           tf.keras.metrics.RootMeanSquaredError(name='rmse'), \n",
    "                           'mean_absolute_error'])\n",
    "    # ModelCheckpoint\n",
    "    ckpt_filepath = tempfile.NamedTemporaryFile().name + '.h5'\n",
    "    ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = ckpt_filepath,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"auto\",\n",
    "    )\n",
    "    # CSVLogger\n",
    "    log = tf.keras.callbacks.CSVLogger(filename=(name_str + '.csv'), append=True)\n",
    "    callbacks = [early_stopping, ckpt, reduce_lr, log]\n",
    "    history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=128, validation_split=0.2,\n",
    "                        callbacks=callbacks)\n",
    "    model.load_weights(ckpt_filepath)\n",
    "    y_predicted1 = model.predict(X_test1)\n",
    "    y_predicted1 = y_predicted1.reshape(y_test1.shape)\n",
    "    y_predicted2 = model.predict(X_test2)\n",
    "    y_predicted2 = y_predicted2.reshape(y_test2.shape)\n",
    "    y_predicted3 = model.predict(X_test3)\n",
    "    y_predicted3 = y_predicted3.reshape(y_test3.shape)\n",
    "    coef1 = np.corrcoef(y_test1, y_predicted1)[0,1] ** 2\n",
    "    coef2 = np.corrcoef(y_test2, y_predicted2)[0,1] ** 2\n",
    "    coef3 = np.corrcoef(y_test3, y_predicted3)[0,1] ** 2\n",
    "    eval_1 = model.evaluate(X_test1, y_test1)\n",
    "    eval_2 = model.evaluate(X_test2, y_test2)\n",
    "    eval_3 = model.evaluate(X_test3, y_test3)\n",
    "    result = {'Model': [name_str]*12,\n",
    "              'Train_site': [site_1]*12,\n",
    "              'Test_site': [site_1] * 4 + [site_2] * 4 + [site_3] * 4,\n",
    "              'Metric': ['MSE', 'RMSE', 'MAE', 'coef'] * 3,\n",
    "              'Value': [eval_1[1], eval_1[2], eval_1[3], coef1,\n",
    "                        eval_2[1], eval_2[2], eval_2[3], coef2,\n",
    "                        eval_3[1], eval_3[2], eval_3[3], coef3]}\n",
    "    df = pd.DataFrame(result)\n",
    "    return df, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "352138f2",
   "metadata": {
    "gather": {
     "logged": 1652212989474
    }
   },
   "outputs": [],
   "source": [
    "# Generate evaluation results and correlation coeffcients combined in a dataframe, and history\n",
    "def double_cross_site(model_name, name_str, lr,\n",
    "                      site_1, site_2, site_3, X, y):\n",
    "    # Split the data by sites\n",
    "    X_1 = X[site==site_1]\n",
    "    y_1 = y[site==site_1]\n",
    "    X_2 = X[site==site_2]\n",
    "    y_2 = y[site==site_2]\n",
    "    X_3 = X[site==site_3]\n",
    "    y_3 = y[site==site_3]\n",
    "    # Split the data into train and test sets:\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(X_1, y_1, test_size=0.2)\n",
    "    X_train2, X_test2, y_train2, y_test2 = train_test_split(X_2, y_2, test_size=0.2)\n",
    "    X_train3, X_test3, y_train3, y_test3 = train_test_split(X_3, y_3, test_size=0.2)\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    # Impute train and test separately:\n",
    "    X_train1 = np.concatenate([imputer.fit_transform(X_train1[..., ii])[:, :, None] for ii in range(X_train1.shape[-1])], -1)\n",
    "    X_train2 = np.concatenate([imputer.fit_transform(X_train2[..., ii])[:, :, None] for ii in range(X_train2.shape[-1])], -1)\n",
    "    X_test1 = np.concatenate([imputer.fit_transform(X_test1[..., ii])[:, :, None] for ii in range(X_test1.shape[-1])], -1)\n",
    "    X_test2 = np.concatenate([imputer.fit_transform(X_test2[..., ii])[:, :, None] for ii in range(X_test2.shape[-1])], -1)\n",
    "    X_test3 = np.concatenate([imputer.fit_transform(X_test3[..., ii])[:, :, None] for ii in range(X_test3.shape[-1])], -1)\n",
    "    # size down evenly\n",
    "    sample = 202\n",
    "    sample1 = resample(X_train1, y_train1, n_samples=sample, replace=False)\n",
    "    sample2 = resample(X_train2, y_train2, n_samples=sample, replace=False)\n",
    "    X_train = np.concatenate((sample1[0], sample2[0]), axis=0)\n",
    "    y_train = np.concatenate((sample1[1], sample2[1]), axis=0)\n",
    "    # shuffle\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    # Augment\n",
    "    X_train, y_train = augment_this(X_train, y_train, rounds=6)\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    model = model_name(input_shape=(100, X_train.shape[-1]), n_classes=1, output_activation=None, verbose=True)\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  metrics=['mean_squared_error', \n",
    "                           tf.keras.metrics.RootMeanSquaredError(name='rmse'), \n",
    "                           'mean_absolute_error'])\n",
    "    # ModelCheckpoint\n",
    "    ckpt_filepath = tempfile.NamedTemporaryFile().name + '.h5'\n",
    "    ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = ckpt_filepath,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"auto\",\n",
    "    )\n",
    "    # CSVLogger\n",
    "    log = tf.keras.callbacks.CSVLogger(filename=(name_str + '.csv'), append=True)\n",
    "    callbacks = [early_stopping, ckpt, reduce_lr, log]\n",
    "    history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=128, validation_split=0.2,\n",
    "                        callbacks=callbacks)\n",
    "    model.load_weights(ckpt_filepath)\n",
    "    \n",
    "    y_predicted1 = model.predict(X_test1)\n",
    "    y_predicted1 = y_predicted1.reshape(y_test1.shape)\n",
    "    y_predicted2 = model.predict(X_test2)\n",
    "    y_predicted2 = y_predicted2.reshape(y_test2.shape)\n",
    "    y_predicted3 = model.predict(X_test3)\n",
    "    y_predicted3 = y_predicted3.reshape(y_test3.shape)\n",
    "    coef1 = np.corrcoef(y_test1, y_predicted1)[0,1] ** 2\n",
    "    coef2 = np.corrcoef(y_test2, y_predicted2)[0,1] ** 2\n",
    "    coef3 = np.corrcoef(y_test3, y_predicted3)[0,1] ** 2\n",
    "    eval_1 = model.evaluate(X_test1, y_test1)\n",
    "    eval_2 = model.evaluate(X_test2, y_test2)\n",
    "    eval_3 = model.evaluate(X_test3, y_test3)\n",
    "    result = {'Model': [name_str]*12,\n",
    "              'Train_site': [f'{site_1}, {site_2}'] * 12,\n",
    "              'Test_site': [site_1] * 4 + [site_2] * 4 + [site_3] * 4,\n",
    "              'Metric': ['MSE', 'RMSE', 'MAE', 'coef'] * 3,\n",
    "              'Value': [eval_1[1], eval_1[2], eval_1[3], coef1,\n",
    "                        eval_2[1], eval_2[2], eval_2[3], coef2,\n",
    "                        eval_3[1], eval_3[2], eval_3[3], coef3]}\n",
    "    df = pd.DataFrame(result)\n",
    "    return df, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb238f4",
   "metadata": {},
   "source": [
    "### cnn_resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0cb65",
   "metadata": {},
   "source": [
    "#### single-cross-site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "464cd5bb",
   "metadata": {
    "gather": {
     "logged": 1652120673260
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100, 24)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 100, 64)      12352       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 100, 64)     256         ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 100, 64)      0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 100, 64)      20544       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 100, 64)     256         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 100, 64)      0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 100, 64)      12352       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 100, 64)      1600        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 100, 64)     256         ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 100, 64)     256         ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 100, 64)      0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 100, 64)      0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 100, 64)      0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 100, 128)     65664       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 100, 128)    512         ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 100, 128)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 100, 128)     82048       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 100, 128)    512         ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 100, 128)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 100, 128)     49280       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 100, 128)     8320        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 100, 128)    512         ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 100, 128)    512         ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 100, 128)     0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 100, 128)     0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 100, 128)     0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 100, 128)     131200      ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 100, 128)    512         ['conv1d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 100, 128)     0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 100, 128)     82048       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 100, 128)    512         ['conv1d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 100, 128)     0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 100, 128)     49280       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 100, 128)    512         ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 100, 128)    512         ['activation_7[0][0]']           \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 100, 128)     0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 100, 128)     0           ['batch_normalization_11[0][0]', \n",
      "                                                                  'activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 100, 128)     0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['activation_11[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            129         ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 519,937\n",
      "Trainable params: 517,377\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "27/27 [==============================] - ETA: 0s - loss: 16.3593 - mean_squared_error: 16.3593 - rmse: 4.0447 - mean_absolute_error: 2.910\n",
      "Epoch 1: val_loss improved from inf to 13933660.00000, saving model to /tmp/tmpc7nyb65v.h5\n",
      "27/27 [==============================] - 12s 237ms/step - loss: 16.3593 - mean_squared_error: 16.3593 - rmse: 4.0447 - mean_absolute_error: 2.9107 - val_loss: 13933660.0000 - val_mean_squared_error: 13933660.0000 - val_rmse: 3732.7820 - val_mean_absolute_error: 3722.0095 - lr: 0.0100\n",
      "Epoch 2/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 4.5157 - mean_squared_error: 4.5157 - rmse: 2.1250 - mean_absolute_error: 1.667\n",
      "Epoch 2: val_loss improved from 13933660.00000 to 47562.53516, saving model to /tmp/tmpc7nyb65v.h5\n",
      "27/27 [==============================] - 2s 80ms/step - loss: 4.5230 - mean_squared_error: 4.5230 - rmse: 2.1267 - mean_absolute_error: 1.6695 - val_loss: 47562.5352 - val_mean_squared_error: 47562.5352 - val_rmse: 218.0884 - val_mean_absolute_error: 216.5481 - lr: 0.0100\n",
      "Epoch 3/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 3.6397 - mean_squared_error: 3.6397 - rmse: 1.9078 - mean_absolute_error: 1.495\n",
      "Epoch 3: val_loss improved from 47562.53516 to 392.52356, saving model to /tmp/tmpc7nyb65v.h5\n",
      "27/27 [==============================] - 2s 80ms/step - loss: 3.6216 - mean_squared_error: 3.6216 - rmse: 1.9031 - mean_absolute_error: 1.4906 - val_loss: 392.5236 - val_mean_squared_error: 392.5236 - val_rmse: 19.8122 - val_mean_absolute_error: 18.9004 - lr: 0.0100\n",
      "Epoch 4/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 2.7927 - mean_squared_error: 2.7927 - rmse: 1.6711 - mean_absolute_error: 1.317\n",
      "Epoch 4: val_loss improved from 392.52356 to 43.78543, saving model to /tmp/tmpc7nyb65v.h5\n",
      "27/27 [==============================] - 2s 81ms/step - loss: 2.7775 - mean_squared_error: 2.7775 - rmse: 1.6666 - mean_absolute_error: 1.3137 - val_loss: 43.7854 - val_mean_squared_error: 43.7854 - val_rmse: 6.6171 - val_mean_absolute_error: 5.7262 - lr: 0.0100\n",
      "Epoch 5/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 2.2661 - mean_squared_error: 2.2661 - rmse: 1.5054 - mean_absolute_error: 1.181\n",
      "Epoch 5: val_loss improved from 43.78543 to 19.33966, saving model to /tmp/tmpc7nyb65v.h5\n",
      "27/27 [==============================] - 2s 80ms/step - loss: 2.2707 - mean_squared_error: 2.2707 - rmse: 1.5069 - mean_absolute_error: 1.1826 - val_loss: 19.3397 - val_mean_squared_error: 19.3397 - val_rmse: 4.3977 - val_mean_absolute_error: 3.6737 - lr: 0.0100\n",
      "Epoch 6/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 1.8977 - mean_squared_error: 1.8977 - rmse: 1.3776 - mean_absolute_error: 1.083\n",
      "Epoch 6: val_loss did not improve from 19.33966\n",
      "27/27 [==============================] - 2s 77ms/step - loss: 1.8946 - mean_squared_error: 1.8946 - rmse: 1.3765 - mean_absolute_error: 1.0826 - val_loss: 53.2842 - val_mean_squared_error: 53.2842 - val_rmse: 7.2996 - val_mean_absolute_error: 6.1256 - lr: 0.0100\n",
      "Epoch 7/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 1.6160 - mean_squared_error: 1.6160 - rmse: 1.2712 - mean_absolute_error: 1.001\n",
      "Epoch 7: val_loss did not improve from 19.33966\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 1.6173 - mean_squared_error: 1.6173 - rmse: 1.2717 - mean_absolute_error: 1.0016 - val_loss: 105.5625 - val_mean_squared_error: 105.5625 - val_rmse: 10.2744 - val_mean_absolute_error: 9.5593 - lr: 0.0100\n",
      "Epoch 8/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 1.2652 - mean_squared_error: 1.2652 - rmse: 1.1248 - mean_absolute_error: 0.883\n",
      "Epoch 8: val_loss improved from 19.33966 to 13.12732, saving model to /tmp/tmpc7nyb65v.h5\n",
      "27/27 [==============================] - 2s 80ms/step - loss: 1.2667 - mean_squared_error: 1.2667 - rmse: 1.1255 - mean_absolute_error: 0.8848 - val_loss: 13.1273 - val_mean_squared_error: 13.1273 - val_rmse: 3.6232 - val_mean_absolute_error: 3.0809 - lr: 0.0100\n",
      "Epoch 9/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 1.3105 - mean_squared_error: 1.3105 - rmse: 1.1448 - mean_absolute_error: 0.891\n",
      "Epoch 9: val_loss did not improve from 13.12732\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 1.3002 - mean_squared_error: 1.3002 - rmse: 1.1403 - mean_absolute_error: 0.8882 - val_loss: 15.1255 - val_mean_squared_error: 15.1255 - val_rmse: 3.8892 - val_mean_absolute_error: 3.2530 - lr: 0.0100\n",
      "Epoch 10/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 1.0096 - mean_squared_error: 1.0096 - rmse: 1.0048 - mean_absolute_error: 0.792\n",
      "Epoch 10: val_loss improved from 13.12732 to 11.30126, saving model to /tmp/tmpc7nyb65v.h5\n",
      "27/27 [==============================] - 2s 81ms/step - loss: 1.0110 - mean_squared_error: 1.0110 - rmse: 1.0055 - mean_absolute_error: 0.7922 - val_loss: 11.3013 - val_mean_squared_error: 11.3013 - val_rmse: 3.3617 - val_mean_absolute_error: 2.8938 - lr: 0.0100\n",
      "Epoch 11/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.9749 - mean_squared_error: 0.9749 - rmse: 0.9874 - mean_absolute_error: 0.768\n",
      "Epoch 11: val_loss did not improve from 11.30126\n",
      "27/27 [==============================] - 2s 77ms/step - loss: 0.9859 - mean_squared_error: 0.9859 - rmse: 0.9929 - mean_absolute_error: 0.7734 - val_loss: 12.5886 - val_mean_squared_error: 12.5886 - val_rmse: 3.5480 - val_mean_absolute_error: 2.9668 - lr: 0.0100\n",
      "Epoch 12/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.8888 - mean_squared_error: 0.8888 - rmse: 0.9428 - mean_absolute_error: 0.739\n",
      "Epoch 12: val_loss did not improve from 11.30126\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.9008 - mean_squared_error: 0.9008 - rmse: 0.9491 - mean_absolute_error: 0.7446 - val_loss: 25.3715 - val_mean_squared_error: 25.3715 - val_rmse: 5.0370 - val_mean_absolute_error: 4.4629 - lr: 0.0100\n",
      "Epoch 13/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.8244 - mean_squared_error: 0.8244 - rmse: 0.9080 - mean_absolute_error: 0.716\n",
      "Epoch 13: val_loss improved from 11.30126 to 5.48582, saving model to /tmp/tmpc7nyb65v.h5\n",
      "27/27 [==============================] - 2s 81ms/step - loss: 0.8214 - mean_squared_error: 0.8214 - rmse: 0.9063 - mean_absolute_error: 0.7153 - val_loss: 5.4858 - val_mean_squared_error: 5.4858 - val_rmse: 2.3422 - val_mean_absolute_error: 1.8046 - lr: 0.0100\n",
      "Epoch 14/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.6480 - mean_squared_error: 0.6480 - rmse: 0.8050 - mean_absolute_error: 0.639\n",
      "Epoch 14: val_loss did not improve from 5.48582\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.6624 - mean_squared_error: 0.6624 - rmse: 0.8139 - mean_absolute_error: 0.6458 - val_loss: 7.6633 - val_mean_squared_error: 7.6633 - val_rmse: 2.7683 - val_mean_absolute_error: 2.2681 - lr: 0.0100\n",
      "Epoch 15/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.6815 - mean_squared_error: 0.6815 - rmse: 0.8255 - mean_absolute_error: 0.650\n",
      "Epoch 15: val_loss did not improve from 5.48582\n",
      "27/27 [==============================] - 2s 77ms/step - loss: 0.6824 - mean_squared_error: 0.6824 - rmse: 0.8261 - mean_absolute_error: 0.6506 - val_loss: 5.9697 - val_mean_squared_error: 5.9697 - val_rmse: 2.4433 - val_mean_absolute_error: 1.9563 - lr: 0.0100\n",
      "Epoch 16/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.7858 - mean_squared_error: 0.7858 - rmse: 0.8864 - mean_absolute_error: 0.700\n",
      "Epoch 16: val_loss did not improve from 5.48582\n",
      "27/27 [==============================] - 2s 77ms/step - loss: 0.7964 - mean_squared_error: 0.7964 - rmse: 0.8924 - mean_absolute_error: 0.7038 - val_loss: 17.2961 - val_mean_squared_error: 17.2961 - val_rmse: 4.1589 - val_mean_absolute_error: 3.6012 - lr: 0.0100\n",
      "Epoch 17/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.7238 - mean_squared_error: 0.7238 - rmse: 0.8507 - mean_absolute_error: 0.672\n",
      "Epoch 17: val_loss did not improve from 5.48582\n",
      "27/27 [==============================] - 2s 79ms/step - loss: 0.7212 - mean_squared_error: 0.7212 - rmse: 0.8492 - mean_absolute_error: 0.6711 - val_loss: 6.4199 - val_mean_squared_error: 6.4199 - val_rmse: 2.5337 - val_mean_absolute_error: 2.1074 - lr: 0.0100\n",
      "Epoch 18/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.6681 - mean_squared_error: 0.6681 - rmse: 0.8174 - mean_absolute_error: 0.641\n",
      "Epoch 18: val_loss did not improve from 5.48582\n",
      "27/27 [==============================] - 2s 77ms/step - loss: 0.6726 - mean_squared_error: 0.6726 - rmse: 0.8201 - mean_absolute_error: 0.6436 - val_loss: 14.8872 - val_mean_squared_error: 14.8872 - val_rmse: 3.8584 - val_mean_absolute_error: 3.3358 - lr: 0.0100\n",
      "Epoch 19/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.5879 - mean_squared_error: 0.5879 - rmse: 0.7668 - mean_absolute_error: 0.592\n",
      "Epoch 19: val_loss improved from 5.48582 to 3.75055, saving model to /tmp/tmpc7nyb65v.h5\n",
      "27/27 [==============================] - 2s 80ms/step - loss: 0.6200 - mean_squared_error: 0.6200 - rmse: 0.7874 - mean_absolute_error: 0.6051 - val_loss: 3.7505 - val_mean_squared_error: 3.7505 - val_rmse: 1.9366 - val_mean_absolute_error: 1.5160 - lr: 0.0100\n",
      "Epoch 20/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.7108 - mean_squared_error: 0.7108 - rmse: 0.8431 - mean_absolute_error: 0.664\n",
      "Epoch 20: val_loss did not improve from 3.75055\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.7088 - mean_squared_error: 0.7088 - rmse: 0.8419 - mean_absolute_error: 0.6631 - val_loss: 5.6481 - val_mean_squared_error: 5.6481 - val_rmse: 2.3766 - val_mean_absolute_error: 1.8522 - lr: 0.0100\n",
      "Epoch 21/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.4358 - mean_squared_error: 0.4358 - rmse: 0.6601 - mean_absolute_error: 0.522\n",
      "Epoch 21: val_loss did not improve from 3.75055\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.4360 - mean_squared_error: 0.4360 - rmse: 0.6603 - mean_absolute_error: 0.5221 - val_loss: 6.0349 - val_mean_squared_error: 6.0349 - val_rmse: 2.4566 - val_mean_absolute_error: 2.0225 - lr: 0.0100\n",
      "Epoch 22/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.4472 - mean_squared_error: 0.4472 - rmse: 0.6687 - mean_absolute_error: 0.525\n",
      "Epoch 22: val_loss improved from 3.75055 to 3.26783, saving model to /tmp/tmpc7nyb65v.h5\n",
      "27/27 [==============================] - 2s 80ms/step - loss: 0.4645 - mean_squared_error: 0.4645 - rmse: 0.6816 - mean_absolute_error: 0.5332 - val_loss: 3.2678 - val_mean_squared_error: 3.2678 - val_rmse: 1.8077 - val_mean_absolute_error: 1.4249 - lr: 0.0100\n",
      "Epoch 23/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.4196 - mean_squared_error: 0.4196 - rmse: 0.6478 - mean_absolute_error: 0.505\n",
      "Epoch 23: val_loss improved from 3.26783 to 2.46616, saving model to /tmp/tmpc7nyb65v.h5\n",
      "27/27 [==============================] - 2s 81ms/step - loss: 0.4220 - mean_squared_error: 0.4220 - rmse: 0.6496 - mean_absolute_error: 0.5066 - val_loss: 2.4662 - val_mean_squared_error: 2.4662 - val_rmse: 1.5704 - val_mean_absolute_error: 1.2213 - lr: 0.0100\n",
      "Epoch 24/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.4204 - mean_squared_error: 0.4204 - rmse: 0.6484 - mean_absolute_error: 0.506\n",
      "Epoch 24: val_loss did not improve from 2.46616\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.4291 - mean_squared_error: 0.4291 - rmse: 0.6551 - mean_absolute_error: 0.5113 - val_loss: 4.7164 - val_mean_squared_error: 4.7164 - val_rmse: 2.1717 - val_mean_absolute_error: 1.6883 - lr: 0.0100\n",
      "Epoch 25/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.5402 - mean_squared_error: 0.5402 - rmse: 0.7350 - mean_absolute_error: 0.582\n",
      "Epoch 25: val_loss did not improve from 2.46616\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.5456 - mean_squared_error: 0.5456 - rmse: 0.7386 - mean_absolute_error: 0.5855 - val_loss: 2.7121 - val_mean_squared_error: 2.7121 - val_rmse: 1.6468 - val_mean_absolute_error: 1.2672 - lr: 0.0100\n",
      "Epoch 26/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.4837 - mean_squared_error: 0.4837 - rmse: 0.6955 - mean_absolute_error: 0.542\n",
      "Epoch 26: val_loss did not improve from 2.46616\n",
      "27/27 [==============================] - 2s 77ms/step - loss: 0.4826 - mean_squared_error: 0.4826 - rmse: 0.6947 - mean_absolute_error: 0.5420 - val_loss: 2.9612 - val_mean_squared_error: 2.9612 - val_rmse: 1.7208 - val_mean_absolute_error: 1.3740 - lr: 0.0100\n",
      "Epoch 27/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.5403 - mean_squared_error: 0.5403 - rmse: 0.7351 - mean_absolute_error: 0.576\n",
      "Epoch 27: val_loss did not improve from 2.46616\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.5448 - mean_squared_error: 0.5448 - rmse: 0.7381 - mean_absolute_error: 0.5797 - val_loss: 3.1104 - val_mean_squared_error: 3.1104 - val_rmse: 1.7636 - val_mean_absolute_error: 1.3542 - lr: 0.0100\n",
      "Epoch 28/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.4195 - mean_squared_error: 0.4195 - rmse: 0.6477 - mean_absolute_error: 0.510\n",
      "Epoch 28: val_loss did not improve from 2.46616\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.4245 - mean_squared_error: 0.4245 - rmse: 0.6516 - mean_absolute_error: 0.5136 - val_loss: 3.3247 - val_mean_squared_error: 3.3247 - val_rmse: 1.8234 - val_mean_absolute_error: 1.4065 - lr: 0.0100\n",
      "Epoch 29/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3858 - mean_squared_error: 0.3858 - rmse: 0.6212 - mean_absolute_error: 0.485\n",
      "Epoch 29: val_loss did not improve from 2.46616\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.3838 - mean_squared_error: 0.3838 - rmse: 0.6195 - mean_absolute_error: 0.4843 - val_loss: 3.0182 - val_mean_squared_error: 3.0182 - val_rmse: 1.7373 - val_mean_absolute_error: 1.4048 - lr: 0.0100\n",
      "Epoch 30/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3470 - mean_squared_error: 0.3470 - rmse: 0.5891 - mean_absolute_error: 0.457\n",
      "Epoch 30: val_loss did not improve from 2.46616\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.3650 - mean_squared_error: 0.3650 - rmse: 0.6041 - mean_absolute_error: 0.4678 - val_loss: 3.3973 - val_mean_squared_error: 3.3973 - val_rmse: 1.8432 - val_mean_absolute_error: 1.3952 - lr: 0.0100\n",
      "Epoch 31/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.4288 - mean_squared_error: 0.4288 - rmse: 0.6549 - mean_absolute_error: 0.515\n",
      "Epoch 31: val_loss improved from 2.46616 to 1.92222, saving model to /tmp/tmpc7nyb65v.h5\n",
      "27/27 [==============================] - 2s 80ms/step - loss: 0.4297 - mean_squared_error: 0.4297 - rmse: 0.6555 - mean_absolute_error: 0.5165 - val_loss: 1.9222 - val_mean_squared_error: 1.9222 - val_rmse: 1.3864 - val_mean_absolute_error: 1.0860 - lr: 0.0100\n",
      "Epoch 32/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3529 - mean_squared_error: 0.3529 - rmse: 0.5941 - mean_absolute_error: 0.471\n",
      "Epoch 32: val_loss did not improve from 1.92222\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.3543 - mean_squared_error: 0.3543 - rmse: 0.5952 - mean_absolute_error: 0.4727 - val_loss: 2.3782 - val_mean_squared_error: 2.3782 - val_rmse: 1.5421 - val_mean_absolute_error: 1.2073 - lr: 0.0100\n",
      "Epoch 33/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3088 - mean_squared_error: 0.3088 - rmse: 0.5557 - mean_absolute_error: 0.440\n",
      "Epoch 33: val_loss did not improve from 1.92222\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.3080 - mean_squared_error: 0.3080 - rmse: 0.5550 - mean_absolute_error: 0.4395 - val_loss: 2.5231 - val_mean_squared_error: 2.5231 - val_rmse: 1.5884 - val_mean_absolute_error: 1.1843 - lr: 0.0100\n",
      "Epoch 34/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3657 - mean_squared_error: 0.3657 - rmse: 0.6048 - mean_absolute_error: 0.480\n",
      "Epoch 34: val_loss did not improve from 1.92222\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.3774 - mean_squared_error: 0.3774 - rmse: 0.6143 - mean_absolute_error: 0.4862 - val_loss: 2.5844 - val_mean_squared_error: 2.5844 - val_rmse: 1.6076 - val_mean_absolute_error: 1.2374 - lr: 0.0100\n",
      "Epoch 35/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2985 - mean_squared_error: 0.2985 - rmse: 0.5463 - mean_absolute_error: 0.422\n",
      "Epoch 35: val_loss improved from 1.92222 to 1.71099, saving model to /tmp/tmpc7nyb65v.h5\n",
      "27/27 [==============================] - 2s 81ms/step - loss: 0.2975 - mean_squared_error: 0.2975 - rmse: 0.5454 - mean_absolute_error: 0.4216 - val_loss: 1.7110 - val_mean_squared_error: 1.7110 - val_rmse: 1.3080 - val_mean_absolute_error: 1.0397 - lr: 0.0100\n",
      "Epoch 36/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.4263 - mean_squared_error: 0.4263 - rmse: 0.6529 - mean_absolute_error: 0.507\n",
      "Epoch 36: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.4266 - mean_squared_error: 0.4266 - rmse: 0.6531 - mean_absolute_error: 0.5087 - val_loss: 3.4468 - val_mean_squared_error: 3.4468 - val_rmse: 1.8566 - val_mean_absolute_error: 1.4121 - lr: 0.0100\n",
      "Epoch 37/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.4692 - mean_squared_error: 0.4692 - rmse: 0.6850 - mean_absolute_error: 0.538\n",
      "Epoch 37: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.4664 - mean_squared_error: 0.4664 - rmse: 0.6829 - mean_absolute_error: 0.5372 - val_loss: 6.6150 - val_mean_squared_error: 6.6150 - val_rmse: 2.5720 - val_mean_absolute_error: 1.9796 - lr: 0.0100\n",
      "Epoch 38/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.4252 - mean_squared_error: 0.4252 - rmse: 0.6521 - mean_absolute_error: 0.506\n",
      "Epoch 38: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.4228 - mean_squared_error: 0.4228 - rmse: 0.6502 - mean_absolute_error: 0.5052 - val_loss: 5.2870 - val_mean_squared_error: 5.2870 - val_rmse: 2.2994 - val_mean_absolute_error: 1.6745 - lr: 0.0100\n",
      "Epoch 39/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2756 - mean_squared_error: 0.2756 - rmse: 0.5250 - mean_absolute_error: 0.418\n",
      "Epoch 39: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.2771 - mean_squared_error: 0.2771 - rmse: 0.5264 - mean_absolute_error: 0.4202 - val_loss: 2.4688 - val_mean_squared_error: 2.4688 - val_rmse: 1.5713 - val_mean_absolute_error: 1.1844 - lr: 0.0100\n",
      "Epoch 40/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.4257 - mean_squared_error: 0.4257 - rmse: 0.6525 - mean_absolute_error: 0.491\n",
      "Epoch 40: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 79ms/step - loss: 0.4462 - mean_squared_error: 0.4462 - rmse: 0.6680 - mean_absolute_error: 0.5027 - val_loss: 4.3841 - val_mean_squared_error: 4.3841 - val_rmse: 2.0938 - val_mean_absolute_error: 1.5555 - lr: 0.0100\n",
      "Epoch 41/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3961 - mean_squared_error: 0.3961 - rmse: 0.6293 - mean_absolute_error: 0.489\n",
      "Epoch 41: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.3982 - mean_squared_error: 0.3982 - rmse: 0.6310 - mean_absolute_error: 0.4920 - val_loss: 3.1671 - val_mean_squared_error: 3.1671 - val_rmse: 1.7796 - val_mean_absolute_error: 1.4004 - lr: 0.0100\n",
      "Epoch 42/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.4712 - mean_squared_error: 0.4712 - rmse: 0.6864 - mean_absolute_error: 0.532\n",
      "Epoch 42: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.4724 - mean_squared_error: 0.4724 - rmse: 0.6873 - mean_absolute_error: 0.5343 - val_loss: 2.1526 - val_mean_squared_error: 2.1526 - val_rmse: 1.4672 - val_mean_absolute_error: 1.1476 - lr: 0.0100\n",
      "Epoch 43/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3451 - mean_squared_error: 0.3451 - rmse: 0.5874 - mean_absolute_error: 0.454\n",
      "Epoch 43: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.3524 - mean_squared_error: 0.3524 - rmse: 0.5936 - mean_absolute_error: 0.4591 - val_loss: 2.4605 - val_mean_squared_error: 2.4605 - val_rmse: 1.5686 - val_mean_absolute_error: 1.1966 - lr: 0.0100\n",
      "Epoch 44/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3085 - mean_squared_error: 0.3085 - rmse: 0.5554 - mean_absolute_error: 0.435\n",
      "Epoch 44: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.3079 - mean_squared_error: 0.3079 - rmse: 0.5549 - mean_absolute_error: 0.4346 - val_loss: 7.7873 - val_mean_squared_error: 7.7873 - val_rmse: 2.7906 - val_mean_absolute_error: 2.1796 - lr: 0.0100\n",
      "Epoch 45/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3129 - mean_squared_error: 0.3129 - rmse: 0.5594 - mean_absolute_error: 0.438\n",
      "Epoch 45: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.3168 - mean_squared_error: 0.3168 - rmse: 0.5629 - mean_absolute_error: 0.4418 - val_loss: 7.3446 - val_mean_squared_error: 7.3446 - val_rmse: 2.7101 - val_mean_absolute_error: 2.1946 - lr: 0.0100\n",
      "Epoch 46/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.4006 - mean_squared_error: 0.4006 - rmse: 0.6329 - mean_absolute_error: 0.493\n",
      "Epoch 46: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 77ms/step - loss: 0.4007 - mean_squared_error: 0.4007 - rmse: 0.6330 - mean_absolute_error: 0.4937 - val_loss: 2.2799 - val_mean_squared_error: 2.2799 - val_rmse: 1.5099 - val_mean_absolute_error: 1.1887 - lr: 0.0100\n",
      "Epoch 47/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3122 - mean_squared_error: 0.3122 - rmse: 0.5588 - mean_absolute_error: 0.439\n",
      "Epoch 47: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 79ms/step - loss: 0.3319 - mean_squared_error: 0.3319 - rmse: 0.5761 - mean_absolute_error: 0.4497 - val_loss: 2.2016 - val_mean_squared_error: 2.2016 - val_rmse: 1.4838 - val_mean_absolute_error: 1.1653 - lr: 0.0100\n",
      "Epoch 48/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.5453 - mean_squared_error: 0.5453 - rmse: 0.7385 - mean_absolute_error: 0.577\n",
      "Epoch 48: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 77ms/step - loss: 0.5527 - mean_squared_error: 0.5527 - rmse: 0.7435 - mean_absolute_error: 0.5807 - val_loss: 6.1001 - val_mean_squared_error: 6.1001 - val_rmse: 2.4698 - val_mean_absolute_error: 1.9208 - lr: 0.0100\n",
      "Epoch 49/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3950 - mean_squared_error: 0.3950 - rmse: 0.6285 - mean_absolute_error: 0.495\n",
      "Epoch 49: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 79ms/step - loss: 0.4011 - mean_squared_error: 0.4011 - rmse: 0.6333 - mean_absolute_error: 0.4987 - val_loss: 2.8985 - val_mean_squared_error: 2.8985 - val_rmse: 1.7025 - val_mean_absolute_error: 1.3944 - lr: 0.0100\n",
      "Epoch 50/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3666 - mean_squared_error: 0.3666 - rmse: 0.6055 - mean_absolute_error: 0.467\n",
      "Epoch 50: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.3662 - mean_squared_error: 0.3662 - rmse: 0.6052 - mean_absolute_error: 0.4677 - val_loss: 2.4204 - val_mean_squared_error: 2.4204 - val_rmse: 1.5558 - val_mean_absolute_error: 1.2074 - lr: 0.0100\n",
      "Epoch 51/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2807 - mean_squared_error: 0.2807 - rmse: 0.5298 - mean_absolute_error: 0.410\n",
      "Epoch 51: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 79ms/step - loss: 0.2963 - mean_squared_error: 0.2963 - rmse: 0.5443 - mean_absolute_error: 0.4198 - val_loss: 3.0525 - val_mean_squared_error: 3.0525 - val_rmse: 1.7471 - val_mean_absolute_error: 1.3206 - lr: 0.0100\n",
      "Epoch 52/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3134 - mean_squared_error: 0.3134 - rmse: 0.5598 - mean_absolute_error: 0.428\n",
      "Epoch 52: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.3117 - mean_squared_error: 0.3117 - rmse: 0.5583 - mean_absolute_error: 0.4270 - val_loss: 2.2908 - val_mean_squared_error: 2.2908 - val_rmse: 1.5135 - val_mean_absolute_error: 1.2020 - lr: 0.0100\n",
      "Epoch 53/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2655 - mean_squared_error: 0.2655 - rmse: 0.5153 - mean_absolute_error: 0.404\n",
      "Epoch 53: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.2863 - mean_squared_error: 0.2863 - rmse: 0.5351 - mean_absolute_error: 0.4161 - val_loss: 2.6921 - val_mean_squared_error: 2.6921 - val_rmse: 1.6408 - val_mean_absolute_error: 1.2114 - lr: 0.0100\n",
      "Epoch 54/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.4415 - mean_squared_error: 0.4415 - rmse: 0.6645 - mean_absolute_error: 0.526\n",
      "Epoch 54: val_loss did not improve from 1.71099\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.4371 - mean_squared_error: 0.4371 - rmse: 0.6612 - mean_absolute_error: 0.5235 - val_loss: 1.7241 - val_mean_squared_error: 1.7241 - val_rmse: 1.3131 - val_mean_absolute_error: 1.0121 - lr: 0.0100\n",
      "Epoch 55/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2705 - mean_squared_error: 0.2705 - rmse: 0.5201 - mean_absolute_error: 0.398\n",
      "Epoch 55: val_loss did not improve from 1.71099\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.2722 - mean_squared_error: 0.2722 - rmse: 0.5218 - mean_absolute_error: 0.4001 - val_loss: 4.4724 - val_mean_squared_error: 4.4724 - val_rmse: 2.1148 - val_mean_absolute_error: 1.7919 - lr: 0.0100\n",
      "Epoch 56/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1764 - mean_squared_error: 0.1764 - rmse: 0.4200 - mean_absolute_error: 0.329\n",
      "Epoch 56: val_loss improved from 1.71099 to 0.96782, saving model to /tmp/tmpc7nyb65v.h5\n",
      "27/27 [==============================] - 2s 81ms/step - loss: 0.1756 - mean_squared_error: 0.1756 - rmse: 0.4190 - mean_absolute_error: 0.3286 - val_loss: 0.9678 - val_mean_squared_error: 0.9678 - val_rmse: 0.9838 - val_mean_absolute_error: 0.7599 - lr: 0.0050\n",
      "Epoch 57/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1232 - mean_squared_error: 0.1232 - rmse: 0.3509 - mean_absolute_error: 0.270\n",
      "Epoch 57: val_loss did not improve from 0.96782\n",
      "27/27 [==============================] - 2s 79ms/step - loss: 0.1241 - mean_squared_error: 0.1241 - rmse: 0.3522 - mean_absolute_error: 0.2709 - val_loss: 1.0590 - val_mean_squared_error: 1.0590 - val_rmse: 1.0291 - val_mean_absolute_error: 0.7910 - lr: 0.0050\n",
      "Epoch 58/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3108 - mean_squared_error: 0.3108 - rmse: 0.5575 - mean_absolute_error: 0.428\n",
      "Epoch 58: val_loss did not improve from 0.96782\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.3096 - mean_squared_error: 0.3096 - rmse: 0.5565 - mean_absolute_error: 0.4278 - val_loss: 1.1349 - val_mean_squared_error: 1.1349 - val_rmse: 1.0653 - val_mean_absolute_error: 0.8145 - lr: 0.0050\n",
      "Epoch 59/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2736 - mean_squared_error: 0.2736 - rmse: 0.5231 - mean_absolute_error: 0.396\n",
      "Epoch 59: val_loss did not improve from 0.96782\n",
      "27/27 [==============================] - 2s 79ms/step - loss: 0.2766 - mean_squared_error: 0.2766 - rmse: 0.5259 - mean_absolute_error: 0.3990 - val_loss: 2.1279 - val_mean_squared_error: 2.1279 - val_rmse: 1.4587 - val_mean_absolute_error: 1.1279 - lr: 0.0050\n",
      "Epoch 60/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.3224 - mean_squared_error: 0.3224 - rmse: 0.5678 - mean_absolute_error: 0.429\n",
      "Epoch 60: val_loss improved from 0.96782 to 0.68435, saving model to /tmp/tmpc7nyb65v.h5\n",
      "27/27 [==============================] - 2s 80ms/step - loss: 0.3208 - mean_squared_error: 0.3208 - rmse: 0.5664 - mean_absolute_error: 0.4286 - val_loss: 0.6844 - val_mean_squared_error: 0.6844 - val_rmse: 0.8273 - val_mean_absolute_error: 0.6423 - lr: 0.0050\n",
      "Epoch 61/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2668 - mean_squared_error: 0.2668 - rmse: 0.5165 - mean_absolute_error: 0.398\n",
      "Epoch 61: val_loss did not improve from 0.68435\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.2663 - mean_squared_error: 0.2663 - rmse: 0.5160 - mean_absolute_error: 0.3989 - val_loss: 1.0227 - val_mean_squared_error: 1.0227 - val_rmse: 1.0113 - val_mean_absolute_error: 0.7998 - lr: 0.0050\n",
      "Epoch 62/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2037 - mean_squared_error: 0.2037 - rmse: 0.4513 - mean_absolute_error: 0.357\n",
      "Epoch 62: val_loss did not improve from 0.68435\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.2015 - mean_squared_error: 0.2015 - rmse: 0.4489 - mean_absolute_error: 0.3546 - val_loss: 0.8889 - val_mean_squared_error: 0.8889 - val_rmse: 0.9428 - val_mean_absolute_error: 0.7393 - lr: 0.0050\n",
      "Epoch 63/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1934 - mean_squared_error: 0.1934 - rmse: 0.4398 - mean_absolute_error: 0.341\n",
      "Epoch 63: val_loss did not improve from 0.68435\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.1917 - mean_squared_error: 0.1917 - rmse: 0.4379 - mean_absolute_error: 0.3397 - val_loss: 0.8413 - val_mean_squared_error: 0.8413 - val_rmse: 0.9172 - val_mean_absolute_error: 0.7095 - lr: 0.0050\n",
      "Epoch 64/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1277 - mean_squared_error: 0.1277 - rmse: 0.3574 - mean_absolute_error: 0.285\n",
      "Epoch 64: val_loss did not improve from 0.68435\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.1267 - mean_squared_error: 0.1267 - rmse: 0.3559 - mean_absolute_error: 0.2844 - val_loss: 1.2516 - val_mean_squared_error: 1.2516 - val_rmse: 1.1187 - val_mean_absolute_error: 0.9005 - lr: 0.0050\n",
      "Epoch 65/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1466 - mean_squared_error: 0.1466 - rmse: 0.3829 - mean_absolute_error: 0.300\n",
      "Epoch 65: val_loss did not improve from 0.68435\n",
      "27/27 [==============================] - 2s 79ms/step - loss: 0.1481 - mean_squared_error: 0.1481 - rmse: 0.3848 - mean_absolute_error: 0.3016 - val_loss: 1.0199 - val_mean_squared_error: 1.0199 - val_rmse: 1.0099 - val_mean_absolute_error: 0.7633 - lr: 0.0050\n",
      "Epoch 66/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1527 - mean_squared_error: 0.1527 - rmse: 0.3908 - mean_absolute_error: 0.301\n",
      "Epoch 66: val_loss improved from 0.68435 to 0.59953, saving model to /tmp/tmpc7nyb65v.h5\n",
      "27/27 [==============================] - 2s 80ms/step - loss: 0.1509 - mean_squared_error: 0.1509 - rmse: 0.3885 - mean_absolute_error: 0.2995 - val_loss: 0.5995 - val_mean_squared_error: 0.5995 - val_rmse: 0.7743 - val_mean_absolute_error: 0.6025 - lr: 0.0050\n",
      "Epoch 67/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2431 - mean_squared_error: 0.2431 - rmse: 0.4930 - mean_absolute_error: 0.388\n",
      "Epoch 67: val_loss did not improve from 0.59953\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.2468 - mean_squared_error: 0.2468 - rmse: 0.4968 - mean_absolute_error: 0.3922 - val_loss: 0.8578 - val_mean_squared_error: 0.8578 - val_rmse: 0.9262 - val_mean_absolute_error: 0.7110 - lr: 0.0050\n",
      "Epoch 68/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1872 - mean_squared_error: 0.1872 - rmse: 0.4327 - mean_absolute_error: 0.334\n",
      "Epoch 68: val_loss did not improve from 0.59953\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.1870 - mean_squared_error: 0.1870 - rmse: 0.4324 - mean_absolute_error: 0.3343 - val_loss: 1.0283 - val_mean_squared_error: 1.0283 - val_rmse: 1.0140 - val_mean_absolute_error: 0.7861 - lr: 0.0050\n",
      "Epoch 69/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2242 - mean_squared_error: 0.2242 - rmse: 0.4735 - mean_absolute_error: 0.364\n",
      "Epoch 69: val_loss did not improve from 0.59953\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.2223 - mean_squared_error: 0.2223 - rmse: 0.4714 - mean_absolute_error: 0.3628 - val_loss: 1.7712 - val_mean_squared_error: 1.7712 - val_rmse: 1.3309 - val_mean_absolute_error: 1.0472 - lr: 0.0050\n",
      "Epoch 70/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2996 - mean_squared_error: 0.2996 - rmse: 0.5474 - mean_absolute_error: 0.420\n",
      "Epoch 70: val_loss did not improve from 0.59953\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.2964 - mean_squared_error: 0.2964 - rmse: 0.5444 - mean_absolute_error: 0.4177 - val_loss: 0.7103 - val_mean_squared_error: 0.7103 - val_rmse: 0.8428 - val_mean_absolute_error: 0.6694 - lr: 0.0050\n",
      "Epoch 71/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1352 - mean_squared_error: 0.1352 - rmse: 0.3677 - mean_absolute_error: 0.288\n",
      "Epoch 71: val_loss did not improve from 0.59953\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.1431 - mean_squared_error: 0.1431 - rmse: 0.3783 - mean_absolute_error: 0.2948 - val_loss: 0.7324 - val_mean_squared_error: 0.7324 - val_rmse: 0.8558 - val_mean_absolute_error: 0.6562 - lr: 0.0050\n",
      "Epoch 72/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1819 - mean_squared_error: 0.1819 - rmse: 0.4265 - mean_absolute_error: 0.331\n",
      "Epoch 72: val_loss did not improve from 0.59953\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.1801 - mean_squared_error: 0.1801 - rmse: 0.4244 - mean_absolute_error: 0.3296 - val_loss: 1.8054 - val_mean_squared_error: 1.8054 - val_rmse: 1.3436 - val_mean_absolute_error: 1.0872 - lr: 0.0050\n",
      "Epoch 73/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1843 - mean_squared_error: 0.1843 - rmse: 0.4293 - mean_absolute_error: 0.340\n",
      "Epoch 73: val_loss did not improve from 0.59953\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.1829 - mean_squared_error: 0.1829 - rmse: 0.4277 - mean_absolute_error: 0.3394 - val_loss: 0.7453 - val_mean_squared_error: 0.7453 - val_rmse: 0.8633 - val_mean_absolute_error: 0.6507 - lr: 0.0050\n",
      "Epoch 74/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2037 - mean_squared_error: 0.2037 - rmse: 0.4513 - mean_absolute_error: 0.349\n",
      "Epoch 74: val_loss did not improve from 0.59953\n",
      "27/27 [==============================] - 2s 79ms/step - loss: 0.2073 - mean_squared_error: 0.2073 - rmse: 0.4553 - mean_absolute_error: 0.3532 - val_loss: 0.7768 - val_mean_squared_error: 0.7768 - val_rmse: 0.8813 - val_mean_absolute_error: 0.6750 - lr: 0.0050\n",
      "Epoch 75/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1340 - mean_squared_error: 0.1340 - rmse: 0.3661 - mean_absolute_error: 0.289\n",
      "Epoch 75: val_loss did not improve from 0.59953\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.1343 - mean_squared_error: 0.1343 - rmse: 0.3665 - mean_absolute_error: 0.2894 - val_loss: 0.6507 - val_mean_squared_error: 0.6507 - val_rmse: 0.8067 - val_mean_absolute_error: 0.6250 - lr: 0.0050\n",
      "Epoch 76/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1584 - mean_squared_error: 0.1584 - rmse: 0.3980 - mean_absolute_error: 0.305\n",
      "Epoch 76: val_loss did not improve from 0.59953\n",
      "27/27 [==============================] - 2s 79ms/step - loss: 0.1582 - mean_squared_error: 0.1582 - rmse: 0.3977 - mean_absolute_error: 0.3059 - val_loss: 0.7780 - val_mean_squared_error: 0.7780 - val_rmse: 0.8821 - val_mean_absolute_error: 0.6785 - lr: 0.0050\n",
      "Epoch 77/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2141 - mean_squared_error: 0.2141 - rmse: 0.4627 - mean_absolute_error: 0.365\n",
      "Epoch 77: val_loss did not improve from 0.59953\n",
      "27/27 [==============================] - 2s 79ms/step - loss: 0.2141 - mean_squared_error: 0.2141 - rmse: 0.4627 - mean_absolute_error: 0.3657 - val_loss: 1.2880 - val_mean_squared_error: 1.2880 - val_rmse: 1.1349 - val_mean_absolute_error: 0.9114 - lr: 0.0050\n",
      "Epoch 78/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1755 - mean_squared_error: 0.1755 - rmse: 0.4190 - mean_absolute_error: 0.317\n",
      "Epoch 78: val_loss did not improve from 0.59953\n",
      "27/27 [==============================] - 2s 79ms/step - loss: 0.1754 - mean_squared_error: 0.1754 - rmse: 0.4188 - mean_absolute_error: 0.3177 - val_loss: 1.0488 - val_mean_squared_error: 1.0488 - val_rmse: 1.0241 - val_mean_absolute_error: 0.8073 - lr: 0.0050\n",
      "Epoch 79/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1970 - mean_squared_error: 0.1970 - rmse: 0.4438 - mean_absolute_error: 0.346\n",
      "Epoch 79: val_loss did not improve from 0.59953\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.2042 - mean_squared_error: 0.2042 - rmse: 0.4519 - mean_absolute_error: 0.3527 - val_loss: 0.6420 - val_mean_squared_error: 0.6420 - val_rmse: 0.8012 - val_mean_absolute_error: 0.6011 - lr: 0.0050\n",
      "Epoch 80/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2152 - mean_squared_error: 0.2152 - rmse: 0.4639 - mean_absolute_error: 0.373\n",
      "Epoch 80: val_loss did not improve from 0.59953\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.2167 - mean_squared_error: 0.2167 - rmse: 0.4655 - mean_absolute_error: 0.3741 - val_loss: 1.0747 - val_mean_squared_error: 1.0747 - val_rmse: 1.0367 - val_mean_absolute_error: 0.7962 - lr: 0.0050\n",
      "Epoch 81/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.2219 - mean_squared_error: 0.2219 - rmse: 0.4711 - mean_absolute_error: 0.368\n",
      "Epoch 81: val_loss did not improve from 0.59953\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.2302 - mean_squared_error: 0.2302 - rmse: 0.4798 - mean_absolute_error: 0.3757 - val_loss: 0.7003 - val_mean_squared_error: 0.7003 - val_rmse: 0.8368 - val_mean_absolute_error: 0.6400 - lr: 0.0050\n",
      "Epoch 82/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1429 - mean_squared_error: 0.1429 - rmse: 0.3781 - mean_absolute_error: 0.288\n",
      "Epoch 82: val_loss did not improve from 0.59953\n",
      "27/27 [==============================] - 2s 79ms/step - loss: 0.1429 - mean_squared_error: 0.1429 - rmse: 0.3780 - mean_absolute_error: 0.2879 - val_loss: 0.7581 - val_mean_squared_error: 0.7581 - val_rmse: 0.8707 - val_mean_absolute_error: 0.6608 - lr: 0.0050\n",
      "Epoch 83/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1320 - mean_squared_error: 0.1320 - rmse: 0.3634 - mean_absolute_error: 0.279\n",
      "Epoch 83: val_loss did not improve from 0.59953\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 0.1316 - mean_squared_error: 0.1316 - rmse: 0.3627 - mean_absolute_error: 0.2789 - val_loss: 0.8446 - val_mean_squared_error: 0.8446 - val_rmse: 0.9190 - val_mean_absolute_error: 0.7244 - lr: 0.0050\n",
      "Epoch 84/1000\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.1737 - mean_squared_error: 0.1737 - rmse: 0.4168 - mean_absolute_error: 0.307\n",
      "Epoch 84: val_loss did not improve from 0.59953\n",
      "27/27 [==============================] - 2s 79ms/step - loss: 0.1739 - mean_squared_error: 0.1739 - rmse: 0.4170 - mean_absolute_error: 0.3083 - val_loss: 0.6656 - val_mean_squared_error: 0.6656 - val_rmse: 0.8159 - val_mean_absolute_error: 0.6375 - lr: 0.0050\n",
      "Epoch 85/1000\n",
      "13/27 [=============>................] - ETA: 1s - loss: 0.2086 - mean_squared_error: 0.2086 - rmse: 0.4567 - mean_absolute_error: 0.3519"
     ]
    }
   ],
   "source": [
    "single0, history_single0 = single_cross_site(cnn_resnet, 'cnn_resnet', 0.01, 0, 3, 4, X, y)\n",
    "single3, history_single3 = single_cross_site(cnn_resnet, 'cnn_resnet', 0.01, 3, 0, 4, X, y)\n",
    "single4, history_single4 = single_cross_site(cnn_resnet, 'cnn_resnet', 0.01, 4, 0, 3, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd4e202",
   "metadata": {
    "gather": {
     "logged": 1652120673383
    }
   },
   "outputs": [],
   "source": [
    "df_single = (single0.merge(single3, how='outer')).merge(single4, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc2394",
   "metadata": {
    "gather": {
     "logged": 1652120673525
    }
   },
   "outputs": [],
   "source": [
    "df_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5227cf",
   "metadata": {
    "gather": {
     "logged": 1652120673843
    }
   },
   "outputs": [],
   "source": [
    "within_site_mae = df_single[(df_single['Metric'] == 'MAE')][(df_single['Test_site'] == df_single['Train_site'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6727dd",
   "metadata": {
    "gather": {
     "logged": 1652120673982
    }
   },
   "outputs": [],
   "source": [
    "within_site_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51740111",
   "metadata": {
    "gather": {
     "logged": 1652120674095
    }
   },
   "outputs": [],
   "source": [
    "cross_site_mae = df_single[(df_single['Metric'] == 'MAE')][(df_single['Test_site'] != df_single['Train_site'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b2e33",
   "metadata": {
    "gather": {
     "logged": 1652120674223
    }
   },
   "outputs": [],
   "source": [
    "cross_site_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3701bc",
   "metadata": {},
   "source": [
    "#### double-cross-site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31f9b1a",
   "metadata": {
    "gather": {
     "logged": 1652122385694
    }
   },
   "outputs": [],
   "source": [
    "double_34, history_double_34 = double_cross_site(cnn_resnet, 'cnn_resnet', 0.01, 3, 4, 0, X, y)\n",
    "double_04, history_double_04 = double_cross_site(cnn_resnet, 'cnn_resnet', 0.01, 0, 4, 3, X, y)\n",
    "double_03, history_double_03 = double_cross_site(cnn_resnet, 'cnn_resnet', 0.01, 0, 3, 4, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d01d8",
   "metadata": {
    "gather": {
     "logged": 1652122385820
    }
   },
   "outputs": [],
   "source": [
    "df_double = (double_34.merge(double_04, how='outer')).merge(double_03, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417aa037",
   "metadata": {
    "gather": {
     "logged": 1652122386081
    }
   },
   "outputs": [],
   "source": [
    "double_mae = df_double[(df_double['Metric'] == 'MAE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af95689",
   "metadata": {
    "gather": {
     "logged": 1652122386392
    }
   },
   "outputs": [],
   "source": [
    "double_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b6911e",
   "metadata": {
    "gather": {
     "logged": 1652122386558
    }
   },
   "outputs": [],
   "source": [
    "cross_site_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9a1d4e",
   "metadata": {
    "gather": {
     "logged": 1652122386703
    }
   },
   "outputs": [],
   "source": [
    "within_site_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1d10db",
   "metadata": {
    "gather": {
     "logged": 1652122386833
    }
   },
   "outputs": [],
   "source": [
    "for site in [0, 3, 4]: \n",
    "    within = np.mean(within_site_mae[within_site_mae[\"Test_site\"] == site][\"Value\"])\n",
    "    across = np.mean(cross_site_mae[cross_site_mae[\"Test_site\"] == site][\"Value\"])\n",
    "    cost = np.mean(across - within)\n",
    "    for x in double_mae[double_mae[\"Test_site\"] == site].iterrows():\n",
    "        if str(site) not in x[1][\"Train_site\"]:\n",
    "            across_double = np.mean(x[1][\"Value\"])\n",
    "            cost_double = np.mean(across_double - within)\n",
    "            \n",
    "    print(\"site:\", site)\n",
    "    print(\"within: \", within)\n",
    "    print(\"across: \", across)\n",
    "    print(\"cost: \", cost)\n",
    "    print(\"across_double: \", across_double)\n",
    "    print(\"cost_double: \", cost_double)\n",
    "    print(\"################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6f46b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "azureml_py38_pt_tf"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - Pytorch and Tensorflow",
   "language": "python",
   "name": "azureml_py38_pt_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
