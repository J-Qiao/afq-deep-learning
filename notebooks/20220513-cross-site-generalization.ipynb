{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f8734f6",
   "metadata": {
    "gather": {
     "logged": 1652212959976
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import afqinsight.nn.tf_models as nn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from afqinsight.datasets import AFQDataset\n",
    "from afqinsight.nn.tf_models import cnn_lenet, mlp4, cnn_vgg, lstm1v0, lstm1, lstm2, blstm1, blstm2, lstm_fcn, cnn_resnet\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os.path\n",
    "# Harmonization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from neurocombat_sklearn import CombatModel\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle, resample\n",
    "from afqinsight.augmentation import jitter, time_warp, scaling\n",
    "import tempfile\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0eccb79",
   "metadata": {
    "gather": {
     "logged": 1652212986960
    }
   },
   "outputs": [],
   "source": [
    "afq_dataset = AFQDataset.from_files(\n",
    "    fn_nodes=\"../data/raw/combined_tract_profiles.csv\",\n",
    "    fn_subjects=\"../data/raw/participants_updated_id.csv\",\n",
    "    dwi_metrics=[\"dki_fa\", \"dki_md\", \"dki_mk\"],\n",
    "    index_col=\"subject_id\",\n",
    "    target_cols=[\"age\", \"dl_qc_score\", \"scan_site_id\"],\n",
    "    label_encode_cols=[\"scan_site_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fc97db2",
   "metadata": {
    "gather": {
     "logged": 1652212987198
    }
   },
   "outputs": [],
   "source": [
    "afq_dataset.drop_target_na()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d47ebb60",
   "metadata": {
    "gather": {
     "logged": 1652212987403
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1865\n",
      "(1865, 7200)\n",
      "(1865, 3)\n"
     ]
    }
   ],
   "source": [
    "print(len(afq_dataset.subjects))\n",
    "print(afq_dataset.X.shape)\n",
    "print(afq_dataset.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c366051",
   "metadata": {
    "gather": {
     "logged": 1652212988137
    }
   },
   "outputs": [],
   "source": [
    "full_dataset = list(afq_dataset.as_tensorflow_dataset().as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d75581",
   "metadata": {
    "gather": {
     "logged": 1652212988321
    }
   },
   "outputs": [],
   "source": [
    "X = np.concatenate([xx[0][None] for xx in full_dataset], 0)\n",
    "y = np.array([yy[1][0] for yy in full_dataset])\n",
    "qc = np.array([yy[1][1] for yy in full_dataset])\n",
    "site = np.array([yy[1][2] for yy in full_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "623180c2",
   "metadata": {
    "gather": {
     "logged": 1652212988490
    }
   },
   "outputs": [],
   "source": [
    "X = X[qc>0]\n",
    "y = y[qc>0]\n",
    "site = site[qc>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86789a05-6d17-4c98-8604-b515c9c8a1dc",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1652212988730
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1817, 100, 72)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "356c33a0",
   "metadata": {
    "gather": {
     "logged": 1652212988908
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "# EarlyStopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.001,\n",
    "    mode=\"min\",\n",
    "    patience=100\n",
    ")\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e11c5b77",
   "metadata": {
    "gather": {
     "logged": 1652212989076
    }
   },
   "outputs": [],
   "source": [
    "def augment_this(X, y, rounds=2): \n",
    "    new_X = X[:]\n",
    "    new_y = y[:]\n",
    "    for f in range(rounds): \n",
    "        aug_X = np.zeros_like(X)\n",
    "        # Do each channel separately:\n",
    "        for channel in range(aug_X.shape[-1]):\n",
    "            this_X = X[..., channel][..., np.newaxis]\n",
    "            this_X = jitter(this_X, sigma=np.mean(this_X)/25)\n",
    "            this_X = scaling(this_X, sigma=np.mean(this_X)/25)\n",
    "            this_X = time_warp(this_X, sigma=np.mean(this_X)/25)\n",
    "            aug_X[..., channel] = this_X[...,0]\n",
    "        new_X = np.concatenate([new_X, aug_X])\n",
    "        new_y = np.concatenate([new_y, y])\n",
    "    return new_X, new_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69834832-d894-4c9c-a58c-55fa2aaf6cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = X[site==0]\n",
    "y0 = y[site==0]\n",
    "X3 = X[site==3]\n",
    "y3 = y[site==3]\n",
    "X4 = X[site==4]\n",
    "y4 = y[site==4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ea59de2-1f4d-4e74-881e-71ae1b75da46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((755, 100, 72), (743, 100, 72), (253, 100, 72))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0.shape, X3.shape, X4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47879b42-76cc-4ff5-9c3e-ce047d25cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(model_func, X_train, y_train):\n",
    "    \n",
    "    model = model_func(input_shape=(100, X_train.shape[-1]), n_classes=1, output_activation=None, verbose=True)\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  metrics=['mean_squared_error', \n",
    "                           tf.keras.metrics.RootMeanSquaredError(name='rmse'), \n",
    "                           'mean_absolute_error'])\n",
    "    # ModelCheckpoint\n",
    "    ckpt_filepath = tempfile.NamedTemporaryFile().name + '.h5'\n",
    "    ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath = ckpt_filepath,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        mode=\"auto\",\n",
    "        )\n",
    "    callbacks = [early_stopping, ckpt, reduce_lr]\n",
    "    history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=128, validation_split=0.2,\n",
    "                        callbacks=callbacks, verbose=0, use_multiprocessing=True)\n",
    "    model.load_weights(ckpt_filepath)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ea47010",
   "metadata": {
    "gather": {
     "logged": 1652212989278
    }
   },
   "outputs": [],
   "source": [
    "def cross_site(model_func, name_str, lr, X, y, random_states, augment=True):\n",
    "    # Split the data by sites\n",
    "    X0 = X[site==0]\n",
    "    y0 = y[site==0]\n",
    "    X3 = X[site==3]\n",
    "    y3 = y[site==3]\n",
    "    X4 = X[site==4]\n",
    "    y4 = y[site==4]\n",
    "\n",
    "    # We downsample each site down to the size of the smallest site:\n",
    "    sample_size = X4.shape[0]\n",
    "    X0, y0 = resample(X0, y0, n_samples=sample_size, replace=False, random_state=random_states[0])\n",
    "    X3, y3 = resample(X3, y3, n_samples=sample_size, replace=False, random_state=random_states[1])\n",
    "    X4, y4 = resample(X4, y4, n_samples=sample_size, replace=False, random_state=random_states[2])\n",
    "    \n",
    "    # Split the data into train and test sets:\n",
    "    X0_train, X0_test, y0_train, y0_test = train_test_split(X0, y0, \n",
    "                                                            test_size=0.2, \n",
    "                                                            random_state=random_states[0])\n",
    "    X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, \n",
    "                                                            test_size=0.2, \n",
    "                                                            random_state=random_states[1])\n",
    "    \n",
    "    X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, \n",
    "                                                            test_size=0.2, \n",
    "                                                            random_state=random_states[2])\n",
    "    \n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    # Impute train and test separately:\n",
    "    X0_train = np.concatenate([imputer.fit_transform(X0_train[..., ii])[:, :, None] for ii in range(X0_train.shape[-1])], -1)\n",
    "    X0_test = np.concatenate([imputer.fit_transform(X0_test[..., ii])[:, :, None] for ii in range(X0_test.shape[-1])], -1)\n",
    "    X3_train = np.concatenate([imputer.fit_transform(X3_train[..., ii])[:, :, None] for ii in range(X3_train.shape[-1])], -1)\n",
    "    X3_test = np.concatenate([imputer.fit_transform(X3_test[..., ii])[:, :, None] for ii in range(X3_test.shape[-1])], -1)\n",
    "    X4_train = np.concatenate([imputer.fit_transform(X4_train[..., ii])[:, :, None] for ii in range(X4_train.shape[-1])], -1)\n",
    "    X4_test = np.concatenate([imputer.fit_transform(X4_test[..., ii])[:, :, None] for ii in range(X4_test.shape[-1])], -1)\n",
    "    \n",
    "    if augment:\n",
    "        # Augment\n",
    "        X0_train, y0_train = augment_this(X0_train, y0_train, rounds=6)\n",
    "        X0_train, y0_train = shuffle(X0_train, y0_train)\n",
    "        X3_train, y3_train = augment_this(X3_train, y3_train, rounds=6)\n",
    "        X3_train, y3_train = shuffle(X3_train, y3_train)\n",
    "        X4_train, y4_train = augment_this(X4_train, y4_train, rounds=6)\n",
    "        X4_train, y4_train = shuffle(X4_train, y4_train)\n",
    "    \n",
    "    train_data = {0: [X0_train, y0_train], \n",
    "                  3: [X3_train, y3_train],\n",
    "                  4: [X4_train, y4_train]}\n",
    "\n",
    "    test_data = {0: [X0_test, y0_test], \n",
    "                 3: [X3_test, y3_test],\n",
    "                 4: [X4_test, y4_test]}\n",
    "\n",
    "    train_site = []\n",
    "    test_site = []\n",
    "    metric = []\n",
    "    value = []\n",
    "\n",
    "    # Train on each one separately and test on all of them\n",
    "    for train in train_data: \n",
    "        X_train, y_train = train_data[train]\n",
    "        trained = model_fit(model_func, X_train, y_train)\n",
    "        for test in test_data:\n",
    "            X_test, y_test = test_data[test]\n",
    "            y_pred = trained.predict(X_test)\n",
    "            train_site.append([train]*3)\n",
    "            test_site.append([test]*3)\n",
    "            metric.append(\"mae\")\n",
    "            value.append(mean_absolute_error(y_test, y_pred))\n",
    "            metric.append(\"mad\")\n",
    "            value.append(median_absolute_error(y_test, y_pred))\n",
    "            metric.append(\"r2\")\n",
    "            value.append(r2_score(y_test, y_pred))\n",
    "    \n",
    "    result = {'Model': [name_str] * 27,\n",
    "              'Train_site': np.array(train_site).ravel(),\n",
    "              'Test_site': np.array(test_site).ravel(),\n",
    "              'Metric': metric,\n",
    "              'Value': value}\n",
    "    df = pd.DataFrame(result)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0790377c-9b35-4c0c-bb97-fcfc3b5d4c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\"cnn_lenet\": {\"model\": cnn_lenet, \"lr\": 0.001}, \n",
    "              \"mlp4\": {\"model\": mlp4, \"lr\": 0.001},\n",
    "              \"cnn_vgg\": {\"model\": cnn_vgg, \"lr\": 0.001},\n",
    "              \"lstm1v0\": {\"model\": lstm1v0, \"lr\": 0.01},\n",
    "              \"lstm1\": {\"model\": lstm1, \"lr\": 0.01},\n",
    "              \"lstm2\": {\"model\": lstm2, \"lr\": 0.01},\n",
    "              \"blstm1\": {\"model\": blstm1, \"lr\": 0.01},\n",
    "              \"blstm2\": {\"model\": blstm1, \"lr\": 0.01},\n",
    "              \"lstm_fcn\": {\"model\": lstm_fcn, \"lr\": 0.01},\n",
    "              \"cnn_resnet\": {\"model\": cnn_resnet, \"lr\": 0.01}\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7e465bf-19e0-4acf-b687-6140186a1fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "970f7013-3446-463e-855d-a2a434b69e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = np.abs(np.floor(np.random.randn(3 * n_runs )*1000)).astype(int).reshape((n_runs, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6f46b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "model:  cnn_lenet\n",
      "pooling layers: 4\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 50, 6)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 25, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 12, 26)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 6, 36)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 216)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 381: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 418: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 444: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 468: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 524: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 544: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 564: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 584: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 604: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 50, 6)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 25, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 12, 26)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 6, 36)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 216)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 246: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 320: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 371: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 391: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 411: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 431: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "pooling layers: 4\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 50, 6)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPooling  (None, 25, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 216)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 214: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 256: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 316: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 336: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 356: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 376: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 396: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 216)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 236: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 288: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 336: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 375: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 404: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 424: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 444: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 464: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 484: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_16 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_18 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_19 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 216)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 291: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 328: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 348: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 368: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 388: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 408: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_20 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_20 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_21 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_21 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_22 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_22 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_23 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 216)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 284: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 320: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 340: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 373: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 393: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 413: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 433: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 453: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_24 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_24 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_25 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_25 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_26 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_26 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_27 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_27 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 216)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 279: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 384: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 417: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 437: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 457: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 477: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 497: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_28 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_28 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_29 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_29 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_30 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_30 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_31 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_31 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 216)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 239: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 298: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 332: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 352: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 372: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 392: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 412: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_32 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_32 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_33 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_33 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_34 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_34 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_35 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_35 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 216)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 302: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 379: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 487: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 507: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 527: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 547: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 567: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_36 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_36 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_37 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_37 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_38 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_38 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_39 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_39 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 216)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 216: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 286: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 306: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 326: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 346: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 366: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_40 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_40 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_41 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_41 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_42 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_42 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_43 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_43 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 247: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 302: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 325: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 380: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 431: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 451: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 471: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 491: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 511: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_44 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_44 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_45 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_45 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_46 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_46 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_47 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_47 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 257: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 284: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 307: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 327: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 347: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 367: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 387: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_48 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_48 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_49 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_49 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_50 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_50 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_51 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_51 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 229: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 299: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 463: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 489: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 523: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 543: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 563: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 583: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 603: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_52 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_52 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_53 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_53 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_54 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_54 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_55 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_55 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 218: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 324: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 367: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 410: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 430: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 450: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 470: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 491: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 511: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 531: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 551: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 571: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "pooling layers: 4\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_56 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_56 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_57 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_57 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_58 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_58 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_59 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_59 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 364: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 384: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 409: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 429: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 461: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 481: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 501: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 521: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 541: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_60 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_60 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_61 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_61 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_62 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_62 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_63 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_63 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 166: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 203: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 286: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 397: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 432: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 452: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 472: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 492: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 512: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_64 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_64 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_65 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_65 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_66 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_66 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_67 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_67 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 299: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 439: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 498: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 518: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 538: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 558: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 578: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_68 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_68 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_69 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_69 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_70 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_70 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_71 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_71 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 128: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 167: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 191: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 221: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 241: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 261: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 281: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 301: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_72 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_72 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_73 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_73 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_74 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_74 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_75 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_75 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 306: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 333: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 368: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 388: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 408: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 428: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 448: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_76 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_76 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_77 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_77 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_78 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_78 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_79 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_79 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 209: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 287: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 336: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 392: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 417: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 437: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 457: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 477: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 497: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_80 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_80 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_81 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_81 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_82 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_82 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_83 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_83 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 520: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 576: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 616: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 636: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 656: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 676: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 696: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_22 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_84 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_84 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_85 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_85 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_86 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_86 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_87 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_87 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 198: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 235: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 266: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 308: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 346: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 366: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 386: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 406: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 426: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_88 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_88 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_89 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_89 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_90 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_90 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_91 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_91 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 253: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 290: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 372: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 392: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 436: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 456: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 476: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 496: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 516: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_24 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_92 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_92 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_93 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_93 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_94 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_94 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_95 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_95 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 246: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 277: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 306: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 359: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 394: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 414: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 434: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 454: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 474: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_96 (Conv1D)          (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_96 (MaxPoolin  (None, 50, 6)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_97 (Conv1D)          (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_97 (MaxPoolin  (None, 25, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_98 (Conv1D)          (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_98 (MaxPoolin  (None, 12, 26)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_99 (Conv1D)          (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_99 (MaxPoolin  (None, 6, 36)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 168: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 196: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 268: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 289: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 309: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 342: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 362: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 382: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 402: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_26 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_100 (Conv1D)         (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_100 (MaxPooli  (None, 50, 6)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_101 (Conv1D)         (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_101 (MaxPooli  (None, 25, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_102 (Conv1D)         (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_102 (MaxPooli  (None, 12, 26)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_103 (Conv1D)         (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_103 (MaxPooli  (None, 6, 36)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 229: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 366: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 404: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 427: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 447: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 467: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 487: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 507: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_27 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_104 (Conv1D)         (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_104 (MaxPooli  (None, 50, 6)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_105 (Conv1D)         (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_105 (MaxPooli  (None, 25, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_106 (Conv1D)         (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_106 (MaxPooli  (None, 12, 26)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_107 (Conv1D)         (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_107 (MaxPooli  (None, 6, 36)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 207: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 266: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 306: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 341: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 374: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 394: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 414: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 434: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 454: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_28 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_108 (Conv1D)         (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_108 (MaxPooli  (None, 50, 6)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_109 (Conv1D)         (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_109 (MaxPooli  (None, 25, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_110 (Conv1D)         (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_110 (MaxPooli  (None, 12, 26)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_111 (Conv1D)         (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_111 (MaxPooli  (None, 6, 36)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_27 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 170: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 252: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 296: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 330: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 350: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 370: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 390: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 410: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_29 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_112 (Conv1D)         (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_112 (MaxPooli  (None, 50, 6)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_113 (Conv1D)         (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_113 (MaxPooli  (None, 25, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_114 (Conv1D)         (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_114 (MaxPooli  (None, 12, 26)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_115 (Conv1D)         (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_115 (MaxPooli  (None, 6, 36)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 291: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 332: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 472: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 510: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 553: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 573: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 593: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 613: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 633: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "pooling layers: 4\n",
      "Model: \"model_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_30 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " conv1d_116 (Conv1D)         (None, 100, 6)            1302      \n",
      "                                                                 \n",
      " max_pooling1d_116 (MaxPooli  (None, 50, 6)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_117 (Conv1D)         (None, 50, 16)            304       \n",
      "                                                                 \n",
      " max_pooling1d_117 (MaxPooli  (None, 25, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_118 (Conv1D)         (None, 25, 26)            1274      \n",
      "                                                                 \n",
      " max_pooling1d_118 (MaxPooli  (None, 12, 26)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_119 (Conv1D)         (None, 12, 36)            2844      \n",
      "                                                                 \n",
      " max_pooling1d_119 (MaxPooli  (None, 6, 36)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_29 (Flatten)        (None, 216)               0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 120)               26040     \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,013\n",
      "Trainable params: 42,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 160: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 324: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 380: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 400: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 455: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 500: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 520: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 540: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 560: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 580: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "##################################################\n",
      "model:  mlp4\n",
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_31 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 155: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 175: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Model: \"model_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_32 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_31 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 155: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 175: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 195: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 215: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Model: \"model_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_33 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_34 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_33 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 183: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_35 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_34 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 119: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 139: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 159: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_36 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_35 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_80 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_81 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_82 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_83 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 193: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_37 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_36 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_84 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_85 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_86 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_87 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_38 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_37 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_88 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_90 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_91 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 192: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_39 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_38 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_92 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_93 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_94 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_95 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 202: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Model: \"model_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_40 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_39 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_96 (Dropout)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_97 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_98 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_99 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_41 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_40 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_100 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_101 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_102 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_103 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 165: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_42 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_41 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_104 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_105 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_106 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_107 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_43 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_42 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_108 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_109 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_110 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_111 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 120: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 140: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_44 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_43 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_112 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_114 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_115 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 128: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 148: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 168: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 188: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_45 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_44 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_116 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_117 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_118 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_119 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 110: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 130: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 150: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 170: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_46 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_45 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_120 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_121 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_122 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_123 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_47 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_46 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_124 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_125 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_126 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_127 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 164: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 184: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Model: \"model_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_48 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_47 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_128 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_129 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_130 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_160 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_131 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 155: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_49 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_48 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_132 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_133 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_134 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_135 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_50 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_49 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_136 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_137 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_138 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_139 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 129: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 149: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 169: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 189: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_51 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_50 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_140 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_141 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_142 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_143 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 164: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_52 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_51 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_144 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_145 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_146 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_147 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 146: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 166: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 186: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_53 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_52 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_148 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_149 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_150 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_151 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 193: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 213: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 233: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Model: \"model_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_54 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_53 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_152 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_153 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_154 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_155 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 171: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 191: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Model: \"model_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_55 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_54 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_156 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_157 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_158 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_159 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 110: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 130: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 150: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_56 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_55 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_160 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_190 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_161 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_162 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_163 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 174: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 194: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 214: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Model: \"model_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_57 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_56 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_164 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_165 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_166 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_167 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 192: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_58 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_57 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_168 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_169 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_170 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_200 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_171 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Model: \"model_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_59 (InputLayer)       [(None, 100, 72)]         0         \n",
      "                                                                 \n",
      " flatten_58 (Flatten)        (None, 7200)              0         \n",
      "                                                                 \n",
      " dropout_172 (Dropout)       (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_202 (Dense)           (None, 500)               3600500   \n",
      "                                                                 \n",
      " dropout_173 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_174 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 500)               250500    \n",
      "                                                                 \n",
      " dropout_175 (Dropout)       (None, 500)               0         \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,102,001\n",
      "Trainable params: 4,102,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 110: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 130: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for model_name in model_dict:\n",
    "    model_func = model_dict[model_name][\"model\"]\n",
    "    lr = model_dict[model_name][\"lr\"]\n",
    "    print(\"##################################################\")\n",
    "    print(\"model: \", model_name)\n",
    "    for ii in range(n_runs):     \n",
    "        dfs.append(cross_site(model_func, model_name, lr, X, y, random_states[ii], augment=True))\n",
    "        one_df = pd.concat(dfs)\n",
    "        one_df.to_csv(\"cross_site.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c9f49b-30aa-469f-97f4-f9e5d6b53b83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "azureml_py38_pt_tf"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - Pytorch and Tensorflow",
   "language": "python",
   "name": "azureml_py38_pt_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
