{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8734f6",
   "metadata": {
    "gather": {
     "logged": 1652119071245
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import afqinsight.nn.tf_models as nn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from afqinsight.datasets import AFQDataset\n",
    "from afqinsight.nn.tf_models import cnn_lenet, mlp4, cnn_vgg, lstm1v0, lstm1, lstm2, blstm1, blstm2, lstm_fcn, cnn_resnet\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os.path\n",
    "# Harmonization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from neurocombat_sklearn import CombatModel\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
    "\n",
    "import pickle\n",
    "from tools import load_data, model_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cc071c-aec4-4786-9dd3-932697bf5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale = 1/5 \n",
    "# scale = 1/10\n",
    "# scale = 1/20 \n",
    "# scale = 1/40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5edc8-9195-46ff-99aa-7424799bf1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tf_aug(X_in, scaler=scale):\n",
    "#     X_out = np.zeros_like(X_in)\n",
    "#     for channel in range(X_in.shape[-1]):\n",
    "#         this_X = X_in[..., channel][np.newaxis, ..., np.newaxis]\n",
    "#         scale = np.abs(np.max(this_X) - np.min(this_X)) * scaler\n",
    "#         this_X = jitter(this_X, sigma=scale)\n",
    "#         this_X = scaling(this_X, sigma=scale)\n",
    "#         this_X = time_warp(this_X, sigma=scale)\n",
    "#         this_X = window_warp(this_X, window_ratio=scale)\n",
    "#         X_out[..., channel] = this_X[0, ..., 0]\n",
    "#     return X_out\n",
    "\n",
    "\n",
    "# def augment_this(X_in, y_in):\n",
    "#     X_out = tf.numpy_function(tf_aug, [X_in], tf.float32)    \n",
    "#     return X_out, y_in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef81336e-de7f-4f39-b629-119be45ce679",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, site = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abffc58d-e5bf-47e3-a82f-94df7f92ee56",
   "metadata": {
    "gather": {
     "logged": 1652119104750
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle, resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f091370-5672-4d9e-8fd5-14cc924e8ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ce224-53e2-496b-9135-791d99187b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "  \"cnn_lenet\": {\"model\": cnn_lenet, \"lr\": 0.001}, \n",
    "  # \"mlp4\": {\"model\": mlp4, \"lr\": 0.001},\n",
    "  # \"cnn_vgg\": {\"model\": cnn_vgg, \"lr\": 0.001},\n",
    "  # \"lstm1v0\": {\"model\": lstm1v0, \"lr\": 0.01},\n",
    "  # \"lstm1\": {\"model\": lstm1, \"lr\": 0.01},\n",
    "  # \"lstm2\": {\"model\": lstm2, \"lr\": 0.01},\n",
    "  # \"blstm1\": {\"model\": blstm1, \"lr\": 0.01},\n",
    "  # \"blstm2\": {\"model\": blstm1, \"lr\": 0.01},\n",
    "  # \"lstm_fcn\": {\"model\": lstm_fcn, \"lr\": 0.01},\n",
    "#   \"cnn_resnet\": {\"model\": cnn_resnet, \"lr\": 0.01}\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abcbeb5-f109-4d84-90e1-92aecc61b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4f3387-bb0c-4b6c-ac9a-8f6e87be0314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated once with this code and then hard-coded:\n",
    "# seeds = np.array([np.abs(np.floor(np.random.randn()*1000)) for ii in range(n_runs)], dtype=int)\n",
    "\n",
    "seeds = np.array([484, 645, 714, 244, 215, 1502, 1334, 1576, 469, 1795])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb566ad-94c2-4a5d-9683-f0588b4a8eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_eval(model, X, y, random_state, batch_size=128, n_epochs=1000, augment=None, train_size=None):\n",
    "    model_func = model_dict[model][\"model\"]\n",
    "    lr = model_dict[model][\"lr\"]\n",
    "    X_train, X_test, y_train, y_test, site_train, site_test = train_test_split(X, y, site, test_size=0.2, random_state=random_state)\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    # If train_size is set, select train_size subjects to be the training data:\n",
    "    if train_size is not None:\n",
    "        X_train, y_train = resample(X_train, y_train, replace=False, n_samples=train_size, random_state=random_state)\n",
    "    \n",
    "    # Impute train and test separately:\n",
    "    X_train = np.concatenate([imputer.fit_transform(X_train[..., ii])[:, :, None] for ii in range(X_train.shape[-1])], -1)\n",
    "    X_test = np.concatenate([imputer.fit_transform(X_test[..., ii])[:, :, None] for ii in range(X_test.shape[-1])], -1)\n",
    "    # Combat\n",
    "    X_train = np.concatenate([CombatModel().fit_transform(X_train[..., ii], site_train[:, None], None, None)[:, :, None] for ii in range(X_train.shape[-1])], -1)\n",
    "    X_test = np.concatenate([CombatModel().fit_transform(X_test[..., ii], site_test[:, None], None, None)[:, :, None] for ii in range(X_test.shape[-1])], -1)\n",
    "    \n",
    "    trained = model_fit(model_func, X_train, y_train, lr, \n",
    "                        batch_size=batch_size, n_epochs=n_epochs)\n",
    "    metric = []\n",
    "    value = []\n",
    "    \n",
    "    y_pred = trained.predict(X_test)\n",
    "    metric.append(\"mae\")\n",
    "    value.append(mean_absolute_error(y_test, y_pred))\n",
    "    metric.append(\"mad\")\n",
    "    value.append(median_absolute_error(y_test, y_pred))\n",
    "    metric.append(\"r2\")\n",
    "    value.append(r2_score(y_test, y_pred))\n",
    "    \n",
    "    result = {'Model': [model] * len(metric),\n",
    "              'Metric': metric,\n",
    "              'Value': value}\n",
    "    \n",
    "    return pd.DataFrame(result), pd.DataFrame(dict(y_pred=y_pred.squeeze(), y_test=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e88d0ab-5a49-46c0-80e2-fabffb498a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_eval = []\n",
    "dfs_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd035f48",
   "metadata": {
    "gather": {
     "logged": 1652213549742
    }
   },
   "outputs": [],
   "source": [
    "for model in model_dict:\n",
    "    print(\"##################################################\")\n",
    "    print(\"model: \", model)\n",
    "    for ii in range(n_runs): \n",
    "        print(\"run: \", ii)\n",
    "        this_eval, this_pred = fit_and_eval(\n",
    "            model, \n",
    "            X, \n",
    "            y, \n",
    "            random_state=seeds[ii],\n",
    "            train_size=700)\n",
    "        this_eval[\"run\"] = ii\n",
    "        this_pred[\"run\"] = ii\n",
    "        dfs_eval.append(this_eval)\n",
    "        dfs_pred.append(this_pred)\n",
    "        # Save evaluation metrics\n",
    "        one_df = pd.concat(dfs_eval)\n",
    "        one_df.to_csv(\"lenet_1_eval.csv\")\n",
    "        # Save predictions and test values:\n",
    "        one_df = pd.concat(dfs_pred)\n",
    "        one_df.to_csv(\"lenet_1_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174eac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to try different training sample sizes: s\n",
    "# (1453, 1000, 700, 350, 175)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "azureml_py38_pt_tf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
